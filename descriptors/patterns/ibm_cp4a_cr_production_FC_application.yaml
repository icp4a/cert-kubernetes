
###############################################################################
##
##Licensed Materials - Property of IBM
##
##(C) Copyright IBM Corp. 2021, 2023. All Rights Reserved.
##
##US Government Users Restricted Rights - Use, duplication or
##disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
##
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: icp4adeploy
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 24.0.0
spec:
  appVersion: 24.0.0

  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""

  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:
    ## CP4A patterns or capabilities to be deployed.  This CR represents the "application" pattern (aka Business Automation Application)
    sc_deployment_patterns: application



    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.
    ## The optional components are: app_designer,ae_data_persistence
    sc_optional_components:

    ## The deployment context, which has a default value of "CP4A".  Unless you are instructed to change this value or
    ## know the reason to change this value, please leave the default value.
    sc_deployment_context: "CP4A"

    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores,
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section
    ## is defined with the required parameters in the CR (below) and sc_content_initialization is set to "true" (or the parameter doesn't exist), then the initialization will occur.
    ## However, if sc_content_initialization is set to "false", then the initialization will not occur (even with the "initialize_configuration" section defined)
    sc_content_initialization: false

    sc_egress_configuration:
      ## Required. Enable or disable egress access to external systems.
      ## If "sc_restricted_internet_access" is defined and has no value set, then default will be "true".
      ## If "sc_restricted_internet_access" is not defined (e.g., in the case of upgrade, the existing CR will not have sc_restricted_internet_access), then "sc_restricted_internet_access" will be "false"
      sc_restricted_internet_access: true
      ## Optional.  Kubernetes API server namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default are "openshift-kube-apiserver", "openshift-apiserver" for OCP and ROKS.
      sc_api_namespace:
      ## Optional.  Kubernetes API server port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## Default are 443,6443 for OCP and ROKS
      sc_api_port:
      ## Optional.  Kubernetes DNS service namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default is "openshift-dns" for OCP and ROKS
      sc_dns_namespace:
      ## Optional.  Kubernetes DNS service port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## Default are 53,5353 for OCP and ROKS
      sc_dns_port:

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## For ROKS Ingress, provide TLS secret name for Ingress controller. If you are not using ROKS, comment out this line.
    sc_ingress_tls_secret_name: <Required>

    ## If your Openshift cluster is configured for Hugepages and you want the applicable deployment resources to consume Hugepages.
    ## You must set "true" for sc_hugepages.enabled. Default is "false".
    ## You must set type for "Hugepages" like hugepages-2Mi or hugepages-1Gi. Default is "hugepages-2Mi".
    ## You must set size for value which is suitable for Openshift cluster.
    sc_hugepages:
      enabled: false
      type: ""
      value: ""

    ## This optional property is a string value corresponding to the “ipFamilyPolicy” property of the Kubernetes “service” object.
    ## This setting becomes particularly relevant in dual-stack environments where both IPv4 and IPv6 are enabled.
    ## Here are the options you can specify for ipFamilyPolicy: SingleStack , PreferDualStack , RequireDualStack
    ## Only set this property if you want the “ipFamilyPolicy” property of the services created for CP4BA to be configured differently from the cluster-level settings.
    ## Warning: Setting this property to a value not supported by your cluster will cause CP4BA deployment to fail.
    sc_service_ip_family_policy:

    ## This optional property is a list value corresponding to the “ipFamilies” property of the Kubernetes “service” object.
    ## This parameter works in conjunction with the ipFamilyPolicy to define the IP addressing behaviors for the Service.
    ## You can set it to any of the following array values: ["IPv4"],["IPv6"],["IPv4","IPv6"] (dual-stack environment)
    ## Only set this property if you want the “ipFamilies” property of the services created for CP4BA to be configured differently from the cluster-level settings.
    ## Warning: Setting this property to a value not supported by your cluster will cause CP4BA deployment to fail.
    sc_service_ip_families:

    ## Optional setting for secure computing mode (seccomp) profile for CP4A containers.  The default seccomp profile is RuntimeDefault on OCP 4.11 (k8s v1.24) or higher. seccomp profile won't be created on OCP 4.10 (k8s v1.23) or lower.
    ## For more information on seccomp please refer to https://kubernetes.io/docs/tutorials/security/seccomp/ and https://docs.openshift.com/container-platform/4.12/security/seccomp-profiles.html
    ## NOTE: Defining a custom, localhost seccomp profile that is stricter than the default RuntimeDefault profile may cause our pods fail to start.  This custom profile should be created at the worker nodes.
    sc_seccomp_profile:
    #  type: # RuntimeDefault, Localhost, Unconfined
    #  localhost_profile: # Local path of custom seccomp profile when type `Localhost` is used. The custom profile must be accessible by the pod and must exist locally on all worker nodes.  For example: `/profiles/fine-grained.json`.

    ## Enable/disable FIPS mode for the deployment (default value is "false")
    ## Note: If set as "true", in order to complete enablement of FIPS for CP4BA, please refer to "FIPS wall" configuration in IBM documentation.
    enable_fips: false

    ## If a cluster is configured for multiple availability zones (AZ) and the parameter sc_is_multiple_az is set to true, then the pods are spread across all the zones.
    ## By default, the sc_is_multiple_az parameter is set to false. When the value is set to true, the pods of the CP4BA deployment are spread across your user-defined topology domains.
    ## The pod API includes a spec.topologySpreadConstraints field, which is used by the CP4BA operator to configure it.
    sc_is_multiple_az: false

  #--------------------------------------------------------------------------------------------------------------------------------
  # This section contains CPE and GraphQL for Business Automation Application Data Persistence(ae_data_persistence)
  # It is required when you want to enable ae_data_persistence optional feature. Please uncomment it when enabling ae_data_persistence
  #--------------------------------------------------------------------------------------------------------------------------------
  # ########################################################################
  # ########      IBM FileNet Content Manager configuration         ########
  # ########################################################################
  # ecm_configuration:
  #   ## FNCM secret that contains GCD DB user name and password, Object Store DB user name and password,
  #   ## LDAP user and password, CPE username and password, keystore password, and LTPA passs, etc.
  #   fncm_secret_name: ibm-fncm-secret

  #   # Disable FIPS for the component (default value is "false"), change it to "true" if you enable FIPS mode for the deployment with shared_configuration.enable_fips = true, but want to disable FIPS mode for the component.
  #   disable_fips: false

  #   ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.node_affinity.
  #   node_affinity:
  #     # Value in this field will be used as kubernetes.io/arch selector values. By default all support arch will be included
  #     # It will be transformed to node selector value
  #     # - key: kubernetes.io/arch
  #     #   operator: In
  #     #   values:
  #     #     - amd64
  #     #     - s390x
  #     #     - ppc64le
  #     deploy_arch:
  #     - amd64
  #     - s390x
  #     - ppc64le
  #     #-------------------------------------
  #     # custom_node_selector_match_expression will be added in node selector match expressions.
  #     # It accept array list inputs. You can assign mutiple selector match expressions except (kubernetes.io/arch)
  #     # Example value:
  #     # - key: kubernetes.io/hostname
  #     #   operator: In
  #     #   values:
  #     #     - worker0
  #     #     - worker1
  #     #     - worker3
  #     #-------------------------------------
  #   custom_node_selector_match_expression: []
  #   ## Values in this field will be used as annotations in all generated pods and it must be valid annotation key value pairs.
  #   # Example:
  #   # customAnnotationKey: customAnnotationValue
  #   ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_annotations.
  #   ## To include '{{ }}' in annotation like '{{example}}', add a backward slash before curly brace like '\{\{example\}\}'.
  #   custom_annotations: {}
  #   ## Values in this field will be used as labels in all generated pods and it must be valid label key value pairs
  #   # Example:
  #   # customLabelKey: customLableValue
  #   ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_labels.
  #
  #   custom_labels: {}

  #   # Optional performance tuning for Zen NGINX server.
  #   # For more information, please refer to https://www.nginx.com/blog/tuning-nginx/#keepalive_requests and https://nginx.org/en/docs/http/ngx_http_proxy_module.html.
  #   # This can be overwritten by componenent level definition for example ecm_configuration.graphql.zen_performance.
  #   # For CPE we allow more granular setting like below and they take precedence over ecm_configuration.cpe.zen_performance.
  #   # cpe.zen_performance.acce
  #   # cpe.zen_performance.fncews40mtom
  #   # cpe.zen_performance.pewsi
  #   # cpe.zen_performance.peengine
  #   # cpe.zen_performance.acce
  #   zen_performance:
  #     # Timeout for establishing a connection with a proxy server. This parameter is optional. The default value is 300s.
  #     proxy_connect_timeout: 300
  #     # Timeout for transmitting a request to the proxy server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the proxy server does not receive anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
  #     proxy_send_timeout: 300
  #     # Timeout for reading a response from the proxy server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxy server does not transmit anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
  #     proxy_read_timeout: 300

  #   ####################################
  #   ## Start of configuration for CPE ##
  #   ####################################
  #   cpe:
  #     ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
  #     arch:
  #       amd64: "3 - Most preferred"

  #     ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
  #     ## it is recommended to have 2 or more.
  #     replica_count: 2

  #     ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
  #     image:
  #       ## The default repository is the IBM Entitled Registry.
  #       repository: cp.icr.io/cp/cp4a/fncm/cpe
  #       tag: "24.0.0-IF001"

  #       ## This will override the image pull policy in the shared_configuration.
  #       pull_policy: IfNotPresent

  #     ## Logging for workloads.  This is the default setting.
  #     log:
  #      format: json

  #     ## Set securityContext for CPE deployment.
  #     security_context:
  #       ## Controls which group IDs containers add. For example "supplemental_groups: [1000620001,1000620002]"
  #       supplemental_groups:
  #       ## This can take an array of key value pairs to assign SELinux labels to a Container, for example
  #       ## selinux_options:
  #         ## level: "s0:c123,c456"
  #         ## type: "spc_t
  #       selinux_options:
  #       # Defines behavior for changing ownership and permission of the volume before being exposed inside a Pod. This field has two possible values (Always,OnRootMismatch)
  #       # For example fs_groupchangepolicy: "OnRootMismatch"
  #       fs_groupchangepolicy:

  #     ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
  #     ## make the changes here to meet your requirement.
  #     resources:
  #       requests:
  #         cpu: 1
  #         memory: 3072Mi
  #         ephemeral_storage: 4Gi
  #       limits:
  #         cpu: 1
  #         memory: 3072Mi
  #         ephemeral_storage: 4Gi
  #     ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
  #     ## this settings to meet your requirement.
  #     auto_scaling:
  #       enabled: false
  #       max_replicas: 3
  #       min_replicas: 2
  #       ## This is the default cpu percentage before autoscaling occurs.
  #       target_cpu_utilization_percentage: 80

  #     ## Below are the default CPE Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
  #     cpe_production_setting:
  #       time_zone: Etc/UTC

  #       ## The initial use of available memory.
  #       jvm_initial_heap_percentage: 18
  #       ## The maximum percentage of available memory to use.
  #       jvm_max_heap_percentage: 33

  #       ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
  #       ##  -Dmy.test.jvm.arg1=123
  #       ##  -Dmy.test.jvm.arg2=abc
  #       ##  -XX:+SomeJVMSettings
  #       ##  -XshowSettings:vm"
  #       ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
  #       ## If your JVM option contains comma then you have to include 'DELIM=;' to use a different separator, for example jvm_customize_options="DELIM=;-Dmy.test.jvm.arg1=123;-Dcom.filenet.authentication.wsi.AuthTokenOrder=oauth,oidc,ltpa". Semicolon can be replaced with any other char.
  #       ## If your JVM option contains double quotes then you need to escape it like this: jvm_customize_options="-Dsettings.navigator.default=logging.level={\"_value\":\"4\",\"_mergeOption\":\"replace\"}"
  #       jvm_customize_options:

  #       ## Default JNDI name for GCD for non-XA data source
  #       gcd_jndi_name: FNGCDDS
  #       ## Default JNDI name for GCD for XA data source
  #       gcd_jndixa_name: FNGCDDSXA
  #       license_model: FNCM.PVUNonProd

          ## GCD schema name - uncomment below code and update it's value with your custom GCD Schema name
  #       gcd_schema:

  #       # The license must be set to "accept" in order for the component to install.  This is the default value.
  #       license: accept

  #       This section is optional and it takes a list of configmaps.
  #       A configmap can hold files or environment data but it cannot a mix of both.
  #       The volume_path is optional for a configmap that holds files as its data and if it's not specified,
  #       then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
  #       then is_env is required and set it to true.
  #       custom_configmap:
  #        - name: <name of configmap>
  #          volume_path:  # optional
  #        - name: <name of configmap>
  #          is_env: # required if the configmap holds environment variables.

  #     ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
  #     monitor_enabled: false
  #     ## Enable/disable logging where logs can be sent to Elasticsearch.
  #     logging_enabled: false

  #     ## By default, the plugin for Graphite is enable to emit container metrics.
  #     collectd_enable_plugin_write_graphite: false

  #     ## Persistent Volume Claims for CPE.  If the storage_configuration in the shared_configuration is configured,
  #     ## the Operator will create the PVC using the names below.
  #     datavolume:
  #       existing_pvc_for_cpe_cfgstore:
  #          name: "cpe-cfgstore"
  #          size: 1Gi
  #        existing_pvc_for_cpe_logstore:
  #          name: "cpe-logstore"
  #          size: 1Gi
  #        existing_pvc_for_cpe_filestore:
  #          name: "cpe-filestore"
  #          size: 1Gi
  #        existing_pvc_for_cpe_icmrulestore:
  #          name: "cpe-icmrulesstore"
  #          size: 1Gi
  #        existing_pvc_for_cpe_textextstore:
  #          name: "cpe-textextstore"
  #          size: 3Gi
  #        existing_pvc_for_cpe_bootstrapstore:
  #          name: "cpe-bootstrapstore"
  #          size: 1Gi
  #        existing_pvc_for_cpe_fnlogstore:
  #          name: "cpe-fnlogstore"
  #          size: 1Gi


  #     ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
  #    probe:
  #      startup:
  #        initial_delay_seconds: 120
  #        period_seconds: 30
  #        timeout_seconds: 10
  #        failure_threshold: 40
  #      liveness:
  #        period_seconds: 30
  #        timeout_seconds: 5
  #        failure_threshold: 6

  #     ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
  #     image_pull_secrets:
  #       name: "ibm-entitlement-key"

  #   ########################################
  #   ## Start of configuration for GraphQL ##
  #   ########################################
  #   graphql:
  #     ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
  #     arch:
  #       amd64: "3 - Most preferred"

  #     ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
  #     ## it is recommended to have 2 or more.
  #     replica_count: 2

  #     ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
  #     image:
  #       ## The default repository is the IBM Entitled Registry.
  #       repository: cp.icr.io/cp/cp4a/fncm/graphql
  #       tag: "24.0.0-IF001"

  #       ## This will override the image pull policy in the shared_configuration.
  #       pull_policy: IfNotPresent

  #     ## Logging for workloads.  This is the default setting.
  #     log:
  #       format: json

  #     ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
  #     ## make the changes here to meet your requirement.
  #     resources:
  #       requests:
  #         cpu: 500m
  #         memory: 1536Mi
  #       limits:
  #         cpu: 1
  #         memory: 1536Mi

  #     ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
  #     ## this settings to meet your requirement.
  #     auto_scaling:
  #       enabled: false
  #       min_replicas: 2
  #       max_replicas: 3
  #       ## This is the default cpu percentage before autoscaling occurs.
  #       target_cpu_utilization_percentage: 80

  #     ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
  #     graphql_production_setting:
  #       time_zone: Etc/UTC

  #       ## The initial use of available memory.
  #       jvm_initial_heap_percentage: 40
  #       ## The maximum percentage of available memory to use.
  #       jvm_max_heap_percentage: 66

  #       ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
  #       ##  -Dmy.test.jvm.arg1=123
  #       ##  -Dmy.test.jvm.arg2=abc
  #       ##  -XX:+SomeJVMSettings
  #       ##  -XshowSettings:vm"
  #       ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
  #       ## If your JVM option contains comma then you have to include 'DELIM=;' to use a different separator, for example jvm_customize_options="DELIM=;-Dmy.test.jvm.arg1=123;-Dcom.filenet.authentication.wsi.AuthTokenOrder=oauth,oidc,ltpa". Semicolon can be replaced with any other char.
  #       ## If your JVM option contains double quotes then you need to escape it like this: jvm_customize_options="-Dsettings.navigator.default=logging.level={\"_value\":\"4\",\"_mergeOption\":\"replace\"}"
  #       jvm_customize_options:

  #       license_model: FNCM.PVUNonProd

  #       # The license must be set to "accept" in order for the component to install.  This is the default value.
  #       license: accept

  #       enable_graph_iql: false

  #       This section is optional and it takes a list of configmaps.
  #       A configmap can hold files or environment data but it cannot a mix of both.
  #       The volume_path is optional for a configmap that holds files as its data and if it's not specified,
  #       then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
  #       then is_env is required and set it to true.
  #       custom_configmap:
  #        - name: <name of configmap>
  #          volume_path:  # optional
  #        - name: <name of configmap>
  #          is_env: # required if the configmap holds environment variables.


  #     ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
  #     monitor_enabled: false
  #     ## Enable/disable logging where logs can be sent to Elasticsearch.
  #     logging_enabled: false

  #     ## By default, the plugin for Graphite is enable to emit container metrics.
  #     collectd_enable_plugin_write_graphite: false

  #     ## Persistent Volume Claims for GraphQL.  If the storage_configuration in the shared_configuration is configured,
  #     ## the Operator will create the PVC using the names below.
  #     datavolume:
  #       existing_pvc_for_graphql_cfgstore:
  #         name: "graphql-cfgstore"
  #         size: 1Gi
  #       existing_pvc_for_graphql_logstore: "graphql-logstore"
  #         name: "graphql-logstore"
  #         size: 1Gi

  #     ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
  #     probe:
  #      startup:
  #        initial_delay_seconds: 120
  #        period_seconds: 10
  #        timeout_seconds: 10
  #        failure_threshold: 6
  #      readiness:
  #        period_seconds: 10
  #        timeout_seconds: 10
  #        failure_threshold: 6
  #      liveness:
  #        period_seconds: 10
  #        timeout_seconds: 5
  #        failure_threshold: 6
  #     ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
  #     image_pull_secrets:
  #       name: "ibm-entitlement-key"
  #--------------------------------------------------------------------------------------------------------------------------------
  # This sections contains 2 object stores' data sources: Content Platform Engine Global Configuration Database object store(GCD) data source and Business Automation Application Data Persistence(ae_data_persistence) object store(AEOS) data source
  # It is required when you want to enable ae_data_persistence optional feature. Please uncomment it when enabling ae_data_persistence
  #--------------------------------------------------------------------------------------------------------------------------------
  # ## The beginning section of database configuration for CP4A
  # datasource_configuration:
  #   ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle/PostgreSQL.
  #   dc_ssl_enabled: true
  #   ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
  #   ## If set to "true", then CPE/Navigator database connection check will be enabled.
  #   ## if set to "false", then CPE/Navigator database connection check will not be enabled.
  #  # database_precheck: true
  #   ## The database configuration for the GCD datasource for CPE
  #   dc_gcd_datasource:
  #     ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
  #     ## If you want PostgresDB to be created for a GCD database, set this parameter to true
  #     dc_use_postgres: false
  #     ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".
  #     dc_database_type: "<Required>"
  #     ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
  #     dc_common_gcd_datasource_name: "FNGCDDS"
  #     ## The GCD XA datasource name. The default value is "FNGCDDSXA".
  #     dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
  #     ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
  #     database_servername: "<Required>"
  #     ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
  #     database_name: "<Required>"
  #     ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
  #     database_port: "<Required>"
  #     ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
  #     database_ssl_secret_name: "<Required>"
  #     ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
  #     dc_oracle_gcd_jdbc_url: "<Required>"
  #     ## Provide the validation timeout.  If not preference, keep the default value.
  #     dc_hadr_validation_timeout: 15
  #     ## If the database type is Db2 HADR, then complete the rest of the parameters below.
  #     ## Provide the database server name or IP address of the standby database server.
  #     dc_hadr_standby_servername: "<Required>"
  #     ## Provide the standby database server port.  For Db2, the default is "50000".
  #     dc_hadr_standby_port: "<Required>"
  #     ## Provide the retry internal.  If not preference, keep the default value.
  #     dc_hadr_retry_interval_for_client_reroute: 15
  #     ## Provide the max # of retries.  If not preference, keep the default value.
  #     dc_hadr_max_retries_for_client_reroute: 3

  #   ## The database configuration for the application engine object store (AEOS) datasource for CPE
  #   dc_os_datasources:
  #     ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the
  #     ## GCD configuration above.
  #   ## object store for AEOS
  #   - dc_database_type: "<Required>"
  #     ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
  #     ## If you want PostgresDB to be created for a GCD database, set this parameter to true
  #     dc_use_postgres: false
  #     ## Provide the object store label for the object store.  The default value is "os" or not defined.
  #     ## This label must match the OS secret you define in ibm-fncm-secret.
  #     ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
  #     ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
  #     ## If you don't define dc_os_label, then your secret will be defined as:
  #     ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
  #     ## If you have multiple object stores, then you need to define multiple datasource sections starting
  #     ## at "dc_database_type" element.
  #     ## If all the object store databases share the same username and password, then dc_os_label value should be the same
  #     ## in all the datasource sections.
  #     dc_os_label: "<Required>"
  #     ## The AEOS non-XA datasource name.  The default value is "AEOS".
  #     dc_common_os_datasource_name: "AEOS"
  #     ## The AEOS XA datasource name.  The default value is "AEOSXA".
  #     dc_common_os_xa_datasource_name: "AEOSXA"
  #     ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter. This should be the same as the
  #     ## GCD configuration above.
  #     database_servername: "<Required>"
  #     ## Provide the name of the database for the object store AEOS for CPE.  For example: "AEOSDB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
  #     database_name: "<Required>"
  #     ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
  #     database_port: "<Required>"
  #     ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
  #     database_ssl_secret_name: "<Required>"
  #     ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
  #     dc_oracle_os_jdbc_url: "<Required>"
  #     ## Provide the validation timeout.  If not preference, keep the default value.
  #     dc_hadr_validation_timeout: 15
  #     ######################################################################################
  #     ## If the database type is "Db2HADR", then complete the rest of the parameters below.
  #     ## Otherwise, remove or comment out the rest of the parameters below.
  #     ######################################################################################
  #     dc_hadr_standby_servername: "<Required>"
  #     ## Provide the standby database server port.  For Db2, the default is "50000".
  #     dc_hadr_standby_port: "<Required>"
  #     ## Provide the retry internal.  If not preference, keep the default value.
  #     dc_hadr_retry_interval_for_client_reroute: 15
  #     ## Provide the max # of retries.  If not preference, keep the default value.
  #     dc_hadr_max_retries_for_client_reroute: 3

  #--------------------------------------------------------------------------------------------------------------------------------
  # This section contains 2 object stores: Content Platform Engine Global Configuration Database object store(GCD) and Business Automation Application Data Persistence(ae_data_persistence) object store(AEOS)
  # It is required when you want to enable ae_data_persistence optional feature. Please uncomment it when enabling ae_data_persistence
  #--------------------------------------------------------------------------------------------------------------------------------
  # ########################################################################
  # ########  IBM FileNet Content Manager initialize configuration  ########
  # ########################################################################
  # initialize_configuration:
  #   ic_domain_creation:
  #     ## Provide a name for the domain
  #     domain_name: "P8DOMAIN"
  #     ## The encryption strength
  #     encryption_key: "128"
  #   ic_ldap_creation:
  #     ## Administrator user
  #     ic_ldap_admin_user_name:
  #     - "<Required>"
  #     ## Administrator group
  #     ic_ldap_admins_groups_name:
  #     - "<Required>"
  #     ## Name of the LDAP directory
  #     ic_ldap_name: "ldap_name"
  #   ic_obj_store_creation:
  #     object_stores:
  #       ## Configuration for the application engine object store
  #       ## Display name for the application engine object store to create
  #     - oc_cpe_obj_store_display_name: "AEOS"
  #       ## Symbolic name for the application engine object store to create
  #       oc_cpe_obj_store_symb_name: "AEOS"
  #       oc_cpe_obj_store_schema_name: "aeos"
  #       oc_cpe_obj_store_conn:
  #         ## Object store connection name
  #         name: "AEOS_connection" #database connection name
  #         ## The name of the site
  #         site_name: "InitialSite"
  #         ## Add the name of the object store database
  #         dc_os_datasource_name: "AEOS"
  #         ## The XA datasource
  #         dc_os_xa_datasource_name: "AEOSXA"
  #       ## Admin user group
  #       oc_cpe_obj_store_admin_user_groups:
  #       - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values.
  #       ## An array of users with access to the object store
  #       oc_cpe_obj_store_basic_user_groups:
  #       ## Specify whether to enable add-ons
  #       oc_cpe_obj_store_addons: true
  #       ## Add-ons to enable for Content Platform Engine
  #       oc_cpe_obj_store_addons_list:
  #       - "{CE460ADD-0000-0000-0000-000000000004}"
  #       - "{CE460ADD-0000-0000-0000-000000000001}"
  #       - "{CE460ADD-0000-0000-0000-000000000003}"
  #       - "{CE511ADD-0000-0000-0000-000000000006}"
  #       - "{CE460ADD-0000-0000-0000-000000000008}"
  #       - "{CE460ADD-0000-0000-0000-000000000007}"
  #       - "{CE460ADD-0000-0000-0000-000000000009}"
  #       - "{CE460ADD-0000-0000-0000-00000000000A}"
  #       - "{CE460ADD-0000-0000-0000-00000000000B}"
  #       - "{CE460ADD-0000-0000-0000-00000000000D}"
  #       - "{CE511ADD-0000-0000-0000-00000000000F}"
  #       ## Provide a name for the Advance Storage Area
  #       oc_cpe_obj_store_asa_name: "demo_storage"
  #       ## Provide a name for the file system storage device
  #       oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
  #       ## The root directory path for the object store storage area
  #       oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os01_storagearea"
  #       ## Specify whether to enable workflow for the object store
  #       oc_cpe_obj_store_enable_workflow: false
  #       ## Specify a name for the workflow region
  #       oc_cpe_obj_store_workflow_region_name: "<Required>"
  #       ## Specify the number of the workflow region
  #       oc_cpe_obj_store_workflow_region_number: 1
  #       ## Specify a table space for the workflow data
  #       oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
  #       ## Optionally specify a table space for the workflow index
  #       oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
  #       ## Optionally specify a table space for the workflow blob.
  #       oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
  #       ## Designate an LDAP group for the workflow admin group.
  #       oc_cpe_obj_store_workflow_admin_group: "<Required>"
  #       ## Designate an LDAP group for the workflow config group
  #       oc_cpe_obj_store_workflow_config_group: "<Required>"
  #       ## Default format for date and time
  #       oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
  #       ## Locale for the workflow
  #       oc_cpe_obj_store_workflow_locale: "en"
  #       ## Provide a name for the connection point
  #       oc_cpe_obj_store_workflow_pe_conn_point_name: ""
