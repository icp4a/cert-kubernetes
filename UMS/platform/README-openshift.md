# Install User Management Service 19.0.2 on Red Hat OpenShift 3.11

This documentation provides step-by-step instructions on how to install User Management Service 19.0.2 on Red Hat OpenShift 3.11 for test purposes. The documentation therefore does not include steps to setup a production-ready database, create image policy or configure persistent volume.

## Prepare your environment

As an administrator of the cluster you must be able to interact with your environment. Run the following commands to connect and check your access.

In order to interact with your Red Hat OpenShift 3.11 cluster, you need install and initialize command line interfaces.
1. Access your cluster at https://{MasterIP}:{consolePort}/console/command-line, e.g. https://1.2.3.4:8443/console/command-line
2. Download and install
    * Red Hat OpenShift CLI
    * Kubernetes CLI
    * Helm CLI

3. Login to the cluster:
   ```bash
   oc login https://<CLUSTERIP>:8443 -u <ADMINISTRATOR>
   ```
4. Check you can run docker.
   ```bash
   docker ps
   ```
## Prerequisites

In order to install the User Management Service via helm, you need to create a file `myvalues.yaml` to override some defaults of `values.yaml`, such as your database specific settings. The following section explain the prerequisites and the corresponding settings in `myvalues.yaml`.

### Create a database

User Management Service needs a database to work.

The simplest test environment with a single replica can use a built-in derby database in the container. Data is not shared across multiple replicas and is lost upon restarting the pod. If these restrictions are acceptable for a simple demonstration environment, you can set `derby` as your database type in your `myvalues.yaml`
```yaml
oauth:
  database:
    type: derby
...
teamserver:
  database:
    type: derby
```
For sharing data between replicas and keeping data when restarting, you must use a remote database, which can be installed in the same kubernetes cluster or "standalone". Follow the instructions of your database vendor, e.g.
* [IBM Db2 Developer-C](https://github.com/IBM/charts/tree/master/stable/ibm-db2oltp-dev)
* IBM Db2 Advanced Enterprise Edition Helm Chart

If you install Db2 in the same kubernetes environment, you can access Db2 using a kubernetes service without exposing a port publicly. The database is available at service-name.namespace, see [Service discovery (kube-dns)
](https://www.ibm.com/support/knowledgecenter/en/SSBS6K_3.1.2/manage_network/service_discovery.html).
For example, if you installed Db2 in namespace `db2` and created a service `umsdb-ibm-db2oltp-dev-db2`, you can use `umsdb-ibm-db2oltp-dev-db2.db2` as hostname:

```yaml
oauth:
  database:
    type: db2
    name: umsdb
    host: umsdb-ibm-db2oltp-dev-db2.db2
    port: 50000
```

### Create a project where you want to install User Management Service
User Management Service should be installed into a dedicated project/namespace. Use the following command to create a project and switch to it.

```bash
oc new-project umsproject
```

**Note:** The `oc` command implicitly passes the current project name for all subsequent commands. For `kubectl` you will need to pass the `-n umsproject` parameter explicitly.

### Create image policy
This is optional. If you intend to load docker images for User Management Service into a remote docker registry and let your Red Hat OpenShift cluster pull images, from this remote location, you need to create an image pull policy, see [imagepolicy.yaml](../configuration/imagepolicy.yaml) as a sample.

### Install IBM Cloud Pak SecurityContextConstraints resources to your cluster
Install IBM Cloud Pak SecurityContextConstraints resources to your cluster. Refer to '[`ibm-restricted-scc`](https://ibm.biz/cpkspec-scc)'.

### Create a docker pull secret
This is optional. If you intend to load docker images for User Management Service into a remote docker registry and let your IBM Cloud Private cluster pull images, from this remote location, you need to create image pull secrets for each of these registries:

```bash
oc create secret docker-registry ums-pull-secret1 --docker-server=docker-registry.default.svc:5000 --docker-username=dockeruser --docker-password=dockerpassword
```

The name of this secret can be passed to helm as a parameter in `myvalues.yaml`

```yaml
global:
  imagePullSecrets:
    - ums-pull-secret1
    - base-image-artifactory
```

### Generate TLS secret
To ensure the internal communication is secure, a TLS secret must be provided.
The secret can be generated by running the following command:
```bash
openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt
```

This command generates two files: tls.crt and tls.key. They are used to generate the TLS secret:
```bash
oc create secret tls ibm-dba-ums-tls --key=tls.key --cert=tls.crt
```

The name of this secret can be passed to helm as a parameter in `myvalues.yaml`

```yaml
tls:
  tlsSecretName: ibm-dba-ums-tls
```

### Generate UMS secret, DB secrets and LTPA generation secret
To avoid passing sensitive information via values.yaml, three secrets need to be created before installing the chart.
1. Edit [ums-secret.yaml](../configuration/ums-secret.yaml)
2. For ibm-dba-ums-secret specify adminUser, adminPassword, sslKeystorePassword, jwtKeystorePassword, teamserverClientID, teamserverClientSecret and ltpaPassword
3. For ibm-dba-ums-db-secret specify oauthDBUser/outhDBPassword and tsDBUser/tsDBPassword.
4. For ibm-dba-ums-ltpa-creation-secret do nothing. Configuration will be performed during LTPA creation.
5. Save ums-secret.yaml
6. In a shell run this command to create the required secrets.

```bash
oc create -f ums-secret.yaml
```

**Note:** Secret names need to be passed to the chart via the global.ums.adminSecretName, global.ums.dbSecretName and global.ums.ltpaSecretName properties.

### Persistent Volume
This is optional. As this is the instruction for a test deployment of UMS, Persistent Volume configuration is not covered. A persistent volume is only required in order to mount
* JDBC drivers for a database other than Db2.
* custom truststore for connecting to LDAP securely
* custom binaries required by your Liberty configuration (such as a .jar file for a Trust Association Interceptor).

## Install the chart

### Download PPA and load images to the content registry
Follow instructions to download User Management Service images and loadimages.sh file in [Download PPA and load images](https://github.com/icp4a/cert-kubernetes/blob/master/README.md#step-2-download-a-product-package-from-ppa-and-load-the-images)

The following commands need to be executed from inside the cluster (e.g. on master machine) and assume that you are already logged-in to Red Hat OpenShift using `oc login`:

```bash
git clone https://github.com/icp4a/cert-kubernetes.git
cd cert-kubernetes
docker login $(oc registry info) -u <ADMINISTRATOR> -p $(oc whoami -t)
scripts/loadimages.sh -p ~/Downloads/<PPA-ARCHIVE>.tgz -r $(oc registry info)/umsproject
```
When finished, you see a message similar to:

```
Docker images push to docker-registry.default.svc:5000/umsproject completed, and check the following images in the Docker registry:
     -  docker-registry.default.svc:5000/umsproject/ums:19.0.2
     -  docker-registry.default.svc:5000/umsproject/dba-keytool-initcontainer:19.0.2
     -  docker-registry.default.svc:5000/umsproject/dba-keytool-jobcontainer:19.0.2
```
Those image names must match the images section in `myvalues.yaml`.

Check whether the images have been pushed correctly to the registry.

```bash
oc get is
```

The results should look like this:
```bash
NAME                        DOCKER REPO                                                             TAGS        UPDATED
dba-keytool-initcontainer   docker-registry.default.svc:5000/umsproject/dba-keytool-initcontainer   19.0.2      19 hours ago
dba-keytool-jobcontainer    docker-registry.default.svc:5000/umsproject/dba-keytool-jobcontainer    19.0.2      19 hours ago
ums                         docker-registry.default.svc:5000/umsproject/ums                         19.0.2      19 hours ago
```

### Download helm chart and customize values.yaml
1. Download the helm chart [ibm-dba-ums-prod-1.0.0.tgz](../helm-charts/ibm-dba-ums-prod-1.0.0.tgz)
2. In a shell extract the downloaded package
```bash
tar -xvf ibm-dba-ums-prod-1.0.0.tgz
```
3. Review `values.yaml` and the `myvalues.yaml` file for your release to override defaults where necessary and to specify values for settings without defaults. Review `README.md` inside the helm chart for more details on the individual settings. Make sure to set the `global.ums.isOpenShift` parameter to `true`. This ensures required configuration for the pod's container security context.

This is a sample `myvalues.yaml` file using sample values from this guide.

```yaml
global:
  isOpenShift: true
  ums:
    hostname: ums-hostname #replace with your own hostname
    adminSecretName: ibm-dba-ums-secret
    dbSecretName: ibm-dba-ums-db-secret
    ltpaSecretName: ibm-dba-ums-ltpa-creation-secret
    serviceType: Ingress

# UMS Docker images
images:
  ums: docker-registry.default.svc:5000/umsproject/ums:19.0.2
  initTLS: docker-registry.default.svc:5000/umsproject/dba-keytool-initcontainer:19.0.2
  ltpa: docker-registry.default.svc:5000/umsproject/dba-keytool-jobcontainer:19.0.2

# UMS certificate secret
tls:
  tlsSecretName: ibm-dba-ums-tls

# UMS OAuth config
oauth:
  database: # replace with your own db settings
    type: db2
    name: umsdb
    host: umsdb-ibm-db2oltp-dev-db2.db2
    port: 50000
  # for demonstration purposes, we reuse the container TLS certificate to sign JWT tokens, you can create and refer to a dedicated secret here
  jwtSecretName: ibm-dba-ums-tls

# UMS Team Server database config
teamserver:
  database: # replace with your own db settings
    type: db2
    name: umsdb
    host: umsdb-ibm-db2oltp-dev-db2.db2
    port: 50000
```

### Use helm to create the release templates
After having created all prerequisites and customized `myvalues.yaml`, you can run

```bash
helm template -f myvalues.yaml -n cp4a-ums ibm-dba-ums-prod-1.0.0.tgz --output-dir cp4a-ums
```

to create the kubernetes release yaml files into a directory called `cp4a-ums`. Then apply the files in the Red Hat OpenShift cluster using

```bash
oc apply -R -f cp4a-ums
```

The command returns within seconds, summarizing the resources that were created in the cluster.

### Create a route to expose User Management Service

To expose the User Management Service release to the public you need to create a route in the Red Hat OpenShift cluster. The command create a route using SSL/TLS re-encrypt option. With this option the Red Hat OpenShift router will terminate the SSL connection and re-encrypt the traffic using the User Management Service TLS Certificate internally. For that we need to provide the User Management Service TLS Certificate as generated above.

```bash
oc create route reencrypt ums-route --hostname=ums-hostname --path=/ --service=cp4a-ums-ibm-dba-ums --dest-ca-cert=tls.crt
```

## Verify UMS installation
After the Red Hat OpenShift 3.11 cluster completes the creation of resources and starting of pods, you can access User Management Service for basic function testing.

Use the following command to observe the current installation and pod starting status: `oc get pods`

During installation / startup, the status shows 0 ready pods.
```bash
oc get pods
NAME                                                 READY     STATUS      RESTARTS   AGE
cp4a-ums-ibm-dba-ums-76d48486f5-4g9l6                0/1       Running     0          45s
cp4a-ums-ibm-dba-ums-76d48486f5-wlfjv                0/1       Running     0          45s
cp4a-ums-ibm-dba-ums-ltpa-creation-job-32881-czhqr   0/1       Completed   0          45s
```

Once the pods respond to readiness probes, the status will be updated:
```bash
oc get pods
NAME                                                READY     STATUS      RESTARTS   AGE
cp4a-ums-ibm-dba-ums-8f9cc7c54-46mjw                 1/1       Running     0          33m
cp4a-ums-ibm-dba-ums-8f9cc7c54-ml8bz                 1/1       Running     0          33m
cp4a-ums-ibm-dba-ums-ltpa-creation-job-32881-czhqr   0/1       Completed   0          33m
```

**Note:** The <release>-ibm-dba-ums-ltpa-creation-job-<random>-<random> pod is expected in completed state.

You can view the configured route for accepting inbound HTTP traffic:
```bash
oc get route

NAME               HOST/PORT     PATH   SERVICES               PORT    TERMINATION   WILDCARD
ums-route          ums-host      /      cp4a-ums-ibm-dba-ums   https   reencrypt     None
```

Use the host of this route to access `https://<ums-host>/ums` to view the login page. Log in as the administrative user you specified in `ums-secret.yaml` or any user of a connected LDAP if you included an LDAP configuration in `myvalues.yaml` customXML.

Congratulations, your User Management Service is now deployed on Red Hat OpenShift 3.11.
