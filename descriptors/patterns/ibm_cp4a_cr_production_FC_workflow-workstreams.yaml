###############################################################################
#
# Licensed Materials - Property of IBM
#
# (C) Copyright IBM Corp. 2022, 2024. All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: workflow-workstreams
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 24.0.0
spec:
  appVersion: 24.0.0

  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""

  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:

    ## Business Automation Workflow (BAW) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_baw_license: "<Required>"

    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_fncm_license: "<Required>"

    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"



    ## The deployment context, which has a default value of "CP4A".  Unless you are instructed to change this value or
    ## know the reason to change this value, please leave the default value.
    sc_deployment_context: "CP4A"

    ## All CP4A components must use/share the image_pull_secrets to pull images
    image_pull_secrets:
    - ibm-entitlement-key

    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io

    ## Specify the RunAsUser for the security context of the pod.  This is usually a numeric value that corresponds to a user ID.
    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is optional. It is not supported on OCP and ROKS.
    sc_run_as_user:

    ## If your Openshift cluster is configured for Hugepages and you want the applicable deployment resources to consume Hugepages.
    ## You must set "true" for sc_hugepages.enabled. Default is "false".
    ## You must set type for "Hugepages" like hugepages-2Mi or hugepages-1Gi. Default is "hugepages-2Mi".
    ## You must set size for value which is suitable for Openshift cluster.
    sc_hugepages:
      enabled: false
      type: ""
      value: ""

    ## Optional setting for secure computing mode (seccomp) profile for CP4A containers.  The default seccomp profile is RuntimeDefault on OCP 4.11 (k8s v1.24) or higher. seccomp profile won't be created on OCP 4.10 (k8s v1.23) or lower.
    ## For more information on seccomp please refer to https://kubernetes.io/docs/tutorials/security/seccomp/ and https://docs.openshift.com/container-platform/4.12/security/seccomp-profiles.html
    ## NOTE: Defining a custom, localhost seccomp profile that is stricter than the default RuntimeDefault profile may cause our pods fail to start.  This custom profile should be created at the worker nodes.
    sc_seccomp_profile:
    #  type: # RuntimeDefault, Localhost, Unconfined
    #  localhost_profile: # Local path of custom seccomp profile when type `Localhost` is used. The custom profile must be accessible by the pod and must exist locally on all worker nodes.  For example: `/profiles/fine-grained.json`.

    images:
      keytool_job_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-jobcontainer
        tag: "24.0.0-IF001"
      dbcompatibility_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-dbcompatibility-initcontainer
        tag: "24.0.0-IF001"
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-initcontainer
        tag: "24.0.0-IF001"
      umsregistration_initjob:
        repository: cp.icr.io/cp/cp4a/baw/dba-umsregistration-initjob
        tag: "24.0.0-IF001"

      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent

    ## Used to sign all CP4A internal certificates for internal services communications. In most cases, this value should not be changed.
    ## All CP4A components must use/share the root_ca_secret in order for integration
    root_ca_secret: icp4a-root-ca

    ## Shared secret containing a wildcard certificate (and concatenated signers) to be used by all routes, unless overwritten for a specific component route.
    ## If this is not defined, all external routes will be signed with root_ca_secret.
    ## Starting with CP4BA 21.0.3 release, this parameter only applies to non-OCP deployments. For OCP, all external traffic is routed via a
    ## common front door in Platform UI so custom TLS certificates must be configured in AutomationUIConfig. Please refer
    ## to https://www.ibm.com/docs/en/cloud-paks/1.0?topic=foundation-custom-resources#automationuiconfig for more information.
    external_tls_certificate_secret:

    ## CP4A patterns or capabilities to be deployed.  This CR represents the "workflow-workstreams" pattern, which includes the following
    ## mandatory components: ban(Business Automation Navigator), ums (User Management Service), rr (Resource registry), app_engine( Application Engine) and optional components: bai,elasticsearch
    sc_deployment_patterns: workflow-workstreams

    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.
    ## The optional components are: bai,elasticsearch,kafka
    ## To enable Kafka services in your workflow automations, add kafka to sc_optional_components.
    sc_optional_components:

    ## The deployment type as selected by the user.  Possible values are: Starter and Production.
    sc_deployment_type: Production

    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform:

    sc_egress_configuration:
      ## Required. Enable or disable egress access to external systems.
      ## If "sc_restricted_internet_access" is defined and has no value set, then default will be "true".
      ## If "sc_restricted_internet_access" is not defined (e.g., in the case of upgrade, the existing CR will not have sc_restricted_internet_access), then "sc_restricted_internet_access" will be "false"
      sc_restricted_internet_access: true
      ## Optional.  Kubernetes API server namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default are "openshift-kube-apiserver", "openshift-apiserver" for OCP and ROKS.
      sc_api_namespace:
      ## Optional.  Kubernetes API server port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## Default are 443,6443 for OCP and ROKS
      sc_api_port:
      ## Optional.  Kubernetes DNS service namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default is "openshift-dns" for OCP and ROKS
      sc_dns_namespace:
      ## Optional.  Kubernetes DNS service port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## Default are 53,5353 for OCP and ROKS
      sc_dns_port:

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## For ROKS Ingress, provide TLS secret name for Ingress controller. If you are not using ROKS, comment out this line.
    sc_ingress_tls_secret_name: <Required>

    ## This is the deployment hostname suffix, this is optional and the default hostname suffix will be used as {meta.namespace}.router-canonicalhostname
    # sc_deployment_hostname_suffix: "{{ meta.namespace }}.<Required>"

    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []


    ## This is necessary if you want to use your own JDBC drivers and/or need to provide ICCSAP drivers.  If you are providing multiple JDBC drivers and ICCSAP drivers,
    ## all the files must be compressed in a single file.
    ## First you need to package your drivers into a compressed package in the format of "saplibs/drivers_files" and/or
    ## "jdbc/db2|oracle|postgresql|sqlserver/driver_files". For example, if you are providing your own DB2 and Oracle JDBC drivers and ICCSAP drivers, then the compressed
    ## file should have the following structure and content:
    ##   /jdbc/db2/db2jcc4.jar
    ##   /jdbc/db2/db2jcc_license_cu.jar
    ##   /jdbc/oracle/ojdbc8.jar
    ##   /saplibs/libicudata.so.50
    ##   /saplibs/...
    ## Then you need to put the compressed package on an anonymously accessible web server and provide the link here.
    ## The CR can handle .zip files using unzip as well as .tar, .tar.gz, .tar.bz2, .tar.xz. Does not handle .gz files, .bz2 files, .xz, or .zst files that do not contain a .tar archive.
    sc_drivers_url:

    ## Shared encryption key secret name that is used for Workflow or Workstream Services and Process Federation Server integration.
    ## This secret is also used by Workflow and BAStudio to store AES encryption key.
    encryption_key_secret: ibm-iaws-shared-key-secret

    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores,
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section
    ## is defined with the required parameters in the CR (below) and sc_content_initialization is set to "true" (or the parameter doesn't exist), then the initialization will occur.
    ## However, if sc_content_initialization is set to "false", then the initialization will not occur (even with the "initialize_configuration" section defined)
    ## For Workflow and Workstreams, by default sc_content_initialization is set to "true" with "initialize_configuration"section filled.
    ## If you already initialized content or want to upgrade, please set sc_content_initialization to "false" before you apply the CR.
    sc_content_initialization: true

    ## Enable/disable the ECM (FNCM) / BAN verification (e.g., creation of test folder, creation of test document,
    ## execution of CBR search, and creation of Navigator demo repository and desktop).  If the "verify_configuration"
    ## section is defined in the CR and sc_content_verification is set to true, then the verification will occur.  Note that if you are upgrading or
    ## migrating, set this parameter to "false" since the env has been previously verified.
    sc_content_verification: false

    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "production" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.
    ## sc_block_storage_classname is for Zen, Zen requires/recommends block storage (RWO) for metastoreDB
    storage_configuration:
      sc_slow_file_storage_classname: "<Required>"
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"
      sc_block_storage_classname: "<Required>"

    ## The CPE container and other components that use HTTP Basic Authentication are configured to use the OAuth JaaS loginModule
    ## to remove all remaining LDAP dependencies by allowing username/password credentials to be converted into an OAuth token for
    ## authentication. When you are upgrading from a release prior to CP4BA 22.0.2 to 22.0.2 or later, or when
    ## you are migrating FileNet Content Manager on-prem or standalone deployment to IBM Cloud Pak for Business Automation (CP4BA),
    ## you must set "sc_skip_ldap_config: false".  If you are performing fresh install using 23.0.2-IF004 or later, you can also set
    ## "sc_skip_ldap_config: false" in order to have the FileNet Content Manager P8 domain to be configured with direct LDAP bind
    ## as opposed to the default SCIM configuration.
    # sc_skip_ldap_config: true

    ## Enable/disable FIPS mode for the deployment (default value is "false")
    ## Note: If set as "true", in order to complete enablement of FIPS for CP4BA, please refer to "FIPS wall" configuration in IBM documentation.. This parameter only applies to OpenShift Container Platform deployments on Red Hat Enterprise Linux (RHEL) Server - x86
    enable_fips: false

    ## If a cluster is configured for multiple availability zones (AZ) and the parameter sc_is_multiple_az is set to true, then the pods are spread across all the zones.
    ## By default, the sc_is_multiple_az parameter is set to false. When the value is set to true, the pods of the CP4BA deployment are spread across your user-defined topology domains.
    ## The pod API includes a spec.topologySpreadConstraints field, which is used by the CP4BA operator to configure it.
    sc_is_multiple_az: false

  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory" or "Custom"
    lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "<Required>"

    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute. Semicolon-separated list that must include the first RDN user distinguished names. One possible value is "*:uid" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "<Required>"

    ## The LDAP recursive search. Set true or false to enable or disable recursive searches.
    lc_ldap_recursive_search: false

    ## The maximum search results. Specify a higher value if you expect more search results.
    lc_ldap_max_search_results: 4500

    ## The lc_ldap_precheck parameter is used to enable or disable LDAP connection check.
    ## If set to "true", then LDAP connection check will be enabled.
    ## if set to "false", then LDAP connection check will not be enabled.
    # lc_ldap_precheck: true

    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
    #   lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
    # custom:
    #  lc_user_filter: "(&(objectClass=person)(cn=%v))"
    #  lc_group_filter:  "(&(objectClass=group)(cn=%v))"

    ## This section allows to enhance the ldap configuration for the UMS SCIM capability. If lc_user_filter or lc_group_filter cannot handle a custom LDAP filter for user or group searches this section should be enabled.
    ## optional: enables the liberty ldapEntityType configuration and disables the usage of lc_user_filter, lc_group_filter, lc_ldap_group_member_id_map, lc_ldap_user_name_attribute and lc_ldap_group_name_attribute in the UMS capabilities.
    ## for detailed information about the ldapEntityType, loginProperty and groupProperties  parameters please see the liberty documentation: https://www.ibm.com/docs/en/was-liberty/nd?topic=configuration-ldapregistry
    ## default is false
    lc_use_ldap_entity_type:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## default is uid
    lc_ldap_login_property:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_user:
      object_class:
      search_base:
      search_filter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_group:
      object_class:
      search_base:
      search_filter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_group_properties:
      # member_attribute:
        # The name of the member. Required if member_attribute is set
        # name:
        # The name of the object class. Required member_attribute is set
        # object_class:
        ## the scope options are: all, direct, nested
        # scope:
      #membership_attribute:
        # The name of the membership. Required if membership_attribute is set
        # name:
        ## the scope options are: all, direct, nested
        # scope:

    ## This is to add customized IAM SCIM LDAP attributes for this LDAP configuration, If you only add 'scim_configuration_iam', we will create SCIM LDAP attributes mapping using default values and the default value meant for IBM Security Directory Server only. Comment the whole section if you don't want this to be configured.
    # scim_configuration_iam:
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   user_unique_id_attribute: dn
    #   user_external_id_attribute: dn
    #   user_emails_attribute: mail
    #   user_name_attribute: uid
    #   user_display_name_attribute: cn
    #   user_groups_attribute: memberOf
    #   user_object_class_attribute: person
    #   user_principal_name_attribute: uid
    #   user_given_name_attribute: cn
    #   user_family_name_attribute: sn
    #   user_full_name_attribute: cn
    #   ## Optional:  Uncomment 'user_custom_mapping' and add any custom mapping below
    #   # user_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   group_unique_id_attribute: dn
    #   group_external_id_attribute: dn
    #   group_display_name_attribute : cn
    #   group_members_attribute: member
    #   group_object_class_attribute: groupOfNames
    #   group_name_attribute: cn
    #   group_principal_name_attribute: cn
    #   ## Optional:  Uncomment 'group_custom_mapping' and add any custom mapping below
    #   # group_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid

  ## The beginning section of multi ldap configuration for CP4BA
  # ldap_configuration_<id_name>:
    #lc_ldap_id: <id_name>
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory" or "Custom"
    #lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    #lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    #lc_ldap_port: "<Required>"

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    #lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    #lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    #lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute.  One possible value is "*:cn" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    #lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    #lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    #lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    #lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    #lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))" for TDS and AD
    #lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    #lc_ldap_group_member_id_map: "<Required>"

    ## The lc_ldap_precheck parameter is used to enable or disable LDAP connection check.
    ## If set to "true", then LDAP connection check will be enabled.
    ## if set to "false", then LDAP connection check will not be enabled.
    # lc_ldap_precheck: true

    ## Uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds) or custom for other LDAP type) accordingly.
    #ad:
    #  lc_ad_gc_host: "<Required>"
    #  lc_ad_gc_port: "<Required>"
    #  lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
    #  lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    #tds:
    #  lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #  lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
    #custom:
    #  lc_user_filter: "(&(objectClass=person)(cn=%v))"
    #  lc_group_filter:  "(&(objectClass=group)(cn=%v))"

    ## This is to add customized IAM SCIM LDAP attributes for this LDAP configuration, If you only add 'scim_configuration_iam', we will create SCIM LDAP attributes mapping using default values and the default value meant for IBM Security Directory Server only. Comment the whole section if you don't want this to be configured.
    # scim_configuration_iam:
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   user_unique_id_attribute: dn
    #   user_external_id_attribute: dn
    #   user_emails_attribute: mail
    #   user_name_attribute: uid
    #   user_display_name_attribute: cn
    #   user_groups_attribute: memberOf
    #   user_object_class_attribute: person
    #   user_principal_name_attribute: uid
    #   user_given_name_attribute: cn
    #   user_family_name_attribute: sn
    #   user_full_name_attribute: cn
    #   ## Optional:  Uncomment 'user_custom_mapping' and add any custom mapping below
    #   # user_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   group_unique_id_attribute: dn
    #   group_external_id_attribute: dn
    #   group_display_name_attribute : cn
    #   group_members_attribute: member
    #   group_object_class_attribute: groupOfNames
    #   group_name_attribute: cn
    #   group_principal_name_attribute: cn
    #   ## Optional:  Uncomment 'group_custom_mapping' and add any custom mapping below
    #   # group_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid

  ## The idp_iam_configuration is meant when you have an identity provider configured in iam that isn't a directory provider service
  ## Such as Okta or AzureAD configured in IAM as the identity provider.
  ## Set the idp_id to the name giving to the identity provider configured in IAM.
  ## Set the idp_type.  Supported types are okta or azuread.
  ## idp_allow_email_or_upn_short_names by default is true. Only specify idp_allow_email_or_upn_short_names: false if
  ## email or upn short name is not used to login
  #idp_iam_configuration:
  #  - idp_id: <idp_name>
  #    idp_type: okta (or azuread)
  #    idp_allow_email_or_upn_short_names: true (optional - default value is true)

  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle/PostgreSQL.
    dc_ssl_enabled: true
    ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
    ## If set to "true", then CPE/Navigator database connection check will be enabled.
    ## if set to "false", then CPE/Navigator database connection check will not be enabled.
   # database_precheck: true
    ## The database configuration for the GCD datasource for CPE
    dc_gcd_datasource:
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for a GCD database, set this parameter to true
      dc_use_postgres: false
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".
      dc_database_type: "<Required>"
      ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
      dc_common_gcd_datasource_name: "FNGCDDS"
      ## The GCD XA datasource name. The default value is "FNGCDDSXA".
      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_servername: "<Required>"
      ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_gcd_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15

      ## If the database type is Db2 HADR, then complete the rest of the parameters below.
      ## Provide the database server name or IP address of the standby database server.
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for the document object store (DOCS) datasource for CPE
    dc_os_datasources:
    ## Object store for FNDS DOCS. Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the GCD configuration above.
    - dc_database_type: "<Required>"
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for an OS database, set this parameter to true
      dc_use_postgres: false
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOCS non-XA datasource name.  The default value is "FNDSDOCS".
      dc_common_os_datasource_name: "FNDSDOCS"
      ## The DOCS XA datasource name.  The default value is "FNDSDOCSXA".
      dc_common_os_xa_datasource_name: "FNDSDOCSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter. This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for the target object store (TOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for an OS database, set this parameter to true
      dc_use_postgres: false
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The TOS non-XA datasource name.  The default value is "FNDSTOS".
      dc_common_os_datasource_name: "FNDSTOS"
      ## The TOS XA datasource name.  The default value is "FNDSTOSXA".
      dc_common_os_xa_datasource_name: "FNDSTOSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter. This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for the design object store (DOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for an OS database, set this parameter to true
      dc_use_postgres: false
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOS non-XA datasource name.  The default value is "FNDSDOS".
      dc_common_os_datasource_name: "FNDSDOS"
      ## The DOS XA datasource name.  The default value is "FNDSDOSXA".
      dc_common_os_xa_datasource_name: "FNDSDOSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter. This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for CPE, Operator will only add them as data source for CPE, won't create Object Store for these database connection.
    dc_cpe_datasources:
    #--------------------------------------------------------------------------------------------------------------------------------
    # This sections contains 1 CPE data source: Case History Store CPE data source
    # It is required when you want to enable case history emitter feature. Please uncomment it when enabling case history emitter
    #--------------------------------------------------------------------------------------------------------------------------------
    #   #CPE data source for Case History Store
    #   # Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the
    #   # GCD configuration above.
    # - dc_database_type: "<Required>"
    #   ## Provide the label for the CPE data source.  The default value is "os" if not defined.
    #   ## This label must match the secret you define in ibm-fncm-secret.
    #   ## If you define dc_os_label: "ch" , then your secret must be defined as:
    #   ## --from-literal=chDBUsername="<your db username>" --from-literal=chDBPassword="<your db password>".
    #   ## If all the CPE datasource databases share the same username and password, then dc_os_label value should be the same in all the datasource sections.
    #   dc_os_label: "ch"
    #   ## The XA datasource name.
    #   dc_common_cpe_xa_datasource_name: "CASEHISTORYDSXA"
    #   ## The non-XA datasource name.
    #   dc_common_cpe_datasource_name: "CASEHISTORYDS"
    #   ## Provide the database server name or IP address of the database server
    #   database_servername: "<Required>"
    #   ## Provide the name of the database for the CPE data source.  For example: "DS1DB"
    #   database_name: "<Required>"
    #   ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
    #   database_port: "<Required>"
    #   ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
    #   database_ssl_secret_name: "<Required>"
    #   ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
    #   dc_oracle_os_jdbc_url: "<Required>"
    #   ## Database connection name, database connection will be created according to your input
    #   dc_common_conn_name: "<Required>"
    #   ######################################################################################
    #   ## If the database type is "Db2HADR", then complete the rest of the parameters below.
    #   ## Otherwise, remove or comment out the rest of the parameters below.
    #   ######################################################################################
    #   dc_hadr_standby_servername: "<Required>"
    #   ## Provide the standby database server port.  For Db2, the default is "50000".
    #   dc_hadr_standby_port: "<Required>"
    #   ## Provide the validation timeout.  If not preference, keep the default value.
    #   dc_hadr_validation_timeout: 15
    #   ## Provide the retry internal.  If not preference, keep the default value.
    #   dc_hadr_retry_interval_for_client_reroute: 15
    #   ## Provide the max # of retries.  If not preference, keep the default value.
    #   dc_hadr_max_retries_for_client_reroute: 3
    #   ## Connection manager for a data source.
    #   connection_manager:
    #     ## Minimum number of physical connections to maintain in the pool.
    #     min_pool_size: 0
    #     ## Maximum number of physical connections for a pool.
    #     max_pool_size: 50
    #     ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
    #     max_idle_time: 1m
    #     ## Amount of time between runs of the pool maintenance thread.
    #     reap_time: 2m
    #     ## Specifies which connections to destroy when a stale connection is detected in a pool.
    #     purge_policy: EntirePool
  ########################################################################
  ########   IBM Business Automation Workflow configuration     ########
  ########################################################################
  baw_configuration:
  ## The baw_configuration is a list. You can deploy multiple instances of Workflow Server and assign different configurations for each instance.
  ## For each instance, baw_configuration.name and hostname must be assigned different values.
  ## Case Manager section "case" can be configured only in one Workflow Server instance.
  ## For each instance's database configuration, you can choose to use either different database instances, or one shared database instance. If you use a shared database instance, in Db2 or PostgreSQL, you must assign different database names (baw_configuration[x].database.database_name); in Oracle, you must assign different database users (the dbUser in the baw_configuration[x].database.secret_name).
  ## Each baw_configuration.name can consist of lowercase alphanumeric characters or '-', and must start and end with an alphanumeric character. Keep the instance name as short as possible.
  ## For baw_configuration.tls.tls_secret_name, if you choose to use a customized Workflow Server TLS certificate, ensure that each BAW instance has a different value.
  - name: instance1
    ## Whether the Business Automation Workflow instance hosts federated Process Portal and integrates with Intelligent Task Prioritization.
    host_federated_portal: false
    ## Workflow Server service type.
    service_type: "Route"
    ## Workflow Server hostname.
    hostname: ""
    ## Workflow Server port.
    port: 443
    ## Workflow Server node port.
    nodeport: 30026
    ## Workflow Server environment type. Possible values are Development, Test, Staging, and Production.
    env_type: "Production"
    ## Workflow Server capability.
    capabilities: "workflow,workstreams"
    ## Workflow Server replica count.
    ## The value takes priority when both profile size and replica properties are set
    replicas: 1
    ## Designate an existing LDAP user for the Workflow Server admin user.
    admin_user: "<Required>"
    ## The name of Workflow Server admin secret. This secret name is optional, if the secret name is null, default secret named {{ meta.name }}-<instance-name>-baw-admin-secret will be generated.
    admin_secret_name: "{{ meta.name }}-instance1-baw-admin-secret"
    ## Whether to use the built-in monitoring capability.
    monitor_enabled: false
    ## Enable/disable logging where logs can be sent to Elasticsearch, default is 'false'
    logging_enabled: false
    ## Name prefix of elasticsearch index where server logs are stored, default is server deployment name
    mon_elastic_search_index_prefix: ""
    # To enable "data collector and data indexer" function, you need add opensearch in shared_configuration.sc_optional_components and opensearch is deployed.
    # You could also provide your own elasticsearch or opensearch leveraging parameters: elasticsearch.endpoint and elasticsearch.admin_secret_name.
    full_text_search:
      enable: false
    # Elasticsearch/Opensearch information
    # Required only when you want to use external Elasticsearch or OpenSearch for "data collector and data indexer" function.
    elasticsearch:
      ## Endpoint of external elasticsearch/opensearch, such as: https://<external_es_host>:<external_es_port>.
      endpoint:
      ## The external elasticsearch/opensearch administrative secret that contains the keys: username and password.
      ## If your instance does not have basic authentication, leave this parameter empty.
      admin_secret_name:
    # Set PFS information if you have PFS installed and want to federate Workflow Server to it.
    process_federation_server:
      hostname:
      port:
      context_root_prefix:
    ## Set securityContext for BAW deployment to skip SELinux relabeling
    security_context:
      ## This can take an array of key value pairs to assign SELinux labels to a Container, for example
      ## selinux_options:
        ## level: "s0:c123,c456"
        ## type: "spc_t"
      selinux_options:
      # Defines behavior for changing ownership and permission of the volume before being exposed inside a Pod. This field has two possible values (Always,OnRootMismatch)
      # For example fs_groupchangepolicy: "OnRootMismatch"
      fs_groupchangepolicy:

    # Optional: You can specify a profile size for BAW Server if different from BAW (see shared_configuration.sc_deployment_profile_size).  In other words,
    # you can override "shared_configuration.sc_deployment_profile_size" with "deployment_profile_size" defined here.
    # The valid values are small, medium, large - default is small.  The resources in this file are reflecting a "small" profile.
    #deployment_profile_size: "small"

    ## Required if you implemented your own portal. For example, https://portal.mycompany.com.
    customized_portal_endpoint: ""

    ## External connection timeout.
    external_connection_timeout: ""

    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use a customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use a customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:
    tls:
      ## Workflow Server TLS secret that contains tls.key and tls.crt.
      ## If you want to use a customized Workflow Server TLS certificate, ensure it is signed by the CA in shared_configuration.root_ca_secret.
      ## If you do not want to use a customized Workflow Server TLS certificate, leave it empty.
      tls_secret_name:
      ## Workflow Server TLS trust list.
      ## You might specify a list of secrets, every secret stores a trusted CA
      ## Use command `kubectl create secret generic baw_custom_trust_ca_secret1 --from-file=tls.crt=./ca1.crt` to generate the secret.
      tls_trust_list:
      ## Secret to store your custom trusted keystore (optional). The type for the keystore must be JKS or PKCS12. All certificates from the keystore are imported into the trust keystore of the Workflow Server.
      ## You might run the following sample command to create the secret:
      ## `kubectl create secret generic baw_custom_trusted_keystore_secret --from-file=truststorefile=./trust.p12 --from-literal=type=PKCS12  --from-literal=password=WebAS`
      tls_trust_store:
    image:
      ## Workflow Server (Process Server) image repository URL.
      repository: cp.icr.io/cp/cp4a/baw/workflow-server
      ## Image tag for Workflow Server container.
      tag: "24.0.0-IF001"
      ## Pull policy for Workflow Server container. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
      pull_policy: IfNotPresent
    upgrade_job:
      ## Workflow Server database handling image repository URL.
      repository: cp.icr.io/cp/cp4a/baw/workflow-server-dbhandling
      ## Workflow Server database handling image repository tag.
      tag: "24.0.0-IF001"
      ## Pull policy for database handling. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
      pull_policy: IfNotPresent
      ## The trace Specification for database handling job, the trace is disabled by default, you can enable it when the job fails, the sample trace specification is WLE.*=all:com.ibm.bpm.*=all:com.ibm.workflow.*=all
      trace_specification: ""

    ## The database configuration for Workflow Server
    database:
      ##Whether to use EDB. If you set it to true, just set db_cert_secret_name, type, server_name, database_name, port and secret_name as "", and set enable_ssl to true.
      dc_use_postgres: false
      ## Whether to enable Secure Sockets Layer (SSL) support for the Workflow Server database connection.
      enable_ssl: true
      ## Secret name for storing the database TLS certificate when an SSL connection is enabled, if it's client authentication for PostgreSQL DB,
      # The secret will store the database client key and client certificate and ca certification.
      ## Required only when enable_ssl is true. If enable_ssl is false, comment out this line.
      db_cert_secret_name: "<Required>"
      ## Workflow Server database type. Possible values are: db2, oracle, postgresql
      type: "<Required>"
      ## Workflow Server database server name. It must be an accessible address, such as IP, hostname, or Kubernetes service name.
      ## This parameter is required.
      server_name: "<Required>"
      ## Workflow Server database name. This parameter is required.
      database_name: "<Required>"
      ## Workflow Server database port. This parameter is required. For DB2, the default value is "50000"
      port: "<Required>"
      ## Workflow Server database secret name. This parameter is required.
      ## apiVersion: v1
      ## kind: Secret
      ## metadata:
      ##   name: ibm-baw-wfs-server-db-secret
      ## type: Opaque
      ## data:
      ##   dbUser: <DB_USER>
      ##   password: <DB_USER_PASSWORD>
      secret_name: "<Required>"
      ## Oracle and PostgreSQL database connection string.
      ## If the database type is Oracle, provide the Oracle database connection string. For example, jdbc:oracle:thin:@//<oracle_server>:1521/orcl.
      ## If the database type is PostgreSQL, this parameter is optional, you can choose inputs server_name, database_name, and port with or without this parameter here. If you do not need this parameter when PostgreSQL, remove or comment this parameter.
      ## In any other cases, remove or comment this parameter.
      jdbc_url: "<Required>"
      ## Workflow Server database schema name. This parameter is optional. If not set, the schema name is the same as database user name.
      ## This parameter is only supported by DB2 and PostgreSQL. For DB2, the schema name is case-sensitive, and must be specified in uppercase characters.
      current_schema: ""
      ## Whether to use custom JDBC drivers. set it as true if you don't want use embedded jdbc drivers and don't specify sc_drivers_url.
      use_custom_jdbc_drivers: false
      ## If use_custom_jdbc_drivers is set to true, input the name of the persistent volume claim (PVC) that binds to the persistent volume (PV) where the custom JDBC driver files are stored.
      ## If use_custom_jdbc_drivers is set to false, remove or comments this parameter.
      custom_jdbc_pvc: ""
      ## The comma or space separated list of custom JDBC driver files. If the custom JDBC driver files are not specified, all files under custom_jdbc_pvc will be loaded.
      jdbc_driver_files: ""
      ## Workflow Server database connect pool maximum number of physical connections.
      cm_max_pool_size: 200
      dbcheck:
        ## The maximum wait time (seconds) to check the database intialization status. The server fails to start after wait_time.
        wait_time: 900
        ## The interval time (seconds) to check the database initialization status before the database is ready and bootstrapped with system data.
        interval_time: 15
      hadr:
        ## Database standby host for high availability disaster recovery (HADR)
        ## To enable database HADR, configure both standby host and port.
        standbydb_host:
        ## Database standby port for HADR. To enable database HADR, configure both standby host and port.
        standbydb_port:
        ## Retry interval for HADR
        retryinterval:
        ## Maximum retries for HADR
        maxretries:

    ## Workflow center configuration
    workflow_center:
      ## The URL of workflow Center
      url: ""
      ## The secret name of workflow center that contains username and password.
      ## apiVersion: v1
      ## kind: Secret
      ## metadata:
      ##  name: ibm-baw-wc-secret
      ## type: Opaque
      ## stringData:
      ##  username: deadmin
      ##  password: deadmin
      secret_name: ""
      ## Heartbeat interval (seconds) to connect to Workflow Center.
      heartbeat_interval: 30
      ## URL that is used by Workflow Center to link to the web Process Designer. For example, https://hostname:port/WebPD.
      webpd_url: ""

    ## The configurations for content integration for attachment in process
    content_integration:
      init_job_image:
        ## Image name for content integration container.
        repository: cp.icr.io/cp/cp4a/baw/iaws-ps-content-integration
        ## Image tag for content integration container.
        tag: "24.0.0-IF001"
        ## Pull policy for content integration container. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
        pull_policy: IfNotPresent
      ## Domain name for content integration. The value must be the same as initialize_configuration.ic_domain_creation.domain_name.
      domain_name: "P8DOMAIN"
      ## Object Store name for content integration.
      ## The value must be an existing object store in CPE.
      ## If use initialize_configuration for the object store initialization, the value must be one of initialize_configuration.ic_obj_store_creation.object_stores.
      object_store_name: "DOCS"
      ## Admin secret for connecting to Content Platform Engine (CPE). This parameter is optional. If not set, it will autodetect CPE's admin secret in the same namespace.
      cpe_admin_secret: ""


    ## The configuration for case
    case:
      init_job_image:
        ## Image name for CASE init job container.
        repository: cp.icr.io/cp/cp4a/baw/workflow-server-case-initialization
        ## Image tag for CASE init job container.
        tag: "24.0.0-IF001"
        ## Pull policy for CASE init job container. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
        pull_policy: IfNotPresent

      ## Domain name for CASE. The value must be the same as initialize_configuration.ic_domain_creation.domain_name.
      domain_name: "P8DOMAIN"
      ## Design Object Store name of CASE.
      ## The value must be the same as the oc_cpe_obj_store_symb_name value of one of the object stores defined in initialize_configuration.ic_obj_store_creation.object_stores.
      object_store_name_dos: "DOS"

      tos_list:
      ## The tos_list is a list. You can deploy multiple Target Object Stores.
      ## For each Target Object Store, the object_store_name value must be the same as the oc_cpe_obj_store_symb_name value of one of the object stores defined in initialize_configuration.ic_obj_store_creation.object_stores.
      - object_store_name: "TOS"
        ## Connection point name for Target Object Store.
        ## See initialize_configuration.ic_obj_store_creation.object_stores[x].oc_cpe_obj_store_workflow_pe_conn_point_name.
        ## If oc_cpe_obj_store_workflow_pe_conn_point_name is not specified explicitly, the default value is pe_conn_<TOS_OS_DB_NAME>.
        connection_point_name: "cpe_conn_tos"
        ## Navigator desktop name for Target Object Store.
        desktop_id: "baw"
        ## Name of the target environment or project area to register with the case components and associate with an IBM Content Navigator desktop.
        target_environment_name: "target_env"
        ## Whether to use the Target Object Store as the default Target Object Store.
        ## If none of the Target Object Stores is set as default, the first one in the tos_list will be set as the default Target Object Store.
        is_default: true

      ## Persistent volume claim (PVC) name for case network shared directory.
      ## This parameter must be set to the same value as the Business Automation Navigator pvc_for_icn_pluginstore parameter.
      ## If navigator_configuration.datavolume.existing_pvc_for_icn_pluginstore is not specified explicitly, the default value is icn-pluginstore.
      network_shared_directory_pvc: "{{ navigator_configuration.datavolume.existing_pvc_for_icn_pluginstore.name | default('icn-pluginstore', true) }}"

      ## Custom package names for installing custom packages, where the value format is similar to package1.zip, package2.zip.
      custom_package_names: ""

      ## Custom extension names for installing custom packages, where the value format is similar to extension1.zip, extension2.zip.
      custom_extension_names: ""

      ## Number of seconds before a newly added or modified asset will take effect in the Case Client. The value must be an integer, e.g. "100."
      ## The default value will be used if it is not set.
      cpe_metadata_cache_time_to_live: ""

      ## JVM options separated with spaces for case init job, for example: -Dtest1=test -Dtest2=test2.
      jvm_customize_options: ""

      ## The event emitter settings if you want to enable Case Event Emitter. You can configure multiple Target Object Stores if you want to enable the Case Event Emitter for them. The following example shows sample values:
      ## event_emitter:
      ## - tos_name: TOS1Name
      ##   connection_point_name: tos1_connection_point_name
      ##   date_sql: 20200630T002840Z
      ##   logical_unique_id: bawinst1
      ##   solution_list: SampleSolution1,SampleSolution2
      ## - tos_name: TOS2Name
      ##   connection_point_name: tos2_connection_point_name
      ##   date_sql: 20220930T002710Z
      ##   logical_unique_id: bawinst1
      ##   solution_list: SampleSolution3,SampleSolution4
      event_emitter:
        ## Target Object Store name of CASE
      - tos_name: "BAWINS1TOS"
        ## Connection point name for Target Object Store.
        connection_point_name: "cpe_conn_tos"
        ## Creation date of the events.
        ## The emitter starts processing the events from that date. If a bookmark exists, the emitter ignores this parameter and processes the events from the bookmark.
        date_sql: "<Required>"
        ## An 8-character alphanumeric string without underscores.
        ## This value is always required. While processing, the emitter tracks the events that are processed by using the Content Engine Audit Processing Bookmark with a display name that is based on this value.
        ## Therefore, if the emitter is restarted and if the bookmark exists, the emitter processes the events from the last bookmark.
        logical_unique_id: "<Required>"
        ## Comma-separated list of all the case solution names that need to be processed, e.g "solution1, solution2". Default value is "*". Add all the solutions that you want to be processed before you deploy the Case event emitter.
        solution_list: "*"
        ## Comma-separated list of all the case types that need to be processed, e.g "casetype1, casetype2". Default value is "".
        casetype_list: ""
        ## Case event emitter batch size. Default value is 1000.
        emitter_batch_size: 1000
        ## Whether to process FileNet Process Engine events in addition to IBM Business Automation Workflow events. Default value is true.
        process_pe_events: true

      ## The event emitter settings if you want to enable Case History Emitter. The following example shows sample values:
      ## case_history_emitter:
      ##   enable: true
      ##   dc_common_cpe_datasource_name: "CASEHISTORYDS"
      ##   case_history_store_schema_name: "CHSCHEMA"
      ##
      case_history_emitter:
        ## To enable Case History Emitter, this parameter must be set to true.
        enable: false
        ## The name of the non-XA datasource of Case History Store (from dc_common_cpe_datasource_name in the dc_cpe_datasources section)
        ## This value is always required. To enable Case History Emitter, add the Case History database configuration in the dc_cpe_datasources section, and specify the non-XA datasource name(dc_common_cpe_datasource_name) as the value of this parameter.
        dc_common_cpe_datasource_name: "<Required>"
        ## The schema name for Case History Store.
        case_history_store_schema_name: "CHSCHEMA"

    ## Application engine configuration, because application engine is an array,
    ## when there is only one Application engine deployed along with this CR, below four parameters are not required.
    ## when there is more then one application engine deployed, below four parameters are required.
    appengine:
      ## App Engine hostname
      hostname: ""
      ## App Engine port
      port: "443"
      ## App Engine admin secret name
      admin_secret_name: ""
      ## App Engine context root.
      ## The application default context root will be /{{ meta.name}}-{{ application engine instance name }}-aae
      ## Please adjust this value according to the App Engine instance you selected. Don't miss the slash in front of value
      context_root: ""

    ## The configuration for Java Messaging Service(JMS)
    jms:
      storage:
        ## Whether to enable persistent storage for JMS
        persistent: true
        ## Size for JMS persistent storage
        size: "1Gi"
        ## Whether to enable dynamic provisioning for JMS persistent storage
        use_dynamic_provisioning: true
        ## Access modes for JMS persistent storage
        access_modes:
        - ReadWriteOnce
        ## Storage class name for JMS persistent storage
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"

    ## Resource configuration for init job
    resources_init:
      limits:
        ## CPU limit for init job containers.
        cpu: "500m"
        ## Memory limit for init job containers.
        memory: 512Mi
      requests:
        ## Requested amount of CPU for init job containers.
        cpu: "200m"
        ## Requested amount of memory for init job containers.
        memory: 128Mi

    ## Resource configuration for heavy init job such as database init job
    resources_init_heavy_job:
      limits:
        ## CPU limit for Workflow Server database init job container.
        cpu: 1
        ## Memory limit for Workflow Server database init job container.
        memory: 2048Mi
      requests:
        ## Requested amount of CPU for Workflow Server database init job container.
        cpu: "500m"
        ## Requested amount of memory for Workflow Server database init job container.
        memory: 512Mi

    ## Resource configuration
    resources:
      limits:
        ## CPU limit for Workflow Server.
        cpu: 2
        ## Memory limit for Workflow Server.
        memory: 3060Mi
      requests:
        ## Requested amount of CPU for Workflow Server.
        cpu: "500m"
        ## Requested amount of memory for Workflow Server.
        memory: 2048Mi

    ## liveness and readiness probes configuration
    probe:
      ws:
        liveness_probe:
          ## Number of seconds after the Workflow Server container starts before the liveness probe is initiated
          initial_delay_seconds: 300
          ## Number of seconds to wait before the next probe.
          period_seconds: 10
          ## Number of seconds after which the probe times out.
          timeout_seconds: 10
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 3
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1
        readinessProbe:
          ## Number of seconds after the Workflow Server container starts before the readiness probe is initiated
          initial_delay_seconds: 240
          ## Number of seconds to wait before the next probe.
          period_seconds: 5
          ## Number of seconds after which the probe times out.
          timeout_seconds: 5
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 6
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1
        startup_probe:
          ## Number of seconds to wait before the next probe.
          period_seconds: 5
          ## Number of seconds after which the probe times out.
          timeout_seconds: 10
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 80
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1

    ## log trace configuration
    logs:
      ## Format for printing logs on the console.
      console_format: "json"
      ## Log level for printing logs on the console.
      console_log_level: "INFO"
      ## Source of the logs for printing on the console.
      console_source: "message,trace,accessLog,ffdc,audit"
      ## Required format for the messages.log file. Valid values are SIMPLE and JSON.
      message_format: "SIMPLE"
      ## Format of the trace log. Options values are: BASIC, ADVANCED, and ENHANCED.
      trace_format: "ENHANCED"
      ## Specification for printing trace logs.
      trace_specification: "*=info"
      # Maximum number of log files that are kept before the oldest file is removed.
      max_files: 10
      # The maximum size (in MB) that a log file can reach before it is rolled.
      max_filesize: 50

    ## audit log configuration
    audit_log:
      ## Whether to enable Process Admin Console audit log. Default value is false.
      enable: false
      ## Persistent volume claim (PVC) for audit logs. If it is not specified, audit logs are stored in log PVC. Default value is empty.
      pvc_name: ""
      ## Size of the persistent volume (PV) that is mounted as the audit log store. Default value is 2Gi.
      pvc_size: 2Gi
      ## Audit log file name. Default value is bawaudit.log
      file_name: bawaudit.log
      ## Audit log rollover size(in MB). Default value is 100.
      rollover_size: 100
      ## Whether to enable verbose mode. Default value is true.
      verbose: true
      ## Maximum number of historical files that are kept. Default value is 5.
      max_historical_files: 5

    ## storage configuration
    storage:
      ## Set to true to use dynamic storage provisioning. If set to false, you must set existing_pvc_for_logstore and existing_pvc_for_dumpstore.
      use_dynamic_provisioning: true
      ## Persistent volume claim (PVC) for logs.
      existing_pvc_for_logstore: ""
      ## Minimum size of the persistent volume (PV) that is mounted as the log store.
      size_for_logstore: "1Gi"
      ## Persistent volume claim (PVC) for dump files.
      existing_pvc_for_dumpstore: ""
      ## Minimum size of the persistent volume (PV) that is mounted as the dump store.
      size_for_dumpstore: "5Gi"
      ## Persistent volume claim (PVC) for generic files.
      existing_pvc_for_filestore: ""
      ## Minimum size of the persistent volume (PV) that is mounted as the generic file store.
      size_for_filestore: "1Gi"

    ## autoscaling
    autoscaling:
      ## Whether to enable automatically scaling the number of pods.
      enabled: false
      ## Upper limit for the number of pods that can be set by the autoscaler. If it is not specified or negative, the server uses the default value.
      max_replicas: 3
      ## Lower limit for the number of pods that can be set by the autoscaler. If it is not specified or negative, the server uses the default value.
      min_replicas: 2
      ## Target average CPU utilization (represented as a percent of requested CPU) over all the pods. If it is not specified or negative, the default is used.
      target_cpu_utilization_percentage: 80

    ## customize environment settings
    environment_config:
      ## Timezone of Workflow Server, default value is Etc/UTC.
      timezone: "Etc/UTC"
      ## Whether to show the Intelligent Task Prioritization service toggle button in the web user interface to allow the user to enable or disable this service. This parameter is valid only for the first Workflow instance.
      show_task_prioritization_service_toggle: false
      ## Whether to display the Intelligent Task Prioritization service toggle button. If this parameter is set to true, the previous parameter is ignored. This parameter is valid only for the first Workflow instance.
      always_run_task_prioritization_service: false
      csrf:
        ## Acceptable values in the Origin header field. The value of this property must be a comma-separated list of prefixes in the format protocol://host:port, e.g "https://example.com, http://example2.com:8080".
        origin_allowlist:
        ## Acceptable values in the Referer header field. The value of this property must be a comma-separated list of fully qualified host names, e.g "example1.com, example2.com".
        referer_allowlist:
        ## Comma-separated list of user agents. For the REST API requests with the path pattern "/rest/bpm/wle/v1/*" that is sent by the agents in the list, the server will not validate the "XSRF-TOKEN" cookie. The value of this property must be a comma-separated list, e.g "agentkeyworkd1, agentkeyworkd2".
        user_agent_keyword_allow_list_for_old_restapi_csrf_check: "java,wink client,httpclient,curl,jersey,httpurlconnection"
        ## Whether to validate the cookie "XSRF-TOKEN" against incoming REST API requests (POST/PUT/DELETE) with the path pattern "/rest/bpm/wle/v1/*". The value must be "true" or "false".
        check_xsrf_for_old_restapi: "true"

      ## Content security policy additional origins. E.g ["https://hostname1","https://hostname2"]
      content_security_policy_additional_origins: []
      ## Content security policy additional directive for default-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_default_src: []
      ## Content security policy additional directive for script-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_script_src: []
      ## Content security policy additional directive for frame-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_frame_src: []
      ## Content security policy additional directive for object-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_object_src: []
      ## Content security policy additional directive for connect-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_connect_src: []
      ## Content security policy additional directive for frame-ancestor, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_frame_ancestor: []
      ## Content security policy additional directive for img-src, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_img_src: []
      ## Content security policy additional directive for font-src, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_font_src: []
      ## Content security policy additional directive for style-src, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_style_src: []

    ## federation config
    federation_config:
      workflow_server:
          ## Number of primary shards of the Elasticsearch index used to store Workflow Server data.
          index_number_of_shards: 3
          ## Number of shard replicas of the Elasticsearch index used to store Workflow Server data.
          index_number_of_replicas: 1
      case_manager:
            ## Case Manager object store name.
          - object_store_name: TOS
            ## Number of primary shards of the Elasticsearch index used to store Case Manager object store data.
            index_number_of_shards: 3
            ## Number of shard replicas of the Elasticsearch index used to store Case Manager object store data.
            index_number_of_replicas: 1

    ## JVM options separated with spaces, for example: -Dtest1=test -Dtest2=test2.
    jvm_customize_options:

    ##  Workflow Server custom plain XML snippet
    ##  liberty_custom_xml: |+
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    ## The custom_xml_secret_name is also used for Workflow Server customization. Ensure the configuration value exists either in liberty_custom_xml or custom_xml_secret_name.
    ## Do not set the configuration value in both places.
    liberty_custom_xml:

    ## Workflow Server custom XML secret name that contains custom configuration in Liberty server.xml,
    ## put the custom.xml in secret with key "sensitiveCustomConfig"
    ##  100Custom.xml: |+
    ##  <properties>
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    ##  </properties>
    ## kubectl create secret generic wfs-custom-xml-secret --from-file=sensitiveCustomConfig=./custom.xml
    ## The liberty_custom_xml property is also used for Workflow Server customization. Ensure the configuration value exists either in liberty_custom_xml or custom_xml_secret_name.
    ## Do not set the configuration value in both places
    custom_xml_secret_name:

    ## Workflow Server Lombardi custom XML secret name that contains custom configuration in 100Custom.xml
    ## put the 100Custom.xml in secret with key "sensitiveCustomConfig"
    #  kubectl create secret generic wfs-lombardi-custom-xml-secret --from-file=sensitiveCustomConfig=./100Custom.xml
    lombardi_custom_xml_secret_name:

    ##  IBM Business Automation Insights integration configuration
    business_event:
      ## Whether to enable event monitoring for Dynamic Event Framework events for the Workflow Services container.
      ## If Business Automation Insights and the Machine Learning Server parameters are configured, this parameter must be set to true.
      enable: false
      ## Whether to enable the task record in generated events. This optional parameter is equivalent to the task-record-enabled parameter,
      ## Also see https://www.ibm.com/support/knowledgecenter/SSYHZ8_20.0.x/com.ibm.dba.bai/topics/ref_bai_bpmn_summary_formats.html
      enable_task_record: true
      ## Whether to record additional task information in generated events.
      ## If Business Automation Insights and the Machine Learning Server parameters are configured, this parameter must be set to true.
      ## This parameter is equivalent to the enable_task_api_def parameter.
      ## Also see https://www.ibm.com/support/knowledgecenter/SSYHZ8_20.0.x/com.ibm.dba.bai/topics/ref_bai_bpmn_summary_formats.html
      enable_task_api: false
      ## List of the subscription configurations. Each subscription attribute is listed in the rest of this table.
      ## app_name: Name of the application that is the source of the events that are to be monitored.
      ## version: Version of the application to be monitored.
      ## component_type: Type of the component to be monitored.
      ## component_name: Name of the component to be monitored.
      ## element_type: Type of element to be monitored. BPMN types are PROCESS, ACTIVITY, EVENT, and GATEWAY.
      ## element_name: Name of the element to be monitored.
      ## nature: Nature of the event. One element can send events of various natures, such as STARTED, ACTIVE, COMPLETED.
      ##         The BPMN nature categories are STARTED, COMPLETED, TERMINATED, DELETED, FAILED, CAUGHT, THROWN, EXPECTED, ACTIVE, READY, RESOURCE_ASSIGNED, ACTIVE, LOOP_CONDITION_TRUE, LOOP_CONDITION_FALSE, and MULTIPLE_INSTANCES_STARTED.
      subscription:
      - {'app_name': '*','version': '*','component_type': '*','component_name': '*','element_type': '*','element_name': '*','nature': '*'}
    node_affinity:
      # Values in this field will be used as kubernetes.io/arch selector values. Default values are ['amd64','s390x','ppc64le']
      deploy_arch: []
      #-------------------------------------
      # custom_node_selector_match_expression will be added in node selector match expressions.
      # It accepts array list inputs. You can assign multiple selector match expressions except (kubernetes.io/arch)
      # Example input:
      # - key: kubernetes.io/hostname
      #   operator: In
      #   values:
      #     - worker0
      #     - worker1
      #     - worker3
      #-------------------------------------
      custom_node_selector_match_expression: []
    # Values in this field will be used as annotations in all generated pods.
    # They must be valid annotation key-value pairs.
    # Example:
    # custom_annotations:
    #   key1: value1
    #   key2: value2
    custom_annotations: {}
    # Values in this field will be used as labels in all generated pods
    # It must be valid label key value pairs
    # Example:
    # custom_labels:
    #   key1: value1
    #   key2: value2
    custom_labels: {}
    ## Optional setting for secure computing mode (seccomp) profile for CP4A containers.  The default seccomp profile is RuntimeDefault on OCP 4.11 (k8s v1.24) or higher. seccomp profile won't be created on OCP 4.10 (k8s v1.23) or lower.
    ## For more information on seccomp please refer to https://kubernetes.io/docs/tutorials/security/seccomp/ and https://docs.openshift.com/container-platform/4.12/security/seccomp-profiles.html
    ## NOTE: Defining a custom, localhost seccomp profile that is stricter than the default RuntimeDefault profile may cause our pods fail to start. This custom profile should be created at the worker nodes.
    ## If it is not set, it will fall back to shared_configuration.sc_seccomp_profile
    seccomp_profile:
    #  type: # RuntimeDefault, Localhost, Unconfined
    #  localhost_profile: # Local path of custom seccomp profile when type `Localhost` is used. The custom profile must be accessible by the pod and must exist locally on all worker nodes.  For example: `/profiles/fine-grained.json`
    ## Optional performance tuning for Zen NGINX server.
    ## For more information, please refer to https://www.nginx.com/blog/tuning-nginx/#keepalive_requests and https://nginx.org/en/docs/http/ngx_http_proxy_module.html.
    #zen_performance:
      # Optional: the number of idle keepalive connections to an upstream server that remain open for each worker process. The default vaue is 512.
      #keepalive:
      # Optional: how long an idle keepalive connection remains open. The default value is 30s.
      #keepalive_timeout:
      # Optional: the number of requests a client can make over a single keepalive connection. The default is 500.
      #keepalive_requests:
      # Optional: sets the size of the buffer used for reading the first part of the response received from the proxied server. The default value is 256k.
      #proxy_buffer_size:
      # Optional: sets the number and size of the buffers used for reading a response from the proxied server, for a single connection. The default value is 8 512k.
      # proxy_buffers:
      # Optional: when buffering of responses from the proxied server is enabled, limits the total size of buffers that can be busy sending a response to the client while the response is not yet fully read.
      # The default value is 512k.
      #proxy_busy_buffers_size:
      # Optional: Defines a timeout for establishing a connection with a proxied server. The default value is 300s.
      #proxy_connect_timeout:
      # Optional: Sets a timeout for transmitting a request to the proxied server. The timeout is set only between two successive write operations, not for the transmission of the whole request.
      # If the proxied server does not receive anything within this time, the connection is closed. The default value is 300s.
      #proxy_send_timeout:
      # Optional: Defines a timeout for reading a response from the proxied server. The timeout is set only between two successive read operations, not for the transmission of the whole response.
      # If the proxied server does not transmit anything within this time, the connection is closed. The default value is 300s.
      #proxy_read_timeout:
    ## Before you can use Kafka services in your workflow automations, you must enable the Kafka services capability.
    ## To enable Kafka, add kafka to sc_optional_components in the ICP4A Cluster custom resource.
    ## If you do not want to enable Kafka services on all of your runtime instances, you need to disable it on those instances by setting kafka_services.enable to false.
    #kafka_services:
    #  enable: false
  ##################################################################################
  ########   IBM Business Automation Machine Learning Server configuration  ########
  ##################################################################################
  baml_configuration:
    ## Intelligent Task Prioritization configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true
    intelligent_task_prioritization:
      ## Intelligent Task Prioritization replica count
      ## The value takes priority when both profile size and replica properties are set
      replicas: 1
      ## Linux cron schedule expression used to trigger Intelligent Task Prioritization server to train model using data retrieved from Business Automation Insights server
      ## default value is '* 3 * * 0' every Sunday at 3AM UTC
      ## for examples: * 3 * * * : everyday at 3AM UTC,  */50 * * * *: every 50 minutes
      retrain_model_schedule: ""
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Intelligent Task Prioritization container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      ## Image name for Intelligent Task Prioritization container
      image:
        repository: cp.icr.io/cp/cp4a/baw/bui-task-prioritization
        ## Image tag for Intelligent Task Prioritization container
        tag: "24.0.0-IF001"
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for Intelligent Task Prioritization container
          cpu: "2"
          ## Memory limit for Intelligent Task Prioritization container
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for Intelligent Task Prioritization container
          cpu: "500m"
          ## Requested amount of memory for Intelligent Task Prioritization container
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_trained_pipelines
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "1Gi"
        ## The persistent volume claim for Intelligent Task Prioritization trained piplines files
        existing_pvc_for_trained_pipelines: ""
        ## The minimum size of the persistent volume used mounted as Intelligent Task Prioritization trained piplines files
        size_for_trained_pipelines: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
      node_affinity:
        # Values in this field will be used as kubernetes.io/arch selector values. Default values are ['amd64']
        deploy_arch: []
        #-------------------------------------
        # custom_node_selector_match_expression will be added in node selector match expressions.
        # It accepts array list inputs. You can assign multiple selector match expressions except (kubernetes.io/arch)
        # Example input:
        # - key: kubernetes.io/hostname
        #   operator: In
        #   values:
        #     - worker0
        #     - worker1
        #     - worker3
        #-------------------------------------
        custom_node_selector_match_expression: []
      # Values in this field will be used as annotations in all generated pods.
      # They must be valid annotation key-value pairs.
      # Example:
      # custom_annotations:
      #   key1: value1
      #   key2: value2
      custom_annotations: {}
      # Values in this field will be used as labels in all generated pods
      # It must be valid label key value pairs
      # Example:
      # custom_labels:
      #   key1: value1
      #   key2: value2
      custom_labels: {}
    ## Workforce Insights configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true and bai_configuration.bpmn.force_elasticsearch_timeseries to true
    workforce_insights:
      ## Workforce Insights replica count
      ## The value takes priority when both profile size and replica properties are set
      replicas: 1
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Workforce Insights pod container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      image:
        repository: cp.icr.io/cp/cp4a/baw/workforce-insights
        tag: "24.0.0-IF001"
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for workforce insights
          cpu: "2"
          ## Memory limit for workforce insights
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for workforce insights
          cpu: "500m"
          ## Requested amount of memory for workforce insights
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "1Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
      node_affinity:
        # Values in this field will be used as kubernetes.io/arch selector values. Default values are ['amd64']
        deploy_arch: []
        #-------------------------------------
        # custom_node_selector_match_expression will be added in node selector match expressions.
        # It accepts array list inputs. You can assign multiple selector match expressions except (kubernetes.io/arch)
        # Example input:
        # - key: kubernetes.io/hostname
        #   operator: In
        #   values:
        #     - worker0
        #     - worker1
        #     - worker3
        #-------------------------------------
        custom_node_selector_match_expression: []
      # Values in this field will be used as annotations in all generated pods.
      # They must be valid annotation key-value pairs.
      # Example:
      # custom_annotations:
      #   key1: value1
      #   key2: value2
      custom_annotations: {}
      # Values in this field will be used as labels in all generated pods
      # It must be valid label key value pairs
      # Example:
      # custom_labels:
      #   key1: value1
      #   key2: value2
      custom_labels: {}

  ########################################################################
  ########   IBM Business Automation Navigator configuration      ########
  ########################################################################
  navigator_configuration:

    ## Enable/disable basic auth.
    ## From 22.0.2 this by default is true to use jaaslogin module
    ## Set this to false let FNCM component to use basic auth
    # disable_basic_auth: true

    ## Navigator secret that contains user credentials for LDAP and database
    ban_secret_name: ibm-ban-secret

    ## The architecture of the cluster.  This is the default for Linux and should not be changed.
    arch:
      amd64: "3 - Most preferred"

    ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
    ## it is recommended to have 2 or more.
    replica_count: 2

    ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
    image:

      ## The default repository is the IBM Entitled Registry
      repository: cp.icr.io/cp/cp4a/ban/navigator-sso
      tag: "24.0.0-IF001"

      ## This will override the image pull policy in the shared_configuration.
      pull_policy: IfNotPresent

    ## Logging for workloads.  This is the default setting.
    log:
      format: json

    ## This is the initial default resource requests.  If more resources are needed,
    ## make the changes here to meet your requirement.
    resources:
      requests:
        cpu: 1
        memory: 3072Mi
      limits:
        cpu: 1
        memory: 3072Mi

    ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
    ## this settings to meet your requirement.
    auto_scaling:
      enabled: false
      max_replicas: 3
      min_replicas: 2
      ## This is the default cpu percentage before autoscaling occurs.
      target_cpu_utilization_percentage: 80

    node_affinity:
      # Value in this field will be used as kubernetes.io/arch selector values. By default all support arch will be included
      # It will be transformed to node selector value
      # - key: kubernetes.io/arch
      #   operator: In
      #   values:
      #     - amd64
      #     - s390x
      #     - ppc64le
      deploy_arch:
      - amd64
      - s390x
      - ppc64le
      #-------------------------------------
      # custom_node_selector_match_expression will be added in node selector match expressions.
      # It accept array list inputs. You can assign mutiple selector match expressions except (kubernetes.io/arch)
      # Example value:
      # - key: kubernetes.io/hostname
      #   operator: In
      #   values:
      #     - worker0
      #     - worker1
      #     - worker3
      #-------------------------------------
      custom_node_selector_match_expression: []
    ## Values in this field will be used as annotations in all generated pods and it must be valid annotation key value pairs.
    # Example:
    # customAnnotationKey: customAnnotationValue
    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_annotations.
    ## To include '{{ }}' in annotation like '{{example}}', add a backward slash before curly brace like '\{\{example\}\}'.
    custom_annotations: {}
    ## Values in this field will be used as labels in all generated pods and it must be valid label key value pairs
    # Example:
    # customLabelKey: customLableValue
    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_labels.
    custom_labels: {}

    # Optional performance tuning for Zen NGINX server.
    # For more information, please refer to https://www.nginx.com/blog/tuning-nginx/#keepalive_requests and https://nginx.org/en/docs/http/ngx_http_proxy_module.html.
    zen_performance:
      # Timeout for establishing a connection with a proxy server. This parameter is optional. The default value is 300s.
      proxy_connect_timeout: 300
      # Timeout for transmitting a request to the proxy server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the proxy server does not receive anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
      proxy_send_timeout: 300
      # Timeout for reading a response from the proxy server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxy server does not transmit anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
      proxy_read_timeout: 300

    ## Below are the default ICN Production settings.  Make the necessary changes as you see fit.
    icn_production_setting:
      timezone: Etc/UTC
      jvm_initial_heap_percentage: 40
      jvm_max_heap_percentage: 66
      jvm_customize_options:
      icn_jndids_name: ECMClientDS
      icn_schema: ICNDB
      icn_table_space: ICNDB
      allow_remote_plugins_via_http: false
      ## uncomment copy_files_to_war parameter to copy customized files into Navigator web application.
      ## The <custom-dir>/navigator_war_filesources.xml must be located in config volume mapping, which is /opt/ibm/wlp/usr/servers/defaultServer/configDropins/overrides
      # copy_files_to_war: <custom-dir>/navigator_war_filesources.xml

      ## The WalkMe URL references a WalkMe snippet.  This snippet is a piece of JavaScript code that allows WalkMe to be displayed in the application.
      ## Each WalkMe Editor account has a unique snippet code that can be accessed inside the Editor.
      #  walkme_url: https://cdn.walkme.com/users/4e7c687193414395aa0411837a9eee4b/test/walkme_4e7c687193414395aa0411837a9eee4b_https.js

      # This section is optional and it takes a list of configmaps.
      # A configmap can hold files or environment data but it cannot a mix of both.
      # The volume_path is optional for a configmap that holds files as its data and if it's not specified,
      # then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
      # then is_env is required and set it to true.
      #
      # custom_configmap:
      #  - name: <name of configmap>
      #    volume_path:  # optional
      #  - name: <name of configmap>
      #    is_env: # required if the configmap holds environment variables.

      # This section you can set custom environments in the CR for the deployment
      # custom_env_var:
      # - some_custom_var_name: "some_custom_var_value"

    ## Default settings for monitoring
    monitor_enabled: false
    ## Default settings for logging
    logging_enabled: false

    ## Persistent Volume Claims for Navigator.  The Operator will create the PVC using the names below by default.
    datavolume:
      existing_pvc_for_icn_cfgstore:
        name: "icn-cfgstore"
        size: 1Gi
      existing_pvc_for_icn_logstore:
        name: "icn-logstore"
        size: 1Gi
      existing_pvc_for_icn_pluginstore:
        name: "icn-pluginstore"
        size: 1Gi
      existing_pvc_for_icnvw_cachestore:
        name: "icn-vw-cachestore"
        size: 1Gi
      existing_pvc_for_icnvw_logstore:
        name: "icn-vw-logstore"
        size: 1Gi
      existing_pvc_for_icn_aspera:
        name: "icn-asperastore"
        size: 1Gi

    ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
    probe:
      startup:
        initial_delay_seconds: 120
        period_seconds: 10
        timeout_seconds: 10
        failure_threshold: 6
      readiness:
        period_seconds: 10
        timeout_seconds: 10
        failure_threshold: 6
      liveness:
        period_seconds: 10
        timeout_seconds: 5
        failure_threshold: 6

    ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
    image_pull_secrets:
      name: "ibm-entitlement-key"

  ########################################################################
  ########      IBM FileNet Content Manager configuration         ########
  ########################################################################
  ecm_configuration:
    ## FNCM secret that contains GCD DB user name and password, Object Store DB user name and password,
    ## LDAP user and password, CPE username and password, keystore password, and LTPA passs, etc.
    fncm_secret_name: ibm-fncm-secret

    ## By default all the components create ingress and routes with required annotations. In case any custom annotation is needed for the environment provide below.
    #    route_ingress_annotations:
    #      - haproxy.router.openshift.io/balance: roundrobin
    route_ingress_annotations:

    # Optional: You can specify a profile size for FNCM if different from CloudPak (see shared_configuration.sc_deployment_profile_size).  In other words,
    # you can override "shared_configuration.sc_deployment_profile_size" with "deployment_profile_size" defined here.
    # The valid values are small, medium, large - default is small.  The resources in this file are reflecting a "small" profile.
    #deployment_profile_size: "small"

    # Optional: Use an existing certificate for automatic creation of OpenShift routes.
    # Set this key if you have an external TLS certificate. Leave this empty if you don't have an external TLS certificate, operator will generate one for you.
    fncm_ext_tls_secret_name:
    ## Optional. The Certificate Authority (CA) used to sign the external TLS secret for automatic creation of OpenShift routes.
    ## Set this key if you have a CA to sign the external TLS certificate, leave this parameter empty if you don't have the CA of your external TLS certificate.
    fncm_auth_ca_secret_name:

    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.node_affinity.
    node_affinity:
      # Values in this field will be used as kubernetes.io/arch selector values. By default all support arch will be included
      # It will be transformed to node selector value
      # - key: kubernetes.io/arch
      #   operator: In
      #   values:
      #     - amd64
      #     - s390x
      #     - ppc64le
      deploy_arch:
      - amd64
      - s390x
      - ppc64le
      #-------------------------------------
      # custom_node_selector_match_expression will be added in node selector match expressions.
      # It accepts array list inputs. You can assign multiple selector match expressions except (kubernetes.io/arch)
      # Example value:
      # - key: kubernetes.io/hostname
      #   operator: In
      #   values:
      #     - worker0
      #     - worker1
      #     - worker3
      #-------------------------------------
      custom_node_selector_match_expression: []
    ## Values in this field will be used as annotations in all generated pods and they must be valid annotation key-value pairs.
    # Example:
    # customAnnotationKey: customAnnotationValue
    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_annotations.
    ## To include '{{ }}' in annotation like '{{example}}', add a backward slash before curly brace like '\{\{example\}\}'.
    custom_annotations: {}
    ## Values in this field will be used as labels in all generated pods and it must be valid label key value pairs
    # Example:
    # customLabelKey: customLableValue
    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_labels.
    custom_labels: {}

    # Optional performance tuning for Zen NGINX server.
    # For more information, please refer to https://www.nginx.com/blog/tuning-nginx/#keepalive_requests and https://nginx.org/en/docs/http/ngx_http_proxy_module.html.
    # This can be overwritten by componenent level definition for example ecm_configuration.graphql.zen_performance.
    # For CPE we allow more granular setting like below and they take precedence over ecm_configuration.cpe.zen_performance.
    # cpe.zen_performance.acce
    # cpe.zen_performance.fncews40mtom
    # cpe.zen_performance.pewsi
    # cpe.zen_performance.peengine
    # cpe.zen_performance.p8ce
    zen_performance:
      # Timeout for establishing a connection with a proxy server. This parameter is optional. The default value is 300s.
      proxy_connect_timeout: 300
      # Timeout for transmitting a request to the proxy server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the proxy server does not receive anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
      proxy_send_timeout: 300
      # Timeout for reading a response from the proxy server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxy server does not transmit anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
      proxy_read_timeout: 300

    ## Enable/disable basic auth.
    ## From 22.0.2 this by default is true to use jaaslogin module
    ## Set this to false let FNCM component to use basic auth
    # disable_basic_auth: true

    ####################################
    ## Start of configuration for CPE ##
    ####################################
    cpe:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cpe
        tag: "24.0.0-IF001"

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
       format: json

      ## Set securityContext for CPE deployment.
      security_context:
        ## Controls which group IDs containers add. For example "supplemental_groups: [1000620001,1000620002]"
        supplemental_groups:
        ## This can take an array of key value pairs to assign SELinux labels to a Container, for example
        ## selinux_options:
          ## level: "s0:c123,c456"
          ## type: "spc_t
        selinux_options:
        # Defines behavior for changing ownership and permission of the volume before being exposed inside a Pod. This field has two possible values (Always,OnRootMismatch)
        # For example fs_groupchangepolicy: "OnRootMismatch"
        fs_groupchangepolicy:

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 1
          memory: 3072Mi
          ephemeral_storage: 4Gi
        limits:
          cpu: 1
          memory: 3072Mi
          ephemeral_storage: 4Gi

      ## By default "Autoscaling" is disabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CPE Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cpe_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 18
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 33

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        ## If your JVM option contains comma then you have to include 'DELIM=;' to use a different separator, for example jvm_customize_options="DELIM=;-Dmy.test.jvm.arg1=123;-Dcom.filenet.authentication.wsi.AuthTokenOrder=oauth,oidc,ltpa". Semicolon can be replaced with any other char.
        ## If your JVM option contains double quotes then you need to escape it like this: jvm_customize_options="-Dsettings.navigator.default=logging.level={\"_value\":\"4\",\"_mergeOption\":\"replace\"}"
        jvm_customize_options:

        ## Default JNDI name for GCD for non-XA data source
        gcd_jndi_name: FNGCDDS
        ## Default JNDI name for GCD for XA data source
        gcd_jndixa_name: FNGCDDSXA
        license_model: FNCM.PVUNonProd

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept

        # This section is optional and it takes a list of configmaps.
        # A configmap can hold files or environment data but it cannot a mix of both.
        # The volume_path is optional for a configmap that holds files as its data and if it's not specified,
        # then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
        # then is_env is required and set it to true.
        #
        # custom_configmap:
        #  - name: <name of configmap>
        #    volume_path:  # optional
        #  - name: <name of configmap>
        #    is_env: # required if the configmap holds environment variables.

        # This section you can set custom environments in the CR for the deployment
        # custom_env_var:
        # - some_custom_var_name: "some_custom_var_value"

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for CPE.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cpe_cfgstore:
          name: "cpe-cfgstore"
          size: 1Gi
        existing_pvc_for_cpe_logstore:
          name: "cpe-logstore"
          size: 1Gi
        existing_pvc_for_cpe_filestore:
          name: "cpe-filestore"
          size: 1Gi
        existing_pvc_for_cpe_icmrulestore:
          name: "cpe-icmrulesstore"
          size: 1Gi
        existing_pvc_for_cpe_textextstore:
          name: "cpe-textextstore"
          size: 3Gi
        existing_pvc_for_cpe_bootstrapstore:
          name: "cpe-bootstrapstore"
          size: 1Gi
        existing_pvc_for_cpe_fnlogstore:
          name: "cpe-fnlogstore"
          size: 1Gi

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        startup:
          initial_delay_seconds: 120
          period_seconds: 30
          timeout_seconds: 10
          failure_threshold: 40
        liveness:
          period_seconds: 30
          timeout_seconds: 5
          failure_threshold: 6

      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "ibm-entitlement-key"
      ## This is only used to deploy CPE in AWS EKS Cluster, and it will create and mount aws-iam-token.
      #aws_iam:
      #  aws_iam_enable: true
      #  audience: "sts.amazonaws.com"
      #  expirationSeconds: 7200
    #####################################
    ## Start of configuration for CMIS ##
    #####################################
    cmis:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cmis
        tag: "24.0.0-IF001"

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 1536Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is disabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cmis_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        ## If your JVM option contains comma then you have to include 'DELIM=;' to use a different separator, for example jvm_customize_options="DELIM=;-Dmy.test.jvm.arg1=123;-Dcom.filenet.authentication.wsi.AuthTokenOrder=oauth,oidc,ltpa". Semicolon can be replaced with any other char.
        ## If your JVM option contains double quotes then you need to escape it like this: jvm_customize_options="-Dsettings.navigator.default=logging.level={\"_value\":\"4\",\"_mergeOption\":\"replace\"}"
        jvm_customize_options:

        ## Enable/disable Websphere Security
        ws_security_enabled: false

        # Enable/disable the content-stream of the Private Working Copy should be copied from the Document that was checked out.
        checkout_copycontent: true
        # The default value for the optional maxItems input argument on paging-related services.
        default_maxitems: 25

        # Enable/disable whether ChoiceLists will be cached once for all users.
        cvl_cache: true
        secure_metadata_cache: false

        # Enable/disalbe hidden P8 domain properties should appear in CMIS type definitions and folder or document instance data.
        filter_hidden_properties: true

        # Timeout in seconds for the queries that specify timeout.
        querytime_limit: 180

        # If true, then a faster response time for REST next line. If false, the next link for REST will re-issue query.
        resumable_queries_forrest: true

        # Specifies whether to escape characters that are not valid for XML unicode as specified by the XML 1.0 standard.
        escape_unsafe_string_characters: false

        # Limits the maximum allowable Web Service SOAP message request size.
        max_soap_size: 180

        # Enable/disable the printing of the full stack trace in the response.
        print_pull_stacktrace: false

        # Configures the sequence in which CMIS tries to identify objects (folder or document first).
        folder_first_search: false

        # To ignore the reading or writing contents in root folder, set this parameter to true.
        ignore_root_documents: false

        # Enable/disable the support type mutability.
        supporting_type_mutability: false

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept

        # This section is optional and it takes a list of configmaps.
        # A configmap can hold files or environment data but it cannot a mix of both.
        # The volume_path is optional for a configmap that holds files as its data and if it's not specified,
        # then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
        # then is_env is required and set it to true.
        #
        # custom_configmap:
        #  - name: <name of configmap>
        #    volume_path:  # optional
        #  - name: <name of configmap>
        #    is_env: # required if the configmap holds environment variables.

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for CMIS.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cmis_cfgstore:
          name: "cmis-cfgstore"
          size: 1Gi
        existing_pvc_for_cmis_logstore:
          name: "cmis-logstore"
          size: 1Gi


      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        startup:
          initial_delay_seconds: 90
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        readiness:
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          period_seconds: 10
          timeout_seconds: 5
          failure_threshold: 6

      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "ibm-entitlement-key"

    ########################################
    ## Start of configuration for GraphQL ##
    ########################################
    graphql:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/graphql
        tag: "24.0.0-IF001"

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 1536Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is disabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        min_replicas: 2
        max_replicas: 3
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      graphql_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        ## If your JVM option contains comma then you have to include 'DELIM=;' to use a different separator, for example jvm_customize_options="DELIM=;-Dmy.test.jvm.arg1=123;-Dcom.filenet.authentication.wsi.AuthTokenOrder=oauth,oidc,ltpa". Semicolon can be replaced with any other char.
        ## If your JVM option contains double quotes then you need to escape it like this: jvm_customize_options="-Dsettings.navigator.default=logging.level={\"_value\":\"4\",\"_mergeOption\":\"replace\"}"
        jvm_customize_options:

        license_model: FNCM.PVUNonProd

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept

        enable_graph_iql: false

        # This section is optional and it takes a list of configmaps.
        # A configmap can hold files or environment data but it cannot a mix of both.
        # The volume_path is optional for a configmap that holds files as its data and if it's not specified,
        # then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
        # then is_env is required and set it to true.
        #
        # custom_configmap:
        #  - name: <name of configmap>
        #    volume_path:  # optional
        #  - name: <name of configmap>
        #    is_env: # required if the configmap holds environment variables.

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for GraphQL.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_graphql_cfgstore:
          name: "graphql-cfgstore"
          size: 1Gi
        existing_pvc_for_graphql_logstore:
          name: "graphql-logstore"
          size: 1Gi

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        startup:
          initial_delay_seconds: 120
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        readiness:
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          period_seconds: 10
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "ibm-entitlement-key"

  ########################################################################
  ########  IBM FileNet Content Manager initialize configuration  ########
  ########################################################################
  ## The deployment of FNCM will be initialized with the default values assigned to the parameters below.
  ## The initialization process includes the creation of the P8 domain, the creation of the directory services,
  ## the assignments of users/groups to the P8 domain and object store(s), the creation of the object store(s),
  ## the creation/addition of add-ons for each object store, the enablement of workflow for each object store, the
  ## creation of Content Search Services servers, index areas, and the enabling of Content-based Retrieval (CBR) for each object store.
  ## In addition, the creation of Navigator desktop will also occur.
  ## If any of the values below does not fit your infrastructure, then change the value to correpond to your configuration
  ## (e.g., "CEAdmin" is the default user for ic_ldap_admin_user_name parameter and if you do not have "CEAdmin" user in your directory
  ## server and have a different user, then replace "CEAdmin" with your own user).  Otherwise, the rest of the values should remain as default.
  initialize_configuration:
    ic_domain_creation:
      ## Provide a name for the domain
      domain_name: "P8DOMAIN"
      ## The encryption strength
      encryption_key: "128"
    ic_ldap_creation:
      ## Administrator user
      ic_ldap_admin_user_name:
      - "<Required>" # user name for P8 domain admin, for example, "CEAdmin".  This parameter accepts a list of values.
      ## Administrator group
      ic_ldap_admins_groups_name:
      - "<Required>" # group name for P8 domain admin, for example, "P8Administrators".  This parameter accepts a list of values.
      ## Name of the LDAP directory
      ic_ldap_name: "ldap_name"
    ic_obj_store_creation:
      object_stores:
      ## Configuration for the document object store
      ## Display name for the document object store to create
      - oc_cpe_obj_store_display_name: "DOCS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "DOCS"
        oc_cpe_obj_store_schema_name: "docs"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOCS_connection" #database connection name
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSDOCS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSDOCSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values.
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os01_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        # Enable the content event emitter only when deploying BAI.
        # Default value is false if not specified in the CR.
        oc_cpe_obj_store_enable_content_event_emitter: false
        # Enable/disable object store database compression.  Default is false.
        oc_cpe_obj_store_enable_compression: false
      ## Configuration for the design object store
      ## Display name for the design object store to create
      - oc_cpe_obj_store_display_name: "DOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "DOS"
        oc_cpe_obj_store_schema_name: "dos"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSDOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSDOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values.
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os02_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        # Enable the content event emitter only when deploying BAI.
        # Default value is false if not specified in the CR.
        oc_cpe_obj_store_enable_content_event_emitter: false
        # Enable/disable object store database compression.  Default is false.
        oc_cpe_obj_store_enable_compression: false
      ## Configuration for the target object store
      ## Display name for the target object store to create
      - oc_cpe_obj_store_display_name: "TOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "TOS"
        oc_cpe_obj_store_schema_name: "tos"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "TOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "FNDSTOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "FNDSTOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values.
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
         ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os03_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: true
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "tos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 3
        ## Specify a table space for the workflow data.
        oc_cpe_obj_store_workflow_data_tbl_space: "<Required>"
        ## Optionally specify a table space for the workflow index.
        oc_cpe_obj_store_workflow_index_tbl_space: ""
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: ""
        ## Designate an LDAP group for the workflow admin groupfor example, "P8Administrators".
        oc_cpe_obj_store_workflow_admin_group: "<Required>"
        ## Designate an LDAP group for the workflow config groupfor example, "P8Administrators".
        oc_cpe_obj_store_workflow_config_group: "<Required>"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: "cpe_conn_tos"
        # Enable the content event emitter only when deploying BAI.
        # Default value is false if not specified in the CR.
        oc_cpe_obj_store_enable_content_event_emitter: false
        # Enable/disable object store database compression.  Default is false.
        oc_cpe_obj_store_enable_compression: false
      ## Configuration for the application engine object store
      ## Display name for the application engine object store to create
  ########################################################################
  ########      IBM Business Automation Insights configuration    ########
  ########################################################################
  bai_configuration:
    image_credentials:
      registry: cp.icr.io/cp/cp4a

    # Set to true to enable the Flink job for sending events to HDFS.
    ingestion:
      install: false

    # Set to false to disable the Flink job for BAW.
    # Enabled automatically if BAI is selected as an optional component of
    # workflow or workflow-workstreams patterns.
    bpmn:
      install: true

    # Set to true to enable the Flink job for BAWAdv.
    # Disabled by default. Can be enabled by setting bawadv.install to true.
    bawadv:
      install: false

    # Set to false to disable the Flink job for ICM.
    # Enabled automatically if BAI is selected as an optional component of
    # workflow or workflow-workstreams patterns.
    icm:
      install: true

    # Set to true to enable the Flink job for ODM.
    # Enabled automatically if BAI is selected as an optional component of
    # decisions pattern.
    odm:
      install: false

    # Set to true to enable the Flink job for Content.
    # Enabled automatically if BAI is selected as an optional component of
    # content pattern.
    content:
      install: false

    # Set to true to enable the Flink job for Navigator.
    # Enabled automatically if BAI is selected as an optional component of
    # content pattern.
    navigator:
      install: false


########################################################################
  ######## IBM FileNet Content Manager Verification configuration ######
  ########################################################################
  ## After the initialization process (see section above), the verification process will take place.
  ## The verification process ensures that the FNCM and BAN components are functioning correctly.  The verification
  ## process includes creation of a CPE folder, a CPE document, a CBR search, verifying the workflow configuration,
  ## and validation of the ICN desktop.
  verify_configuration:
    vc_cpe_verification:
      vc_cpe_folder:
      - folder_cpe_obj_store_name: "BAWTOS"
        folder_cpe_folder_path: "/TESTFOLDER"
      vc_cpe_document:
      - doc_cpe_obj_store_name: "BAWTOS"
        doc_cpe_folder_name: "/TESTFOLDER"
        doc_cpe_doc_title: "test_title"
        DOC_CPE_class_name: "Document"
        doc_cpe_doc_content: "This is a simple document test"
        doc_cpe_doc_content_name: "doc_content_name"
      vc_cpe_cbr:
      - cbr_cpe_obj_store_name: "BAWTOS"
        cbr_cpe_class_name: "Document"
        cbr_cpe_search_string: "is a simple"
      vc_cpe_workflow:
      - workflow_cpe_enabled: false
        workflow_cpe_connection_point: "pe_conn_os1"
