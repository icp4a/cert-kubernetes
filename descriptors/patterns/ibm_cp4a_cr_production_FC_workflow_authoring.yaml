###############################################################################
#
# Licensed Materials - Property of IBM
#
# (C) Copyright IBM Corp. 2022, 2023. All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: workflow
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 24.0.0
spec:
  appVersion: 24.0.0

  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""

  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:

    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_fncm_license: "<Required>"

    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"
    
    
   
    ## All CP4A components must use/share the image_pull_secrets to pull images
    image_pull_secrets:
    - ibm-entitlement-key

    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io

    ## Specify the RunAsUser for the security context of the pod.  This is usually a numeric value that corresponds to a user ID.
    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is optional. It is not supported on OCP and ROKS.
    sc_run_as_user:

    ## If your Openshift cluster is configured for Hugepages and you want the applicable deployment resources to consume Hugepages.
    ## You must set "true" for sc_hugepages.enabled. Default is "false".
    ## You must set type for "Hugepages" like hugepages-2Mi or hugepages-1Gi. Default is "hugepages-2Mi".
    ## You must set size for value which is suitable for Openshift cluster.
    sc_hugepages:
      enabled: false
      type: ""
      value: ""

    ## This optional property is a string value corresponding to the “ipFamilyPolicy” property of the Kubernetes “service” object.
    ## This setting becomes particularly relevant in dual-stack environments where both IPv4 and IPv6 are enabled. 
    ## Here are the options you can specify for ipFamilyPolicy: SingleStack , PreferDualStack , RequireDualStack
    ## Only set this property if you want the “ipFamilyPolicy” property of the services created for CP4BA to be configured differently from the cluster-level settings. 
    ## Warning: Setting this property to a value not supported by your cluster will cause CP4BA deployment to fail.
    sc_service_ip_family_policy: 

    ## This optional property is a list value corresponding to the “ipFamilies” property of the Kubernetes “service” object.
    ## This parameter works in conjunction with the ipFamilyPolicy to define the IP addressing behaviors for the Service.
    ## You can set it to any of the following array values: ["IPv4"],["IPv6"],["IPv4","IPv6"] (dual-stack environment)
    ## Only set this property if you want the “ipFamilies” property of the services created for CP4BA to be configured differently from the cluster-level settings. 
    ## Warning: Setting this property to a value not supported by your cluster will cause CP4BA deployment to fail.
    sc_service_ip_families: 

    ## Optional setting for secure computing mode (seccomp) profile for CP4A containers.  The default seccomp profile is RuntimeDefault on OCP 4.11 (k8s v1.24) or higher. seccomp profile won't be created on OCP 4.10 (k8s v1.23) or lower.
    ## For more information on seccomp please refer to https://kubernetes.io/docs/tutorials/security/seccomp/ and https://docs.openshift.com/container-platform/4.12/security/seccomp-profiles.html
    ## NOTE: Defining a custom, localhost seccomp profile that is stricter than the default RuntimeDefault profile may cause our pods fail to start.  This custom profile should be created at the worker nodes.
    sc_seccomp_profile:
    #  type: # RuntimeDefault, Localhost, Unconfined
    #  localhost_profile: # Local path of custom seccomp profile when type `Localhost` is used. The custom profile must be accessible by the pod and must exist locally on all worker nodes.  For example: `/profiles/fine-grained.json`.

    images:
      keytool_job_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-jobcontainer
        tag: "24.0.0"
      dbcompatibility_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-dbcompatibility-initcontainer
        tag: "24.0.0"
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-initcontainer
        tag: "24.0.0"
      umsregistration_initjob:
        repository: cp.icr.io/cp/cp4a/baw/dba-umsregistration-initjob
        tag: "24.0.0"

      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent
      
    ## Used to sign all CP4A internal certificates for internal services communications. In most cases, this value should not be changed.
    ## All CP4A components must use/share the root_ca_secret in order for integration
    root_ca_secret: icp4a-root-ca

    ## Shared secret containing a wildcard certificate (and concatenated signers) to be used by all routes, unless overwritten for a specific component route.
    ## If this is not defined, all external routes will be signed with root_ca_secret.
    ## Starting with CP4BA 21.0.3 release, this parameter only applies to non-OCP deployments. For OCP, all external traffic is routed via a 
    ## common front door in Platform UI so custom TLS certificates must be configured in AutomationUIConfig. Please refer 
    ## to https://www.ibm.com/docs/en/cloud-paks/1.0?topic=foundation-custom-resources#automationuiconfig for more information.
    external_tls_certificate_secret:

    ## CP4A patterns or capabilities to be deployed.  This CR represents the "workflow" pattern
    sc_deployment_patterns: workflow

    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.
    ## The optional components are: bai,pfs,kafka. Please do not delete baw_authoring, because it determines that this is a Workflow Authoring environment.
    ## pfs will bring advanced full text search function to portal and workplace. And the external workplace can be enabled only when pfs is enabled
    ## kafka will install a kafka cluster and enable kafka service for workflow authoring
    sc_optional_components: baw_authoring

    ## The deployment type as selected by the user.  Possible values are: Starter and Production.
    sc_deployment_type: Production

    ## The deployment context, which has a default value of "CP4A".  Unless you are instructed to change this value or 
    ## know the reason to change this value, please leave the default value.
    sc_deployment_context: "CP4A"

    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform:

    sc_egress_configuration:
      ## Required. Enable or disable egress access to external systems.
      ## If "sc_restricted_internet_access" is defined and has no value set, then default will be "true". 
      ## If "sc_restricted_internet_access" is not defined (e.g., in the case of upgrade, the existing CR will not have sc_restricted_internet_access), then "sc_restricted_internet_access" will be "false"
      sc_restricted_internet_access: true
      ## Optional.  Kubernetes API server namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default are "openshift-kube-apiserver", "openshift-apiserver" for OCP and ROKS.
      sc_api_namespace:
      ## Optional.  Kubernetes API server port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`. 
      ## Default are 443,6443 for OCP and ROKS
      sc_api_port:
      ## Optional.  Kubernetes DNS service namespace(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`.
      ## "{}" can also be used as a value.  It is equivalent to all namespaces (eg: namespaceSelector:{})
      ## Default is "openshift-dns" for OCP and ROKS
      sc_dns_namespace:
      ## Optional.  Kubernetes DNS service port(s) (comma separated) to be used for egress network policy when `sc_restricted_internet_access: true` and `sc_deployment_platform: "other"`. 
      ## Default are 53,5353 for OCP and ROKS
      sc_dns_port:

    ## For OCP, this is used to create route, you should input a valid hostname in the required field.
     

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## For ROKS Ingress, provide TLS secret name for Ingress controller. If you are not using ROKS, comment out this line.
    sc_ingress_tls_secret_name: <Required>

    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []

    ## This is necessary if you want to use your own JDBC drivers and/or need to provide ICCSAP drivers.  If you are providing multiple JDBC drivers and ICCSAP drivers, 
    ## all the files must be compressed in a single file.
    ## First you need to package your drivers into a compressed package in the format of "saplibs/drivers_files" and/or 
    ## "jdbc/db2|oracle|postgresql|sqlserver/driver_files". For example, if you are providing your own DB2 and Oracle JDBC drivers and ICCSAP drivers, then the compressed 
    ## file should have the following structure and content:
    ##   /jdbc/db2/db2jcc4.jar
    ##   /jdbc/db2/db2jcc_license_cu.jar
    ##   /jdbc/oracle/ojdbc8.jar
    ##   /saplibs/libicudata.so.50
    ##   /saplibs/...
    ## Then you need to put the compressed package on an anonymously accessible web server and provide the link here.
    ## The CR can handle .zip files using unzip as well as .tar, .tar.gz, .tar.bz2, .tar.xz. Does not handle .gz files, .bz2 files, .xz, or .zst files that do not contain a .tar archive.    
    sc_drivers_url:

    ## Shared encryption key secret name that is used for Workflow or Workstream Services and Process Federation Server integration.
    ## This secret is also used by Workflow and BAStudio to store AES encryption key.
    encryption_key_secret: ibm-iaws-shared-key-secret

    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores,
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section
    ## is defined with the required parameters in the CR (below) and sc_content_initialization is set to "true" (or the parameter doesn't exist), then the initialization will occur.  
    ## However, if sc_content_initialization is set to "false", then the initialization will not occur (even with the "initialize_configuration" section defined)
    ## For Workflow Authoring, by default sc_content_initialization is set to "true" with "initialize_configuration"section filled.
    ## If you already initialized content or want to upgrade, please set sc_content_initialization to "false" before you apply the CR.
    sc_content_initialization: true

    ## Enable/disable the ECM (FNCM) / BAN verification (e.g., creation of test folder, creation of test document,
    ## execution of CBR search, and creation of Navigator demo repository and desktop).  If the "verify_configuration"
    ## section is defined in the CR and sc_content_verification is set to true, then the verification will occur.  Note that if you are upgrading or
    ## migrating, set this parameter to "false" since the env has been previously verified.
    sc_content_verification: false

    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "production" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.
    ## sc_block_storage_classname is for Zen, Zen requires/recommends block storage (RWO) for metastoreDB
    storage_configuration:
      sc_slow_file_storage_classname: "<Required>"
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"
      sc_block_storage_classname: "<Required>"

    ## The CPE container and other components that use HTTP Basic Authentication are configured to use the OAuth JaaS loginModule         
    ## to remove all remaining LDAP dependencies by allowing username/password credentials to be converted into an OAuth token for        
    ## authentication. When you are upgrading from a release prior to CP4BA 22.0.2 to 22.0.2 or later, or when
    ## you are migrating FileNet Content Manager on-prem or standalone deployment to IBM Cloud Pak for Business Automation (CP4BA), 
    ## you must set "sc_skip_ldap_config: false".  If you are performing fresh install using 23.0.2-IF004 or later, you can also set     
    ## "sc_skip_ldap_config: false" in order to have the FileNet Content Manager P8 domain to be configured with direct LDAP bind
    ## as opposed to the default SCIM configuration.
    sc_skip_ldap_config: true

    ## Enable/disable FIPS mode for the deployment (default value is "false")
    ## Note: If set as "true", in order to complete enablement of FIPS for CP4BA, please refer to "FIPS wall" configuration in IBM documentation.
    enable_fips: false

  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory" or "Custom"
    lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "<Required>"

    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute. Semicolon-separated list that must include the first RDN user distinguished names. One possible value is "*:uid" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "<Required>"

    ## Set to true if you want to enable LDAP nested search in IAM, by default it is false
    lc_ldap_recursive_search: false

    ## Set to true if you want to enable LDAP pagination in IAM, by default it is false
    lc_enable_pagination: false

    ## If lc_enable_pagination is set to true, then specify the pagination size. If not specified, the following default values will be used:
    ## IBM Tivoli Directory Server: 20000; Microsoft Active Directory:1000, and Custom: 4500
    lc_pagination_size: 1000 

    ## add custom group search bases to IAM
    lc_group_searchbase_list: []

    ## add custom user search bases to IAM
    lc_user_searchbase_list: []
    
    ## The lc_ldap_precheck parameter is used to enable or disable LDAP connection check.
    ## If set to "true", then LDAP connection check will be enabled.
    ## if set to "false", then LDAP connection check will not be enabled.
    # lc_ldap_precheck: true

    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
    #   lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
    # custom:
    #   lc_user_filter: "(&(objectClass=person)(cn=%v))"
    #   lc_group_filter:  "(&(objectClass=group)(cn=%v))"

    ## This is to add customized IAM SCIM LDAP attributes for this LDAP configuration, If you only add 'scim_configuration_iam', we will create SCIM LDAP attributes mapping using default values and the default value meant for IBM Security Directory Server only. Comment the whole section if you don't want this to be configured.
    # scim_configuration_iam:
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   user_unique_id_attribute: dn
    #   user_external_id_attribute: dn
    #   user_emails_attribute: mail
    #   user_name_attribute: uid
    #   user_display_name_attribute: cn
    #   user_groups_attribute: memberOf
    #   user_object_class_attribute: person
    #   user_principal_name_attribute: uid
    #   user_given_name_attribute: cn
    #   user_family_name_attribute: sn
    #   user_full_name_attribute: cn
    #   ## Optional:  Uncomment 'user_custom_mapping' and add any custom mapping below
    #   # user_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   group_unique_id_attribute: dn
    #   group_external_id_attribute: dn
    #   group_display_name_attribute : cn
    #   group_members_attribute: member
    #   group_object_class_attribute: groupOfNames
    #   group_name_attribute: cn
    #   group_principal_name_attribute: cn
    #   ## Optional:  Uncomment 'group_custom_mapping' and add any custom mapping below
    #   # group_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid

    ## This section allows to enhance the ldap configuration for the UMS SCIM capability. If lc_user_filter or lc_group_filter cannot handle a custom LDAP filter for user or group searches this section should be enabled.
    ## optional: enables the liberty ldapEntityType configuration and disables the usage of lc_user_filter, lc_group_filter, lc_ldap_group_member_id_map, lc_ldap_user_name_attribute and lc_ldap_group_name_attribute in the UMS capabilities.
    ## for detailed information about the ldapEntityType, loginProperty and groupProperties  parameters please see the liberty documentation: https://www.ibm.com/docs/en/was-liberty/nd?topic=configuration-ldapregistry
    ## default is false
    lc_use_ldap_entity_type:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## default is uid
    lc_ldap_login_property:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_user:
      object_class:
      search_base:
      search_filter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_group:
      object_class:
      search_base:
      search_filter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_group_properties:
      # member_attribute:
        # The name of the member. Required if member_attribute is set
        # name:
        # The name of the object class. Required member_attribute is set
        # object_class:
        ## the scope options are: all, direct, nested
        # scope:
      #membership_attribute:
        # The name of the membership. Required if membership_attribute is set
        # name:
        ## the scope options are: all, direct, nested
        # scope:

  ## The beginning section of multi ldap configuration for CP4BA
  # ldap_configuration_<id_name>:
    #lc_ldap_id: <id_name>
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory" or "Custom"
    #lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    #lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    #lc_ldap_port: "<Required>"

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    #lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    #lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    #lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute.  One possible value is "*:cn" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    #lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    #lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    #lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    #lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    #lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))" for TDS and AD
    #lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    #lc_ldap_group_member_id_map: "<Required>"

    ## The lc_ldap_precheck parameter is used to enable or disable LDAP connection check.
    ## If set to "true", then LDAP connection check will be enabled.
    ## if set to "false", then LDAP connection check will not be enabled.
    # lc_ldap_precheck: true

    ## Uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds) or custom for other LDAP type) accordingly.
    #ad:
    #  lc_ad_gc_host: "<Required>"
    #  lc_ad_gc_port: "<Required>"
    #  lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
    #  lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    #tds:
    #  lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #  lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"
    #custom:
    #  lc_user_filter: "(&(objectClass=person)(cn=%v))"
    #  lc_group_filter:  "(&(objectClass=group)(cn=%v))"

    ## This is to add customized IAM SCIM LDAP attributes for this LDAP configuration, If you only add 'scim_configuration_iam', we will create SCIM LDAP attributes mapping using default values and the default value meant for IBM Security Directory Server only. Comment the whole section if you don't want this to be configured.
    # scim_configuration_iam:
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   user_unique_id_attribute: dn
    #   user_external_id_attribute: dn
    #   user_emails_attribute: mail
    #   user_name_attribute: uid
    #   user_display_name_attribute: cn
    #   user_groups_attribute: memberOf
    #   user_object_class_attribute: person
    #   user_principal_name_attribute: uid
    #   user_given_name_attribute: cn
    #   user_family_name_attribute: sn
    #   user_full_name_attribute: cn
    #   ## Optional:  Uncomment 'user_custom_mapping' and add any custom mapping below
    #   # user_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid
    #   ## This attribute MUST be set to an LDAP attribute that is unique and immutable
    #   group_unique_id_attribute: dn
    #   group_external_id_attribute: dn
    #   group_display_name_attribute : cn
    #   group_members_attribute: member
    #   group_object_class_attribute: groupOfNames
    #   group_name_attribute: cn
    #   group_principal_name_attribute: cn
    #   ## Optional:  Uncomment 'group_custom_mapping' and add any custom mapping below
    #   # group_custom_mapping:
    #     # <scim_attr_name> : <ldap attr name>
    #     # like below
    #     # ibmentryuuid : ibm-entryuuid

  ## The idp_iam_configuration is meant when you have an identity provider configured in iam that isn't a directory provider service
  ## Such as Okta or AzureAD configured in IAM as the identity provider.
  ## Set the idp_id to the name giving to the identity provider configured in IAM.
  ## Set the idp_type.  Supported types are okta or azuread.
  ## idp_allow_email_or_upn_short_names by default is true. Only specify idp_allow_email_or_upn_short_names: false if
  ## email or upn short name is not used to login
  #idp_iam_configuration:
  #  - idp_id: <idp_name>
  #    idp_type: okta (or azuread) 
  #    idp_allow_email_or_upn_short_names: true (optional - default value is true) 

  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle/PostgreSQL.
    dc_ssl_enabled: true
    ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
    ## If set to "true", then CPE/Navigator database connection check will be enabled.
    ## if set to "false", then CPE/Navigator database connection check will not be enabled.
   # database_precheck: true
    ## The database configuration for the GCD datasource for CPE
    dc_gcd_datasource:
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for a GCD database, set this parameter to true
      dc_use_postgres: false
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".
      dc_database_type: "<Required>"
      ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
      dc_common_gcd_datasource_name: "FNGCDDS"
      ## The GCD XA datasource name. The default value is "FNGCDDSXA".
      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_servername: "<Required>"
      ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_gcd_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15

      ## If the database type is Db2 HADR, then complete the rest of the parameters below.
      ## Provide the database server name or IP address of the standby database server.
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m 
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for the document object store (DOCS) datasource for CPE
    dc_os_datasources:
    ## object store for BAW DOCS. Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the GCD configuration above.
    - dc_database_type: "<Required>"
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for an OS database, set this parameter to true
      dc_use_postgres: false
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOCS non-XA datasource name.  The default value is "BAWDOCS".
      dc_common_os_datasource_name: "BAWDOCS"
      ## The DOCS XA datasource name.  The default value is "BAWDOCSXA".
      dc_common_os_xa_datasource_name: "BAWDOCSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter. This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m 
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool
    ## The database configuration for the target object store (TOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for an OS database, set this parameter to true
      dc_use_postgres: false
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The TOS non-XA datasource name.  The default value is "BAWTOS".
      dc_common_os_datasource_name: "BAWTOS"
      ## The TOS XA datasource name.  The default value is "BAWTOSXA".
      dc_common_os_xa_datasource_name: "BAWTOSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter. This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m 
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool
    ## The database configuration for the design object store (DOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Operator will now have a capability to automatically provision an EDBPostgres instance upon request for Production/Enterprise deployment
      ## If you want PostgresDB to be created for an OS database, set this parameter to true
      dc_use_postgres: false
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOS non-XA datasource name.  The default value is "BAWDOS".
      dc_common_os_datasource_name: "BAWDOS"
      ## The DOS XA datasource name.  The default value is "BAWDOSXA".
      dc_common_os_xa_datasource_name: "BAWDOSXA"
      ## Provide the database server name or IP address of the database server. As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter. This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m 
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for CPE, Operator will only add them as data source for CPE, won't create Object Store for these database connection.
    dc_cpe_datasources:
    #--------------------------------------------------------------------------------------------------------------------------------
    # This sections contains 1 CPE data source: Case History Store CPE data source
    # It is required when you want to enable case history emitter feature. Please uncomment it when enabling case history emitter
    #--------------------------------------------------------------------------------------------------------------------------------
    #   #CPE data source for Case History Store
    #   # Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the
    #   # GCD configuration above.
    # - dc_database_type: "<Required>"
    #   ## Provide the label for the CPE data source.  The default value is "os" if not defined.
    #   ## This label must match the secret you define in ibm-fncm-secret.
    #   ## If you define dc_os_label: "ch" , then your secret must be defined as:
    #   ## --from-literal=chDBUsername="<your db username>" --from-literal=chDBPassword="<your db password>".
    #   ## If all the CPE datasource databases share the same username and password, then dc_os_label value should be the same in all the datasource sections.
    #   dc_os_label: "ch"
    #   ## The XA datasource name.
    #   dc_common_cpe_xa_datasource_name: "CASEHISTORYDSXA"
    #   ## The non-XA datasource name.
    #   dc_common_cpe_datasource_name: "CASEHISTORYDS"
    #   ## Provide the database server name or IP address of the database server
    #   database_servername: "<Required>"
    #   ## Provide the name of the database for the CPE data source.  For example: "DS1DB"
    #   database_name: "<Required>"
    #   ## Provide the database server port.  For Db2, the default is "50000". As Oracle configuration requires a JDBC URL, set the parameter to no value or comment out the parameter.
    #   database_port: "<Required>"
    #   ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
    #   database_ssl_secret_name: "<Required>"
    #   ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
    #   dc_oracle_os_jdbc_url: "<Required>"
    #   ## Database connection name, database connection will be created according to your input
    #   dc_common_conn_name: "<Required>"
    #   ######################################################################################
    #   ## If the database type is "Db2HADR", then complete the rest of the parameters below.
    #   ## Otherwise, remove or comment out the rest of the parameters below.
    #   ######################################################################################
    #   dc_hadr_standby_servername: "<Required>"
    #   ## Provide the standby database server port.  For Db2, the default is "50000".
    #   dc_hadr_standby_port: "<Required>"
    #   ## Provide the validation timeout.  If not preference, keep the default value.
    #   dc_hadr_validation_timeout: 15
    #   ## Provide the retry internal.  If not preference, keep the default value.
    #   dc_hadr_retry_interval_for_client_reroute: 15
    #   ## Provide the max # of retries.  If not preference, keep the default value.
    #   dc_hadr_max_retries_for_client_reroute: 3
    #   ## Connection manager for a data source.
    #   connection_manager:
    #     ## Minimum number of physical connections to maintain in the pool.
    #     min_pool_size: 0
    #     ## Maximum number of physical connections for a pool.
    #     max_pool_size: 50
    #     ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
    #     max_idle_time: 1m
    #     ## Amount of time between runs of the pool maintenance thread.
    #     reap_time: 2m
    #     ## Specifies which connections to destroy when a stale connection is detected in a pool.
    #     purge_policy: EntirePool
  ########################################################################
  ########   IBM Business Automation Workflow Authoring configuration     ########
  ########################################################################
  workflow_authoring_configuration:

    image:
      ## Workflow Authoring image repository URL.
      repository: cp.icr.io/cp/cp4a/bas/workflow-authoring
      ## Image tag for Workflow Authoring container.
      tag: "24.0.0"
      ## Pull policy for Workflow Authoring container. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
      pullPolicy: IfNotPresent
    upgrade_job:
      ## Workflow Authoring database handling image repository URL.
      repository: cp.icr.io/cp/cp4a/baw/workflow-server-dbhandling
      ## Workflow Authoring database handling image repository tag.
      tag: "24.0.0"
      ## Pull policy for database handling. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
      pullPolicy: IfNotPresent
    bas_auto_import_job:
      ## Workflow Authoring Business Automation Studio toolkit init image repository URL.
      repository: cp.icr.io/cp/cp4a/baw/toolkit-installer
      ## Workflow Authoring Business Automation Studio toolkit init image repository tag.
      tag: "24.0.0"
      ## Pull policy for Workflow Authoring Business Automation Studio toolkit init image. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
      pullPolicy: IfNotPresent
    ibm_workplace_job:
      ## Workflow Authoring IBM Workplace deployment job image repository URL
      repository: cp.icr.io/cp/cp4a/baw/iaws-ibm-workplace
      ## Workflow Authoring IBM Workplace deployment job image repository tag.
      tag: "24.0.0"
      ## Pull policy for Workflow Authoring IBM Workplace deployment job image. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
      pull_policy: IfNotPresent

    ## The configurations for content integration for attachment in process
    content_integration:
      init_job_image:
        ## Image name for content integration container.
        repository: cp.icr.io/cp/cp4a/baw/iaws-ps-content-integration
        ## Image tag for content integration container.
        tag: "24.0.0"
        ## Pull policy for content integration container. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
        pull_policy: IfNotPresent
      ## Domain name for content integration. The value must be the same as initialize_configuration.ic_domain_creation.domain_name.
      domain_name: "P8DOMAIN"
      ## Object Store name for content integration.
      ## The value must be an existing object store in CPE.
      ## If use initialize_configuration for the object store initialization, the value must be one of initialize_configuration.ic_obj_store_creation.object_stores.
      object_store_name: "BAWDOCS"
      ## Admin secret for connecting to Content Platform Engine (CPE). This parameter is optional. If not set, it will autodetect CPE's admin secret in the same namespace.
      cpe_admin_secret: ""

    ## The configuration for case
    case:
      init_job_image:
        ## Image name for CASE init job container.
        repository: cp.icr.io/cp/cp4a/baw/workflow-server-case-initialization
        ## Image tag for CASE init job container.
        tag: "24.0.0"
        ## Pull policy for CASE init job container. Default value is IfNotPresent. Possible values are IfNotPresent, Always.
        pull_policy: IfNotPresent

      ## Domain name for CASE. The value must be the same as initialize_configuration.ic_domain_creation.domain_name.
      domain_name: "P8DOMAIN"
      ## Design Object Store name of CASE.
      ## The value must be the same as the oc_cpe_obj_store_symb_name value of one of the object stores defined in initialize_configuration.ic_obj_store_creation.object_stores.
      object_store_name_dos: "BAWDOS"
      tos_list:
      ## The tos_list is a list. You can deploy multiple Target Object Stores.
      ## For each Target Object Store, the object_store_name value must be the same as the oc_cpe_obj_store_symb_name value of one of the object stores defined in initialize_configuration.ic_obj_store_creation.object_stores.
      - object_store_name: "BAWTOS"        
        ## Connection point name for Target Object Store.
        ## See initialize_configuration.ic_obj_store_creation.object_stores[x].oc_cpe_obj_store_workflow_pe_conn_point_name.
        ## If oc_cpe_obj_store_workflow_pe_conn_point_name is not specified explicitly, the default value is pe_conn_<TOS_OS_DB_NAME>.
        connection_point_name: "pe_conn_target"
        ## Navigator desktop name for Target Object Store. The default value is the same as object_store_name.
        desktop_id: "baw"
        ## Name of the target environment or project area to register with the case components and associate with an IBM Content Navigator desktop.
        target_environment_name: "dev_env_connection_definition"
        ## Whether to use the Target Object Store as the default Target Object Store.
        ## If none of the Target Object Stores is set as default, the first one in the tos_list will be set as the default Target Object Store.
        is_default: true

      ## Persistent volume claim (PVC) name for case network shared directory.
      ## This parameter must be set to the same value as the Business Automation Navigator pvc_for_icn_pluginstore parameter.
      ## If navigator_configuration.datavolume.existing_pvc_for_icn_pluginstore is not specified explicitly, the default value is icn-pluginstore.
      network_shared_directory_pvc: "{{ navigator_configuration.datavolume.existing_pvc_for_icn_pluginstore.name | default('icn-pluginstore', true) }}"
      ## Custom package names for installing custom packages, where the value format is similar to package1.zip, package2.zip.
      custom_package_names: ""
      ## Custom extension names for installing custom packages, where the value format is similar to extension1.zip, extension2.zip.
      custom_extension_names: ""
      ## Number of seconds before a newly added or modified asset will take effect in the Case Client. The value must be an integer, e.g. "100."
      ## The default value will be used if it is not set.
      cpe_metadata_cache_time_to_live: ""
      ## The event emitter settings if you want to enable Case Event Emitter. The following example shows sample values:
      ## event_emitter:
      ##   date_sql: 20200630T002840Z
      ##   logical_unique_id: bawinst1
      ##   solution_list: SampleSolution1,SampleSolution2
      event_emitter:
      - tos_name:
        ## Connection point name for Target Object Store.
        connection_point_name:
        ## Creation date of the events.
        ## The emitter starts processing the events from that date. If a bookmark exists, the emitter ignores this parameter and processes the events from the bookmark.
        date_sql:
        ## An 8-character alphanumeric string without underscores.
        ## This value is always required. While processing, the emitter tracks the events that are processed by using the Content Engine Audit Processing Bookmark with a display name that is based on this value.
        ## Therefore, if the emitter is restarted and if the bookmark exists, the emitter processes the events from the last bookmark.
        logical_unique_id:
        ## Comma-separated list of all the case solution names that need to be processed. Add all the solutions that you want to be processed before you deploy the Case event emitter.
        solution_list:
        ## Comma-separated list of all the case types that need to be processed.
        casetype_list:
        ## Case event emitter batch size.
        emitter_batch_size:
        ## Whether to process FileNet Process Engine events in addition to IBM Business Automation Workflow events.
        process_pe_events:

      ## The event emitter settings if you want to enable Case History Emitter. The following example shows sample values:
      ## case_history_emitter:
      ##   enable: true
      ##   dc_common_cpe_datasource_name: "CASEHISTORYDS"
      ##   case_history_store_schema_name: "CHSCHEMA"
      ##
      case_history_emitter:
        ## To enable Case History Emitter, this parameter must be set to true.
        enable: false
        ## The name of the non-XA datasource of Case History Store (from dc_common_cpe_datasource_name in the dc_cpe_datasources section)
        ## This value is always required. To enable Case History Emitter, add the Case History database configuration in the dc_cpe_datasources section, and specify the non-XA datasource name(dc_common_cpe_datasource_name) as the value of this parameter.
        dc_common_cpe_datasource_name: "<Required>"
        ## The schema name for Case History Store.
        case_history_store_schema_name: "CHSCHEMA"
    ## Application engine configuration, because application engine is an array,
    ## when there is only one Application engine deployed along with this CR, below four parameters are not required.
    ## when there is more then one application engine deployed, below four parameters are required.
    appengine:
      ## App Engine hostname
      hostname: ""
      ## App Engine port
      port: "443"
      ## App Engine admin secret name
      admin_secret_name: ""
      ## App Engine context root. 
      ## The application default context root will be /{{ meta.name}}-{{ application engine instance name }}-aae
      ## Please adjust this value according to the App Engine instance you selected. Don't miss the slash in front of value
      context_root: ""


    ## storage configuration
    storage:
      ## Set to true to use dynamic storage provisioning. If set to false, you must set existing_pvc_for_logstore and existing_pvc_for_dumpstore.
      use_dynamic_provisioning: true
      ## Persistent volume claim (PVC) for generic files.
      existing_pvc_for_filestore: ""
      ## Minimum size of the persistent volume (PV) that is mounted as the generic file store.
      size_for_filestore: "1Gi"

    ## customize environment settings
    environment_config:
      ## Whether to show the Intelligent Task Prioritization service toggle button in the web user interface to allow the user to enable or disable this service.
      show_task_prioritization_service_toggle: false
      ## Whether to display the Intelligent Task Prioritization service toggle button. If this parameter is set to true, the previous parameter is ignored.
      always_run_task_prioritization_service: false
      csrf:
        ## Acceptable values in the Origin header field. The value of this property must be a comma-separated list of prefixes in the format protocol://host:port, e.g "https://example.com, http://example2.com:8080".
        origin_allowlist:
        ## Acceptable values in the Referer header field. The value of this property must be a comma-separated list of fully qualified host names, e.g "example1.com, example2.com".
        referer_allowlist:
      # Content security policy additional directive for all folders , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_all: []
      ## Content security policy additional directive for default-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_default_src: []
      ## Content security policy additional directive for script-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_script_src: []
      ## Content security policy additional directive for frame-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_frame_src: []
      ## Content security policy additional directive for object-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_object_src: []
      ## Content security policy additional directive for connect-src , e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_connect_src: []
      ## Content security policy additional directive for frame-ancestor, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_frame_ancestor: []
      ## Content security policy additional directive for img-src, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_img_src: []
      ## Content security policy additional directive for font-src, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_font_src: []
      ## Content security policy additional directive for style-src, e.g. ["https://hostname1","https://hostname2"]
      content_security_policy_additional_style_src: []

    ## federation config
    federation_config:
      workflow_server:
          ## Number of primary shards of the Elasticsearch/Opensearch index used to store Workflow Authoring data.
          index_number_of_shards: 3
          ## Number of shard replicas of the Elasticsearch/Opensearch index used to store Workflow Authoring data.
          index_number_of_replicas: 1
      case_manager:
            ## Case Manager object store name.
          - object_store_name: BAWTOS
            ## Number of primary shards of the Elasticsearch/Opensearch index used to store Case Manager object store data.
            index_number_of_shards: 3
            ## Number of shard replicas of the Elasticsearch/Opensearch index used to store Case Manager object store data.
            index_number_of_replicas: 1

    ## JVM options separated with spaces, for example: -Dtest1=test -Dtest2=test2.
    jvm_customize_options:

    ##  Workflow Authoring custom plain XML snippet
    ##  liberty_custom_xml: |+
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    ## The custom_xml_secret_name is also used for Workflow Authoring customization. Ensure the configuration value exists either in liberty_custom_xml or custom_xml_secret_name.
    ## Do not set the configuration value in both places.
    liberty_custom_xml:

    ## Workflow Authoring custom XML secret name that contains custom configuration in Liberty server.xml,
    ## put the custom.xml in secret with key "sensitiveCustomConfig"
    ## kubectl create secret generic wfs-custom-xml-secret --from-file=sensitiveCustomConfig=./custom.xml
    ## The liberty_custom_xml property is also used for Workflow Authoring customization. Ensure the configuration value exists either in liberty_custom_xml or custom_xml_secret_name.
    ## Do not set the configuration value in both places
    custom_xml_secret_name:

    ## Workflow Authoring Lombardi custom XML secret name that contains custom configuration in 100Custom.xml
    ## put the 100Custom.xml in secret with key "sensitiveCustomConfig"
    ##  100Custom.xml: |+
    ##  <properties>
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    ##  </properties> 
    #  kubectl create secret generic wfs-lombardi-custom-xml-secret --from-file=sensitiveCustomConfig=./100Custom.xml
    lombardi_custom_xml_secret_name:

    ##  IBM Business Automation Insights integration configuration
    business_event:
      ## Whether to enable event monitoring for Dynamic Event Framework events for the Workflow Services container.
      ## If Business Automation Insights and the Machine Learning Server parameters are configured, this parameter must be set to true.
      enable: false
      ## Whether to enable the task record in generated events. This optional parameter is equivalent to the task-record-enabled parameter,
      ## Also see https://www.ibm.com/support/knowledgecenter/SSYHZ8_20.0.x/com.ibm.dba.bai/topics/ref_bai_bpmn_summary_formats.html
      enable_task_record: true
      ## Whether to record additional task information in generated events.
      ## If Business Automation Insights and the Machine Learning Server parameters are configured, this parameter must be set to true.
      ## This parameter is equivalent to the enable_task_api_def parameter.
      ## Also see https://www.ibm.com/support/knowledgecenter/SSYHZ8_20.0.x/com.ibm.dba.bai/topics/ref_bai_bpmn_summary_formats.html
      enable_task_api: false
      ## List of the subscription configurations. Each subscription attribute is listed in the rest of this table.
      ## app_name: Name of the application that is the source of the events that are to be monitored.
      ## version: Version of the application to be monitored.
      ## component_type: Type of the component to be monitored.
      ## component_name: Name of the component to be monitored.
      ## element_type: Type of element to be monitored. BPMN types are PROCESS, ACTIVITY, EVENT, and GATEWAY.
      ## element_name: Name of the element to be monitored.
      ## nature: Nature of the event. One element can send events of various natures, such as STARTED, ACTIVE, COMPLETED.
      ##         The BPMN nature categories are STARTED, COMPLETED, TERMINATED, DELETED, FAILED, CAUGHT, THROWN, EXPECTED, ACTIVE, READY, RESOURCE_ASSIGNED, ACTIVE, LOOP_CONDITION_TRUE, LOOP_CONDITION_FALSE, and MULTIPLE_INSTANCES_STARTED.
      subscription:
      - {'app_name': '*','version': '*','component_type': '*','component_name': '*','element_type': '*','element_name': '*','nature': '*'}
    
    elasticsearch:
      ## Required only when you want to use external elasticsearch/opensearch for "data collector and data indexer" function. Endpoint of external elasticsearch/opensearch, such as: https://<external_es_host>:<external_es_port>.
      endpoint: ""
      ## Required only when you want to use external elasticsearch/opensearch for "data collector and data indexer" function. The external elasticsearch/opensearch administrative secret that contains the keys: username and password.
      ## If your instance does not have basic authentication, leave this parameter empty.      
      admin_secret_name: ""
      ## Optionally specify the number of seconds for elasticsearch/opensearch connection timeout.
      connect_timeout: 10s
      ## Optionally specify the number of seconds for elasticsearch/opensearch read timeout.
      read_timeout: 30s
      ## Optionally specify elasticsearch/opensearch thread count.
      thread_count: 0
      ## Optionally specify the maximum number of connections allowed across all routes when workflow authoring service connects to the elasticsearch/opensearch cluster to call its REST API.
      ## Specify a positive integer. If the provided value is less than or equal to 0, then the default Elasticsearch/Opensearch High Level REST Client value will be used.
      max_connection_total: -1
      ## Optionally specify the maximum number of connections allowed for a route when workflow authoring service connects to the elasticsearch/opensearch cluster to call its REST API.
      ## Specify a positive integer. If the provided value is less than or equal to 0, then the default Elasticsearch/Opensearch High Level REST Client value will be used.
      max_connection_per_route: -1

  ##################################################################################
  ########   IBM Business Automation Machine Learning Server configuration  ########
  ##################################################################################
  baml_configuration:
    ## Intelligent Task Prioritization configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true
    intelligent_task_prioritization:
      ## Intelligent Task Prioritization replica count
      ## The value takes priority when both profile size and replica properties are set
      replicas: 2
      ## Linux cron schedule expression used to trigger Intelligent Task Prioritization server to train model using data retrieved from Business Automation Insights server
      ## default value is '* 3 * * 0' every Sunday at 3AM UTC
      ## for examples: * 3 * * * : everyday at 3AM UTC,  */50 * * * *: every 50 minutes
      retrain_model_schedule: ""
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Intelligent Task Prioritization container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      ## Image name for Intelligent Task Prioritization container
      image:
        repository: cp.icr.io/cp/cp4a/baw/bui-task-prioritization
        ## Image tag for Intelligent Task Prioritization container
        tag: "24.0.0"
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for Intelligent Task Prioritization container
          cpu: "2"
          ## Memory limit for Intelligent Task Prioritization container
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for Intelligent Task Prioritization container
          cpu: "500m"
          ## Requested amount of memory for Intelligent Task Prioritization container
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_trained_pipelines
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "1Gi"
        ## The persistent volume claim for Intelligent Task Prioritization trained piplines files
        existing_pvc_for_trained_pipelines: ""
        ## The minimum size of the persistent volume used mounted as Intelligent Task Prioritization trained piplines files
        size_for_trained_pipelines: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
    ## Workforce Insights configuration
    ## if this configuration is enabled, setting bai_configuration.bpmn.install to true and bai_configuration.bpmn.force_elasticsearch_timeseries to true
    workforce_insights:
      ## Workforce Insights replica count
      ## The value takes priority when both profile size and replica properties are set
      replicas: 2
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Workforce Insights pod container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      image:
        repository: cp.icr.io/cp/cp4a/baw/workforce-insights
        tag: "24.0.0"
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for workforce insights
          cpu: "2"
          ## Memory limit for workforce insights
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for workforce insights
          cpu: "500m"
          ## Requested amount of memory for workforce insights
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "1Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
  ########################################################################
  ########   IBM FileNet Content Manager configuration            ########
  ########################################################################
  ecm_configuration:

    ## FNCM secret that contains GCD DB user name and password, Object Store DB user name and password,
    ## LDAP user and password, CPE username and password, keystore password, and LTPA passs, etc.
    fncm_secret_name: ibm-fncm-secret

    # Disable FIPS for the component (default value is "false"), change it to "true" if you enable FIPS mode for the deployment with shared_configuration.enable_fips = true, but want to disable FIPS mode for the component.
    disable_fips: false

    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.node_affinity.
    node_affinity:
      # Value in this field will be used as kubernetes.io/arch selector values. By default all support arch will be included
      # It will be transformed to node selector value
      # - key: kubernetes.io/arch
      #   operator: In
      #   values:
      #     - amd64
      #     - s390x
      #     - ppc64le
      deploy_arch:
      - amd64
      - s390x
      - ppc64le
      #-------------------------------------
      # custom_node_selector_match_expression will be added in node selector match expressions.
      # It accept array list inputs. You can assign mutiple selector match expressions except (kubernetes.io/arch)
      # Example value:
      # - key: kubernetes.io/hostname
      #   operator: In
      #   values:
      #     - worker0
      #     - worker1
      #     - worker3
      #-------------------------------------
      custom_node_selector_match_expression: []
    ## Values in this field will be used as annotations in all generated pods and it must be valid annotation key value pairs.
    # Example:
    # customAnnotationKey: customAnnotationValue
    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_annotations.
    ## To include '{{ }}' in annotation like '{{example}}', add a backward slash before curly brace like '\{\{example\}\}'.
    custom_annotations: {}
    ## Values in this field will be used as labels in all generated pods and it must be valid label key value pairs
    # Example:
    # customLabelKey: customLableValue
    ## This can be overwritten by componenent level definition for example ecm_configuration.cpe.custom_labels.
    custom_labels: {}

    # Optional performance tuning for Zen NGINX server.
    # For more information, please refer to https://www.nginx.com/blog/tuning-nginx/#keepalive_requests and https://nginx.org/en/docs/http/ngx_http_proxy_module.html.
    # This can be overwritten by componenent level definition for example ecm_configuration.graphql.zen_performance.
    # For CPE we allow more granular setting like below and they take precedence over ecm_configuration.cpe.zen_performance. 
    # cpe.zen_performance.acce
    # cpe.zen_performance.fncews40mtom
    # cpe.zen_performance.pewsi
    # cpe.zen_performance.peengine
    # cpe.zen_performance.p8ce
    zen_performance:
      # Timeout for establishing a connection with a proxy server. This parameter is optional. The default value is 300s.
      proxy_connect_timeout: 300
      # Timeout for transmitting a request to the proxy server. The timeout is set only between two successive write operations, not for the transmission of the whole request. If the proxy server does not receive anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
      proxy_send_timeout: 300
      # Timeout for reading a response from the proxy server. The timeout is set only between two successive read operations, not for the transmission of the whole response. If the proxy server does not transmit anything within this time, the connection is closed. This parameter is optional. The default value is 300s.
      proxy_read_timeout: 300
      
    ## Enable/disable basic auth. 
    ## From 22.0.2 this by default is true to use jaaslogin module
    ## Set this to false let FNCM component to use basic auth 
    # disable_basic_auth: true
    
    ####################################
    ## Start of configuration for CPE ##
    ####################################
    cpe:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cpe
        tag: "24.0.0"

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## Set securityContext for CPE deployment.
      security_context:
        ## Controls which group IDs containers add. For example "supplemental_groups: [1000620001,1000620002]"
        supplemental_groups:
        ## This can take an array of key value pairs to assign SELinux labels to a Container, for example
        ## selinux_options:
          ## level: "s0:c123,c456"
          ## type: "spc_t
        selinux_options:
        # Defines behavior for changing ownership and permission of the volume before being exposed inside a Pod. This field has two possible values (Always,OnRootMismatch)
        # For example fs_groupchangepolicy: "OnRootMismatch"
        fs_groupchangepolicy:
      
      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 1
          memory: 3072Mi
          ephemeral_storage: 4Gi
        limits:
          cpu: 1
          memory: 3072Mi
          ephemeral_storage: 4Gi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CPE Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cpe_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 18
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 33

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        ## If your JVM option contains comma then you have to include 'DELIM=;' to use a different separator, for example jvm_customize_options="DELIM=;-Dmy.test.jvm.arg1=123;-Dcom.filenet.authentication.wsi.AuthTokenOrder=oauth,oidc,ltpa". Semicolon can be replaced with any other char.
        ## If your JVM option contains double quotes then you need to escape it like this: jvm_customize_options="-Dsettings.navigator.default=logging.level={\"_value\":\"4\",\"_mergeOption\":\"replace\"}"
        jvm_customize_options:

        ## Default JNDI name for GCD for non-XA data source
        gcd_jndi_name: FNGCDDS
        ## Default JNDI name for GCD for XA data source
        gcd_jndixa_name: FNGCDDSXA
        license_model: FNCM.PVUNonProd
        license: accept

        ## GCD schema name - uncomment below code and update it's value with your custom GCD Schema name
        # gcd_schema:
        
        # This section is optional and it takes a list of configmaps. 
        # A configmap can hold files or environment data but it cannot a mix of both.
        # The volume_path is optional for a configmap that holds files as its data and if it's not specified,
        # then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
        # then is_env is required and set it to true.
        #
        # custom_configmap:
        #  - name: <name of configmap>
        #    volume_path:  # optional
        #  - name: <name of configmap>
        #    is_env: # required if the configmap holds environment variables.

        # This section you can set custom environments in the CR for the deployment
        # custom_env_var:
        # - some_custom_var_name: "some_custom_var_value"

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: true
      ## Enable/disable logging where logs can be sent to Elasticsearch/Opensearch.
      logging_enabled: true

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: true

      ## Persistent Volume Claims for CPE.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cpe_cfgstore: 
          name: "cpe-cfgstore"
          size: 1Gi
        existing_pvc_for_cpe_logstore: 
          name: "cpe-logstore"
          size: 1Gi
        existing_pvc_for_cpe_filestore: 
          name: "cpe-filestore"
          size: 1Gi
        existing_pvc_for_cpe_icmrulestore: 
          name: "cpe-icmrulesstore"
          size: 1Gi
        existing_pvc_for_cpe_textextstore: 
          name: "cpe-textextstore"
          size: 3Gi
        existing_pvc_for_cpe_bootstrapstore: 
          name: "cpe-bootstrapstore"
          size: 1Gi
        existing_pvc_for_cpe_fnlogstore: 
          name: "cpe-fnlogstore"
          size: 1Gi

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        startup:
          initial_delay_seconds: 120
          period_seconds: 30
          timeout_seconds: 10
          failure_threshold: 40
        liveness:
          period_seconds: 30
          timeout_seconds: 5
          failure_threshold: 6

      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "ibm-entitlement-key"
      ## This is only used to deploy CPE in AWS EKS Cluster, and it will create and mount aws-iam-token.
      #aws_iam:
      #  aws_iam_enable: true
      #  audience: "sts.amazonaws.com"
      #  expirationSeconds: 7200 
    #####################################
    ## Start of configuration for CMIS ##
    #####################################
    cmis:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cmis
        tag: "24.0.0"

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 1536Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cmis_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        ## If your JVM option contains comma then you have to include 'DELIM=;' to use a different separator, for example jvm_customize_options="DELIM=;-Dmy.test.jvm.arg1=123;-Dcom.filenet.authentication.wsi.AuthTokenOrder=oauth,oidc,ltpa". Semicolon can be replaced with any other char.
        ## If your JVM option contains double quotes then you need to escape it like this: jvm_customize_options="-Dsettings.navigator.default=logging.level={\"_value\":\"4\",\"_mergeOption\":\"replace\"}"
        jvm_customize_options:

        checkout_copycontent: true
        default_maxitems: 25
        cvl_cache: true
        secure_metadata_cache: false
        filter_hidden_properties: true
        querytime_limit: 180
        resumable_queries_forrest: true
        escape_unsafe_string_characters: false
        max_soap_size: 180
        print_pull_stacktrace: false
        folder_first_search: false
        ignore_root_documents: false
        supporting_type_mutability: false
        license: accept
        
        # This section is optional and it takes a list of configmaps. 
        # A configmap can hold files or environment data but it cannot a mix of both.
        # The volume_path is optional for a configmap that holds files as its data and if it's not specified,
        # then the files will be mounted to the overrides directory.  If the configmap data holds environment variables
        # then is_env is required and set it to true.
        #
        # custom_configmap:
        #  - name: <name of configmap>
        #    volume_path:  # optional
        #  - name: <name of configmap>
        #    is_env: # required if the configmap holds environment variables.

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: true
      ## Enable/disable logging where logs can be sent to Elasticsearch/Opensearch.
      logging_enabled: true

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: true

      ## Persistent Volume Claims for CMIS.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cmis_cfgstore: 
          name: "cmis-cfgstore"
          size: 1Gi
        existing_pvc_for_cmis_logstore: 
          name: "cmis-logstore"
          size: 1Gi


      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        startup:
          initial_delay_seconds: 90
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        readiness:
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          period_seconds: 10
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "ibm-entitlement-key"

  ########################################################################
  ########  IBM FileNet Content Manager initialize configuration  ########
  ########################################################################
  ## The deployment of FNCM will be initialized with the default values assigned to the parameters below.
  ## The initialization process includes the creation of the P8 domain, the creation of the directory services,
  ## the assignments of users/groups to the P8 domain and object store(s), the creation of the object store(s),
  ## the creation/addition of add-ons for each object store, the enablement of workflow for each object store, the
  ## creation of Content Search Services servers, index areas, and the enabling of Content-based Retrieval (CBR) for each object store.
  ## In addition, the creation of Navigator desktop will also occur.
  ## If any of the values below does not fit your infrastructure, then change the value to correpond to your configuration
  ## (e.g., "CEAdmin" is the default user for ic_ldap_admin_user_name parameter and if you do not have "CEAdmin" user in your directory
  ## server and have a different user, then replace "CEAdmin" with your own user).  Otherwise, the rest of the values should remain as default.
  initialize_configuration:
    ic_domain_creation:
      ## Provide a name for the domain
      domain_name: "P8DOMAIN"
      ## The encryption strength
      encryption_key: "128"
    ic_ldap_creation:
      ## Administrator user
      ic_ldap_admin_user_name:
      - "<Required>" # user name for P8 domain admin, for example, "CEAdmin".  This parameter accepts a list of values.
      ## Administrator group
      ic_ldap_admins_groups_name:
      - "<Required>" # group name for P8 domain admin, for example, "P8Administrators".  This parameter accepts a list of values.
      ## Name of the LDAP directory
      ic_ldap_name: "ldap_name"
    ic_obj_store_creation:
      object_stores:
      ## Configuration for the document object store
      ## Display name for the document object store to create
      - oc_cpe_obj_store_display_name: "BAWDOCS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "BAWDOCS"
        oc_cpe_obj_store_schema_name: "bawdocs"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOCS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "BAWDOCS"
          ## The XA datasource
          dc_os_xa_datasource_name: "BAWDOCSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values. 
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os01_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        # Enable the content event emitter only when deploying BAI.
        # Default value is false if not specified in the CR.
        oc_cpe_obj_store_enable_content_event_emitter: false
        # Enable/disable object store database compression.  Default is false.
        oc_cpe_obj_store_enable_compression: false        
      ## Configuration for the design object store
      ## Display name for the design object store to create
      - oc_cpe_obj_store_display_name: "BAWDOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "BAWDOS"
        oc_cpe_obj_store_schema_name: "bawdos"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "BAWDOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "BAWDOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values. 
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os02_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        # Enable the content event emitter only when deploying BAI.
        # Default value is false if not specified in the CR.
        oc_cpe_obj_store_enable_content_event_emitter: false
        # Enable/disable object store database compression.  Default is false.
        oc_cpe_obj_store_enable_compression: false
      ## Configuration for the target object store
      ## Display name for the target object store to create
      - oc_cpe_obj_store_display_name: "BAWTOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "BAWTOS"
        oc_cpe_obj_store_schema_name: "bawtos"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "TOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "BAWTOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "BAWTOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values. 
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
         ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os03_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: true
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "tos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 3
        ## Specify a table space for the workflow data.
        oc_cpe_obj_store_workflow_data_tbl_space: "<Required>" 
        ## Optionally specify a table space for the workflow index.
        oc_cpe_obj_store_workflow_index_tbl_space: ""
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: ""
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: "pe_conn_target"
        # Enable the content event emitter only when deploying BAI.
        # Default value is false if not specified in the CR.
        oc_cpe_obj_store_enable_content_event_emitter: false
        # Enable/disable object store database compression.  Default is false.
        oc_cpe_obj_store_enable_compression: false


########################################################################
  ######## IBM FileNet Content Manager Verification configuration ######
  ########################################################################
  ## After the initialization process (see section above), the verification process will take place.
  ## The verification process ensures that the FNCM and BAN components are functioning correctly.  The verification
  ## process includes creation of a CPE folder, a CPE document, a CBR search, verifying the workflow configuration,
  ## and validation of the ICN desktop.
  verify_configuration:
    vc_cpe_verification:
      vc_cpe_folder:
      - folder_cpe_obj_store_name: "BAWTOS"
        folder_cpe_folder_path: "/TESTFOLDER"
      vc_cpe_document:
      - doc_cpe_obj_store_name: "BAWTOS"
        doc_cpe_folder_name: "/TESTFOLDER"
        doc_cpe_doc_title: "test_title"
        DOC_CPE_class_name: "Document"
        doc_cpe_doc_content: "This is a simple document test"
        doc_cpe_doc_content_name: "doc_content_name"
      vc_cpe_cbr:
      - cbr_cpe_obj_store_name: "BAWTOS"
        cbr_cpe_class_name: "Document"
        cbr_cpe_search_string: "is a simple"
      vc_cpe_workflow:
      - workflow_cpe_enabled: false
        workflow_cpe_connection_point: "pe_conn_os1"
