###############################################################################
#
# Licensed Materials - Property of IBM
#
# (C) Copyright IBM Corp. 2020. All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: workflow
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 20.0.3
spec:
  appVersion: 20.0.3.2

  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""

  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:

    ## Business Automation Workflow (BAW) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_baw_license: "<Required>"

    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_fncm_license: "<Required>"

    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"

    ## All CP4A components must use/share the image_pull_secrets to pull images
    image_pull_secrets:
    - admin.registrykey

    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io

    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is required
    sc_run_as_user:

    images:
      keytool_job_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-jobcontainer
        tag: 20.0.3-IF002
      dbcompatibility_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-dbcompatibility-initcontainer
        tag: 20.0.3-IF002
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/baw/dba-keytool-initcontainer
        tag: 20.0.3-IF002
      umsregistration_initjob:
        repository: cp.icr.io/cp/cp4a/baw/dba-umsregistration-initjob
        tag: 20.0.3-IF002

      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent

    ## All CP4A components must use/share the root_ca_secret in order for integration
    root_ca_secret: icp4a-root-ca

    ## CP4A patterns or capabilities to be deployed.  This CR represents the "workflow" pattern, which includes the following
    ## mandatory components: ban(Business Automation Navigator), ums (User Management Service), rr (Resource registry), app_engine( Application Engine) and optional components: bai, ae_data_persistence
    sc_deployment_patterns: workflow

    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.
    ## The optional components are: bai,ae_data_persistence. Please do not delete baw_authoring, because it determines that this is a Workflow Authoring environment.
    sc_optional_components: baw_authoring

    ## The deployment type as selected by the user.  Possible values are: demo, enterprise
    sc_deployment_type: enterprise

    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform:

    ## For OCP, this is used to create route, you should input a valid hostname in the required field.
    sc_deployment_hostname_suffix: "{{ meta.namespace }}.<Required>"

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## For ROKS Ingress, provide TLS secret name for Ingress controller.
    sc_ingress_tls_secret_name: <Required>

    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []

    ## Shared encryption key secret name that is used for Workflow or Workstream Services and Process Federation Server integration.
    ## This secret is also used by Workflow and BAStudio to store AES encryption key.
    encryption_key_secret: "<Required>"

    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores,
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section
    ## is defined in the CR, then that configuration will take precedence overriding this parameter.
    sc_content_initialization: false
    ## Enable/disable the ECM (FNCM) / BAN verification (e.g., creation of test folder, creation of test document,
    ## execution of CBR search, and creation of Navigator demo repository and desktop).  If the "verify_configuration"
    ## section is defined in the CR, then that configuration will take precedence overriding this parameter.
    sc_content_verification: false

    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "enterprise" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.
    storage_configuration:
      sc_slow_file_storage_classname: "<Required>"
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"

  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory"
    lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "<Required>"

    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute.  One possible value is "*:cn" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(&(cn=%v)(|(objectclass=groupOfNames)(objectclass=groupOfUniqueNames)(objectclass=groupOfURLs)))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "<Required>"

    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(samAccountName=%v)(objectClass=user))"
    #   lc_group_filter: "(&(samAccountName=%v)(objectclass=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"

  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle.
    dc_ssl_enabled: true
    ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
    ## If set to "true", then CPE/Navigator database connection check will be enabled.
    ## if set to "false", then CPE/Navigator database connection check will not be enabled.
   # database_precheck: true
    ## The database configuration for the GCD datasource for CPE
    dc_gcd_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".
      dc_database_type: "<Required>"
      ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
      dc_common_gcd_datasource_name: "FNGCDDS"
      ## The GCD XA datasource name. The default value is "FNGCDDSXA".
      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
      ## Provide the database server name or IP address of the database server.
      database_servername: "<Required>"
      ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_gcd_jdbc_url: "<Required>"

      ## If the database type is Db2 HADR, then complete the rest of the parameters below.
      ## Provide the database server name or IP address of the standby database server.
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3

    ## The database configuration for the document object store (DOCS) datasource for CPE
    dc_os_datasources:
    ## object store for BAW DOCS. Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle".  This should be the same as the GCD configuration above.
    - dc_database_type: "<Required>"
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOCS non-XA datasource name.  The default value is "BAWDOCS".
      dc_common_os_datasource_name: "BAWDOCS"
      ## The DOCS XA datasource name.  The default value is "BAWDOCSXA".
      dc_common_os_xa_datasource_name: "BAWDOCSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    ## The database configuration for the target object store (TOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The TOS non-XA datasource name.  The default value is "BAWTOS".
      dc_common_os_datasource_name: "BAWTOS"
      ## The TOS XA datasource name.  The default value is "BAWTOSXA".
      dc_common_os_xa_datasource_name: "BAWTOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
    ## The database configuration for the design object store (DOS) datasource for CPE
    - dc_database_type: "<Required>"
      ## Provide the object store label for the object store.  The default value is "os" or not defined.
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
      ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If you have multiple object stores, then you need to define multiple datasource sections starting
      ## at "dc_database_type" element.
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same
      ## in all the datasource sections.
      dc_os_label: "<Required>"
      ## The DOS non-XA datasource name.  The default value is "BAWDOS".
      dc_common_os_datasource_name: "BAWDOS"
      ## The DOS XA datasource name.  The default value is "BAWDOSXA".
      dc_common_os_xa_datasource_name: "BAWDOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "OS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2 SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3

    #--------------------------------------------------------------------------------------------------------------------------------
    # This sections contains 1 object store' data sources: Business Automation Application Data Persistence(ae_data_persistence) object store(AEOS) data source
    # It is required when you want to enable ae_data_persistence optional feature. Please uncomment it when enabling ae_data_persistence
    #--------------------------------------------------------------------------------------------------------------------------------
    # ## object store for AEOS
    # - dc_database_type: "<Required>"
    #   ## Provide the object store label for the object store.  The default value is "os" or not defined.
    #   ## This label must match the OS secret you define in ibm-fncm-secret.
    #   ## For example, if you define dc_os_label: "abc", then your OS secret must be defined as:
    #   ## --from-literal=abcDBUsername="<your os db username>" --from-literal=abcDBPassword="<your os db password>"
    #   ## If you don't define dc_os_label, then your secret will be defined as:
    #   ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
    #   ## If you have multiple object stores, then you need to define multiple datasource sections starting
    #   ## at "dc_database_type" element.
    #   ## If all the object store databases share the same username and password, then dc_os_label value should be the same
    #   ## in all the datasource sections.
    #   dc_os_label: "<Required>"
    #   ## The AEOS non-XA datasource name.  The default value is "AEOS".
    #   dc_common_os_datasource_name: "AEOS"
    #   ## The AEOS XA datasource name.  The default value is "AEOSXA".
    #   dc_common_os_xa_datasource_name: "AEOSXA"
    #   ## Provide the database server name or IP address of the database server.  This should be the same as the
    #   ## GCD configuration above.
    #   database_servername: "<Required>"
    #   ## Provide the name of the database for the object store AEOS for CPE.  For example: "AEOSDB"
    #   database_name: "<Required>"
    #   ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
    #   database_port: "<Required>"
    #   ## The name of the secret that contains the DB2 SSL certificate.
    #   database_ssl_secret_name: "<Required>"
    #   ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
    #   dc_oracle_os_jdbc_url: "<Required>"
    #   ######################################################################################
    #   ## If the database type is "Db2HADR", then complete the rest of the parameters below.
    #   ## Otherwise, remove or comment out the rest of the parameters below.
    #   ######################################################################################
    #   dc_hadr_standby_servername: "<Required>"
    #   ## Provide the standby database server port.  For Db2, the default is "50000".
    #   dc_hadr_standby_port: "<Required>"
    #   ## Provide the validation timeout.  If not preference, keep the default value.
    #   dc_hadr_validation_timeout: 15
    #   ## Provide the retry internal.  If not preference, keep the default value.
    #   dc_hadr_retry_interval_for_client_reroute: 15
    #   ## Provide the max # of retries.  If not preference, keep the default value.
    #   dc_hadr_max_retries_for_client_reroute: 3

  ########################################################################
  ########   IBM Business Automation Workflow Authoring configuration     ########
  ########################################################################
  workflow_authoring_configuration:
    ## Workflow Authoring service type.
    service_type: "Route"
    ## Workflow Authoring hostname
    hostname: ""
    ## Workflow Authoring port
    port: 443
    ## Workflow Authoring nodeport
    nodeport: 30026
    ## Workflow Authoring replica count
    replicas: 1
    ## Provide Workflow Authoring default administrator ID
    admin_user: "<Required>"
    ## The name of Workflow Authoring admin secret, the secret name is optional, if the secret name is null, default secret named {{ meta.name }}-baw-admin-secret will be generated
    admin_secret_name: "{{ meta.name }}-baw-admin-secret"
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false
    external_connection_timeout: ""

    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use the customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use the customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:

    tls:
      ## Workflow Authoring TLS secret that contains tls.key and tls.crt.
      tls_secret_name: ibm-baw-tls
      ## Workflow Authoring TLS trust list.
      ## You might specify a list of secrets, every secret stores a trusted CA
      ## kubectl create secret generic baw_custom_trust_ca_secret1 --from-file=tls.crt=./ca1.crt
      tls_trust_list:
      ## The parameter is optional, if you want Workflow Authoring to trust your custom trusted CAs, you can add them to a keystore and then create a secret to store the trusted keystore.
      ## The keystore type must be JKS or PKCS12.
      ## kubectl create secret generic baw_custom_trusted_keystore_secret --from-file=truststorefile=./trust.p12 --from-literal=type=PKCS12  --from-literal=password=WebAS
      tls_trust_store:

    image:
      ## Workflow image repository URL
      repository: cp.icr.io/cp/cp4a/bas/workflow-authoring
      ## Image tag for Workflow Authoring container
      tag: 20.0.3-IF002
      ## Pull policy for Workflow container
      pullPolicy: IfNotPresent
    pfs_bpd_database_init_job:
      ## Database initialization image repository URL for Process Federation Server
      repository: cp.icr.io/cp/cp4a/baw/pfs-bpd-database-init-prod
      ## Image tag for database initialization for Process Federation Server
      tag: 20.0.3-IF002
      ## Pull policy for Process Federation Server database initialization image
      pullPolicy: IfNotPresent
    upgrade_job:
      ## Workflow Authoring database handling image repository URL
      repository: cp.icr.io/cp/cp4a/baw/workflow-server-dbhandling
      ## Image tag for Workflow Authoring database handling
      tag: 20.0.3-IF002
      ## Pull policy for Workflow Authoring database handling
      pullPolicy: IfNotPresent
    bas_auto_import_job:
      ## BAS toolkit init image repository URL
      repository: cp.icr.io/cp/cp4a/baw/toolkit-installer
      ## Image tag for BAS toolkit init image
      tag: 20.0.3-IF002
      ## Pull policy for BAS toolkit init image
      pullPolicy: IfNotPresent
    ibm_workplace_job:
      ## IBM Workplace deployment job image repository URL
      repository: cp.icr.io/cp/cp4a/baw/iaws-ibm-workplace
      ## Image tag for IBM Workplace deployment job image
      tag: 20.0.3-IF002
      ## Pull policy for IBM Workplace deployment job image
      pull_policy: IfNotPresent

    ## The database configuration for Workflow Authoring
    database:
      ## Whether to enable Secure Sockets Layer (SSL) support for the Workflow Authoring database connection
      enable_ssl: true
      ## Secret name for storing the database TLS certificate when enable SSL connections to the Workflow Authoring databae engine. Required only when enable_ssl is true
      db_cert_secret_name: "<Required>"
      ## Workflow Authoring database type, Possible values are: db2, oracle, postgresql
      type: "<Required>"
      ## Workflow Authoring database server name
      server_name: "<Required>"
      ## Workflow Authoring database name
      database_name: "<Required>"
      ## Workflow Authoring database port. For DB2, the default value is "50000"
      port: "<Required>"
      ## Workflow Authoring database secret name which include the database user name and password.
      secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      jdbc_url:
      ## Set to true if using custom JDBC drivers (For example using Oracle, PostgreSQL or some special DB2 driver)
      use_custom_jdbc_drivers: false
      ## The PVC name which bind to the PV which have the custom JDBC driver files stored
      custom_jdbc_pvc:
      ## The custom JDBC driver files set
      jdbc_driver_files: 'db2jcc4.jar db2jcc_license_cisuz.jar db2jcc_license_cu.jar'
      ## Workflow Authoring database connect pool maximum number of physical connections
      cm_max_pool_size: 200
      dbcheck:
        ## The maximum waiting time (seconds) to check the database intialization status
        wait_time: 900
        ## The interval time (seconds) to check.
        interval_time: 15
      hadr:
        ## Database standby host for high availability disaster recovery (HADR)
        ## To enable database HADR, configure both standby host and port
        standbydb_host:
        ## Database standby port for HADR
        standbydb_port:
        ## Retry interval for HADR
        retryinterval:
        ## Maximum retries for HADR
        maxretries:

    ## The configurations for content integration
    content_integration:
      init_job_image:
        ## Image name for content integration container.
        repository: cp.icr.io/cp/cp4a/baw/iaws-ps-content-integration
        ## Image tag for content integration container
        tag: 20.0.3-IF002
        ## Pull policy for content integration container.
        pull_policy: IfNotPresent
      ## Domain name for content integration
      domain_name: "P8DOMAIN"
      ## Object Store name for content integration
      object_store_name: "BAWDOCS"
      ## Admin secret for content integration
      cpe_admin_secret: ""

    ## The configuration for case
    case:
      init_job_image:
        ## Image name for CASE init job container.
        repository: cp.icr.io/cp/cp4a/baw/workflow-server-case-initialization
        ## Image tag for CASE init job container.
        tag: 20.0.3-IF002
        ## Pull policy for CASE init job container.
        pull_policy: IfNotPresent

      ## Domain name for CASE
      domain_name: "P8DOMAIN"
      ## Design Object Store name of CASE
      object_store_name_dos: "BAWDOS"
      ## Target Object Store name of CASE
      object_store_name_tos: "BAWTOS"
      ## Connection point name for Target Object Store
      connection_point_name_tos: "pe_conn_target"

      ## Name of the target environment/project area to register with the case components and associate with an IBM Content Navigator desktop
      target_environment_name: "dev_env_connection_definition"

      ## PVC name for CASE network shared directory
      network_shared_directory_pvc: "{{ navigator_configuration.datavolume.existing_pvc_for_icn_pluginstore | default('icn-pluginstore', true) }}"
      ## The custom package names if need to install custom package, the value format like "package1.zip, package2,zip"
      custom_package_names: ""
      ## The custom extension names if need to install custom extension, the value format like "extension1.zip, extension2,zip"
      custom_extension_names: ""
      ## The event emitter settings if you want to enable Case Event Emitter
      event_emitter:
        date_sql:
        logical_unique_id:
        solution_list:
        emitter_batch_size:
        process_pe_events:
    ## Resource configuration for init job
    resources_init:
      limits:
        ## CPU limit
        cpu: "500m"
        ## Memory limit
        memory: 256Mi
      requests:
        ## Requested amount of CPU
        cpu: "200m"
        ## Requested amount of memory
        memory: 128Mi

    ## Resource configuration for heavy init job such as database init job
    resources_init_heavy_job:
      limits:
        ## CPU limit
        cpu: 1
        ## Memory limit
        memory: 1536Mi
      requests:
        ## Requested amount of CPU
        cpu: "500m"
        ## Requested amount of memory
        memory: 512Mi

    ## The configuration for Java Messaging Service(JMS)
    jms:
      image:
        ## Image name for Java Messaging Service container
        repository: cp.icr.io/cp/cp4a/baw/jms
        ## Image tag for Java Messaging Service container
        tag: 20.0.3-IF002
        ## Pull policy for Java Messaging Service container
        pull_policy: IfNotPresent
      tls:
        ## TLS secret name for Java Message Service (JMS)
        tls_secret_name: ibm-jms-tls-secret
      resources:
        limits:
          ## Memory limit for JMS configuration
          memory: "2Gi"
          ## CPU limit for JMS configuration
          cpu: "1000m"
        requests:
          ## Requested amount of memory for JMS configuration
          memory: "512Mi"
          ## Requested amount of CPU for JMS configuration
          cpu: "200m"
      storage:
        ## Whether to enable persistent storage for JMS
        persistent: true
        ## Size for JMS persistent storage
        size: "1Gi"
        ## Whether to enable dynamic provisioning for JMS persistent storage
        use_dynamic_provisioning: true
        ## Access modes for JMS persistent storage
        access_modes:
        - ReadWriteOnce
        ## Storage class name for JMS persistent storage
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"
      ## Default values for liveness probes. Modify these values to meet your requirements.
      liveness_probe:
        initial_delay_seconds: 180
        period_seconds: 20
        timeout_seconds: 10
        failure_threshold: 3
        success_threshold: 1
      ## Default values for rediness probes. Modify these values to meet your requirements.
      readiness_probe:
        initial_delay_seconds: 30
        period_seconds: 5
        timeout_seconds: 5
        failure_threshold: 6
        success_threshold: 1

    ## Resource configuration
    resources:
      limits:
        ## CPU limit for Workflow Authoring.
        cpu: 4
        ## Memory limit for Workflow Authoring
        memory: 3Gi
      requests:
        ## Requested amount of CPU for Workflow Authoring
        cpu: "500m"
        ## Requested amount of memory for Workflow Authoring.
        memory: 1048Mi

    ## liveness and readiness probes configuration
    probe:
      ws:
        liveness_probe:
          ## Number of seconds after the Workflow Authoring container starts before the liveness probe is initiated
          initial_delay_seconds: 300
          ## Number of seconds to wait before the next probe.
          period_seconds: 10
          ## Number of seconds after which the probe times out.
          timeout_seconds: 10
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 3
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1
        readinessProbe:
          ## Number of seconds after the Workflow Authoring container starts before the readiness probe is initiated
          initial_delay_seconds: 240
          ## Number of seconds to wait before the next probe.
          period_seconds: 5
          ## Number of seconds after which the probe times out.
          timeout_seconds: 5
          ## When a probe fails, number of times that Kubernetes will try before giving up and restarting the container.
          failure_threshold: 6
          ## Minimum consecutive successes for the probe to be considered successful after it failed.
          success_threshold: 1

    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## The required format for the messages.log file. Valid values are SIMPLE or JSON format
      message_format: "SIMPLE"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"
      # Maximum number of log files that are kept before the oldest file is removed
      max_files: 10
      # The maximum size (in MB) that a log file can reach before it is rolled.
      max_filesize: 50

    ## storage configuration
    storage:
      ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_dumpstore
      use_dynamic_provisioning: true
      ## The persistent volume claim for logs
      existing_pvc_for_logstore: ""
      ## The minimum size of the persistent volume used mounted as log store
      size_for_logstore: "10Gi"
      ## The persistent volume claim for dump files
      existing_pvc_for_dumpstore: ""
      ## The minimum size of the persistent volume used mounted as dump store
      size_for_dumpstore: "10Gi"
      ## The persistent volume claim for generic files
      existing_pvc_for_filestore: ""
      ## The minimum size of the persistent volume used mounted as generic file store
      size_for_filestore: "10Gi"
      ## The persistent volume claim for search index files
      existing_pvc_for_indexstore: ""
      ## The minimum size of the persistent volume used mounted as search index file store
      size_for_indexstore: "10Gi"

    ## autoscaling
    autoscaling:
      enabled: false
      max_replicas: 3
      min_replicas: 2
      target_cpu_utilization_percentage: 80

    ## customize environment settings
    environment_config:
      ## Whether to show intelligent task prioritization service toggle button in web UI to allow task user enable/disable task prioritization service
      show_task_prioritization_service_toggle: false
      ## By default, it is false. If 'always_run_task_prioritization_service' is set to true, the value of the 'show_task_prioritization_service_toggle' is ignored and the toggle is not displayed to the user.
      always_run_task_prioritization_service: false

    ## federation config
    federation_config:
      workflow_server:
          index_number_of_shards: 3
          index_number_of_replicas: 1
      case_manager:
          - object_store_name: BAWTOS
            index_number_of_shards: 3
            index_number_of_replicas: 1

    ## JVM options separated with space, for example: -Dtest1=test -Dtest2=test2
    jvm_customize_options:

    ##  Workflow Authoring custom plain XML snippet
    ##  liberty_custom_xml: |+
    ##    <server>
    ##      <!-- custom propeties here -->
    ##    </server>
    liberty_custom_xml:

    ##  Workflow Authoring custom XML secret name that contains custom configuraiton in Liberty server.xml
    custom_xml_secret_name:

    ##  Workflow Authoring Lombardi custom XML secret name that contains custom configuraiton in 100Custom.xml
    lombardi_custom_xml_secret_name:

    ##  IBM Business Automation Insights integration configuration
    business_event:
      enable: false
      enable_task_record: true
      enable_task_api: false
      subscription:
      - {'app_name': '*','version': '*','component_type': '*','component_name': '*','element_type': '*','element_name': '*','nature': '*'}

  ##################################################################################
  ########   IBM Business Automation Machine Learning Server configuration  ########
  ##################################################################################
  baml_configuration:
    ## Intelligent Task Prioritization configuration
    intelligent_task_prioritization:
      ## Intelligent Task Prioritization replica count
      replicas: 2
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Intelligent Task Prioritization container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      ## Image name for Intelligent Task Prioritization container
      image:
        repository: cp.icr.io/cp/cp4a/baw/bui-task-prioritization
        ## Image tag for Intelligent Task Prioritization container
        tag: "20.0.3-IF002"
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for Intelligent Task Prioritization container
          cpu: "2"
          ## Memory limit for Intelligent Task Prioritization container
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for Intelligent Task Prioritization container
          cpu: "500m"
          ## Requested amount of memory for Intelligent Task Prioritization container
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore and existing_pvc_for_trained_pipelines
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "10Gi"
        ## The persistent volume claim for Intelligent Task Prioritization trained piplines files
        existing_pvc_for_trained_pipelines: ""
        ## The minimum size of the persistent volume used mounted as Intelligent Task Prioritization trained piplines files
        size_for_trained_pipelines: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
    ## Workforce Insights configuration
    workforce_insights:
      ## Workforce Insights replica count
      replicas: 2
      ## readiness probes configuration
      probes:
        readiness:
          ## Number of seconds after the Workforce Insights pod container starts before the readiness probe is initiated
          initial_delay_seconds: 40
      image:
        repository: cp.icr.io/cp/cp4a/baw/workforce-insights
        tag: "20.0.3-IF002"
        pull_policy: IfNotPresent
      ## Resource configuration
      resources:
        limits:
          ## CPU limit for workforce insights
          cpu: "2"
          ## Memory limit for workforce insights
          memory: "2048Mi"
        requests:
          ## Requested amount of CPU for workforce insights
          cpu: "500m"
          ## Requested amount of memory for workforce insights
          memory: "1024Mi"
      ## storage configuration
      storage:
        ## Set to true to use dynamic storage provisioner. If set to false, then need set existing_pvc_for_logstore
        use_dynamic_provisioning: true
        ## The persistent volume claim for logs
        existing_pvc_for_logstore: ""
        ## The minimum size of the persistent volume used mounted as log store
        size_for_logstore: "10Gi"
      autoscaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        target_cpu_utilization_percentage: 80
  ########################################################################
  ########   IBM FileNet Content Manager configuration            ########
  ########################################################################
  ecm_configuration:

    ## FNCM secret that contains GCD DB user name and password, Object Store DB user name and password,
    ## LDAP user and password, CPE username and password, keystore password, and LTPA passs, etc.
    fncm_secret_name: ibm-fncm-secret

    ####################################
    ## Start of configuration for CPE ##
    ####################################
    cpe:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cpe
        tag: ga-556-p8cpe-la001

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 3072Mi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CPE Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cpe_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 18
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 33

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:

        ## Default JNDI name for GCD for non-XA data source
        gcd_jndi_name: FNGCDDS
        ## Default JNDI name for GCD for XA data source
        gcd_jndixa_name: FNGCDDSXA
        license_model: FNCM.PVUNonProd
        license: accept

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: true
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: true

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: true

      ## Persistent Volume Claims for CPE.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cpe_cfgstore: "cpe-cfgstore"
        existing_pvc_for_cpe_logstore: "cpe-logstore"
        existing_pvc_for_cpe_filestore: "cpe-filestore"
        existing_pvc_for_cpe_icmrulestore: "cpe-icmrulesstore"
        existing_pvc_for_cpe_textextstore: "cpe-textextstore"
        existing_pvc_for_cpe_bootstrapstore: "cpe-bootstrapstore"
        existing_pvc_for_cpe_fnlogstore: "cpe-fnlogstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 120
          period_seconds: 5
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 600
          period_seconds: 5
          timeout_seconds: 5
          failure_threshold: 6

      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"

    #####################################
    ## Start of configuration for CMIS ##
    #####################################
    cmis:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cmis
        tag: ga-305-cmis-if003

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 256Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cmis_production_setting:
        ## By default, this parameter is set by the Operator using the CPE service endpoint (e.g., "http://{{ meta.name }}-cpe-svc:9080/wsi/FNCEWS40MTOM")
        cpe_url:

        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:

        checkout_copycontent: true
        default_maxitems: 25
        cvl_cache: true
        secure_metadata_cache: false
        filter_hidden_properties: true
        querytime_limit: 180
        resumable_queries_forrest: true
        escape_unsafe_string_characters: false
        max_soap_size: 180
        print_pull_stacktrace: false
        folder_first_search: false
        ignore_root_documents: false
        supporting_type_mutability: false
        license: accept

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: true
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: true

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: true

      ## Persistent Volume Claims for CMIS.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cmis_cfgstore: "cmis-cfgstore"
        existing_pvc_for_cmis_logstore: "cmis-logstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 90
          period_seconds: 5
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 180
          period_seconds: 5
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"


  ########################################################################
  ########   IBM Process Federation Server configuration          ########
  ########################################################################
  pfs_configuration:
    ## Process Federation Server hostname
    hostname: ""
    ## Process Federation Server port
    port: 443
    ## How the HTTPS endpoint service should be published. Possible values are ClusterIP, NodePort, Route
    service_type: Route

    ## If use the external elasticsearch server, provide the following configuration
    elasticsearch:
      ## The endpoint of external elasticearch, such as: https://<external_es_host>:<external_es_port>
      endpoint: ""
      ## The external elasticsearch administrative secret that contains the username, password and .htpasswd.
      admin_secret_name: ""
      connect_timeout: 10s
      read_timeout: 30s
      thread_count: 0

    image:
      ## Process Federation Server image
      repository: cp.icr.io/cp/cp4a/baw/pfs-prod
      ## Process Federation Server image tag
      tag: "20.0.3-IF002"
      ## Process Federation Server image pull policy
      pull_policy: IfNotPresent

    ## Number of initial Process Federation Server pods
    replicas: 1
    ## Service account name for Process Federation Server pod
    service_account:
    ## Whether Kubernetes can (soft) or must not (hard) deploy Process Federation Server pods onto the same node. Possible values are "soft" and "hard".
    anti_affinity: hard

    ## Whether to enable default security roles  and possible values are: true and false
    enable_default_security_roles: true
    ## Name of the secret containing the Process Federation Server administration passwords, such as ltpaPassword, oidcClientPassword, sslKeyPassword
    admin_secret_name: ibm-pfs-admin-secret
    ## Name of the secret containing the files that will be mounted in the /config/configDropins/overrides folder
    config_dropins_overrides_secret: ""
    ## Name of the secret containing the files that will be mounted in the /config/resources/security folder
    resources_security_secret: ""
    ## Name of the custom libraries containing the files that will be mounted in the /config/resources/libs folder
    custom_libs_pvc: ""
    ## Whether to enable notification server and possible values are: true and false
    enable_notification_server: false
    ## The secret that contains the Transport Layer Security (TLS) key and certificate for external https visits. You can enter the secret name here.
    ## If you do not want to use the customized external TLS certificate, leave it empty.
    external_tls_secret:
    ## Certificate authority (CA) used to sign the external TLS secret. It is stored in the secret with the TLS key and certificate. You can enter the secret name here.
    ## If you don't want to use the customized CA to sign the external TLS certificate, leave it empty.
    external_tls_ca_secret:

    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    tls:
      ## Existing TLS secret containing tls.key and tls.crt
      tls_secret_name:
      ## Existing TLS trust secret list
      ## You might specify a list of secrets, every secret stores a trusted CA
      ## kubectl create secret generic pfs_custom_trust_ca_secret1 --from-file=tls.crt=./ca1.crt
      tls_trust_list:
      ## The parameter is optional, if you want PFS server to trust your custom trusted CAs, you can add them to a keystore and then create a secret to store the trusted keystore.
      ## The keystore type must be JKS or PKCS12.
      ## kubectl create secret generic pfs_custom_trusted_keystore_secret --from-file=truststorefile=./trust.p12 --from-literal=type=PKCS12  --from-literal=password=WebAS
      tls_trust_store:

    resources:
      requests:
        ## Requested amount of CPU for PFS configuration
        cpu: 500m
        ## Requested amount of memory for PFS configuration
        memory: 512Mi
      limits:
        ## CPU limit for PFS configuration
        cpu: 2
        ## Memory limit for PFS configuration
        memory: 4Gi

    liveness_probe:
      ## Number of seconds after Process Federation Server container starts before the liveness probe is initiated
      initial_delay_seconds: 300
    readiness_probe:
      ## Number of seconds after Process Federation Server container starts before the readiness probe is initiated
      initial_delay_seconds: 240

    saved_searches:
      ## Name of the Elasticsearch index used to store saved searches
      index_name: ibmpfssavedsearches
      ## Number of shards of the Elasticsearch index used to store saved searches
      index_number_of_shards: 3
      ## Number of replicas (pods) of the Elasticsearch index used to store saved searches
      index_number_of_replicas: 1
      ## Batch size used when retrieving saved searches
      index_batch_size: 100
      ## Amount of time before considering an update lock as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      update_lock_expiration: 5m
      ## Amount of time before considering a unique constraint as expired. Valid values are numbers with a trailing 'm' or 's' for minutes or seconds
      unique_constraint_expiration: 5m

    security:
      sso:
        ## The ssoDomainNames property of the <webAppSecurity> tag
        domain_name:
        ## The ssoCookieName property of the <webAppSecurity> tag
        cookie_name: "ltpatoken2"
        ltpa:
          ## The keysFileName property of the <ltpa> tag
          filename: "ltpa.keys"
          ## The expiration property of the <ltpa> tag
          expiration: "120m"
          ## The monitorInterval property of the <ltpa> tag
          monitor_interval: "60s"
      ## The sslProtocol property of the <ssl> tag used as default SSL config
      ssl_protocol: SSL

    executor:
      ## Value of the maxThreads property of the <executor> tag
      max_threads: "80"
      ## Value of the coreThreads property of the <executor> tag
      core_threads: "40"

    rest:
      ## Value of the userGroupCheckInterval property of the <ibmPfs_restConfig> tag
      user_group_check_interval: "300s"
      ## Value of the systemStatusCheckInterval property of the <ibmPfs_restConfig> tag
      system_status_check_interval: "60s"
      ## Value of the bdFieldsCheckInterval property of the <ibmPfs_restConfig> tag
      bd_fields_check_interval: "300s"

    custom_env_variables:
      ## Names of the custom environment variables defined in the secret referenced in pfs.customEnvVariables.secret
      names:
      # - name: MY_CUSTOM_ENVIRONMENT_VARIABLE
      ## Secret holding custom environment variables
      secret:

    ## log trace configuration
    logs:
      ## Format for printing logs on the console
      console_format: "json"
      ## Log level for printing logs on the console
      console_log_level: "INFO"
      ## Source of the logs for printing on the console
      console_source: "message,trace,accessLog,ffdc,audit"
      ## The required format for the messages.log file. Valid values are SIMPLE or JSON format
      message_format: "SIMPLE"
      ## Format for printing trace logs on the console
      trace_format: "ENHANCED"
      ## Specification for printing trace logs
      trace_specification: "*=info"
      storage:
        ## Use Dynamic Provisioning for PFS Logs Data Storage
        use_dynamic_provisioning: true
        ## The minimum size of the persistent volume used mounted as PFS Liberty server /logs folder
        size: 5Gi
        ## Storage class of the persistent volume used mounted as PFS Liberty server /logs folder
        storage_class: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname }}"
        existing_pvc_name: ""

    ## When PFS is deployed in a environment that includes the Resource Registry ,
    ## the following additional parameters can be used to configure the integration between PFS and the Resource Registry
    dba_resource_registry:
      ## Time to live of the lease that creates the PFS entry in the DBA Resource Registry, in seconds.
      lease_ttl: 120
      ## The interval at which to check that PFS is running, in seconds.
      pfs_check_interval: 10
      ## The number of seconds after which PFS will be considered as not running if no connection can be perfomed
      pfs_connect_timeout: 10
      ## The number of seconds after which PFS will be considered as not running if has not yet responded
      pfs_response_timeout: 30
      ## The key under which PFS should be registered in the DBA Service Registry when running
      pfs_registration_key: /dba/appresources/IBM_PFS/PFS_SYSTEM
      resources:
        limits:
          ## Memory limit for PFS and RR integration pod
          memory: '512Mi'
          ## CPU limit for PFS and RR integration pod
          cpu: '500m'
        requests:
          ## Requested amount of memory for PFS and RR integration pod
          memory: '512Mi'
          ## Requested amount of CPU for PFS and RR integration pod
          cpu: '200m'

  ########################################################################
  ########   Embedded Elasticsearch configuration                 ########
  ########################################################################
  elasticsearch_configuration:
    es_image:
      ## Elasticsearch image
      repository: cp.icr.io/cp/cp4a/baw/pfs-elasticsearch-prod
      ## Elasticsearch image tag
      tag: "20.0.3-IF002"
      ## Elasticsearch image pull policy
      pull_policy: IfNotPresent
    es_init_image:
      ## The image used by the privileged init container to configure Elasticsearch system settings.
      ## This value is only relevant if elasticsearch_configuration.privileged is set to true
      repository: cp.icr.io/cp/cp4a/baw/pfs-init-prod
      ## The image tag for Elasticsearch init container
      tag: "20.0.3-IF002"
      ## The pull policy for Elasticsearch init container
      pull_policy: IfNotPresent
    es_nginx_image:
      ## The name of the Nginx docker image to be used by Elasticsearch pods
      repository: cp.icr.io/cp/cp4a/baw/pfs-nginx-prod
      ## The image tag of the Nginx docker image to be used by Elasticsearch pods
      tag: "20.0.3-IF002"
      ## The pull policy for the Nginx docker image to be used by Elasticsearch pods
      pull_policy: IfNotPresent

    ## Number of initial Elasticsearch pods
    replicas: 1
    ## How the HTTPS endpoint service should be published. The possible values are ClusterIP and NodePort
    service_type: ClusterIP
    ## The port to which the Elasticsearch server HTTPS endpoint will be exposed externally.
    ## This parameter is relevant only if elasticsearch_configuration.service_type is set to NodePort
    external_port:
    ## The elasticsearch admin secret that contains the username, password and .htpasswd.
    ## If not provided, the defualt admin secret named "{{ meta.name }}-elasticsearch-admin-secret" is used.
    admin_secret_name:
    ## Whether Kubernetes "may" (soft) or "must not" (hard) deploy Elasticsearch pods onto the same node
    ## The possible values are "soft" and "hard"
    anti_affinity: hard
    ## The Elasticsearch pods require the hosting worker nodes to be configured to:
    ## - disable memory swapping by setting the sysctl value vm.swappiness to 1.
    ## - increase the limit on the number of open files descriptors for the user running Elasticsearch by setting sysctl value vm.max_map_count to 65,536 or higher.
    ## When set to true, a privileged init container will execute the appropriate sysctl commands to update the worker node configuration to match Elasticsearch requirements.
    ## When set to false, you must ask the cluster administrator to change the memory swapping and descriptor properties on each worker node.
    privileged: false
    ## If elasticsearch_configuration.privileged is set to true, you must create a service account that has the privileged SecurityContextConstraint to allow running privileged containers. Refer to Knowledge Center for more info.
    ## If elasticsearch_configuration.service_account not set, default service account "{{ meta.name }}-elasticsearch-service-account" will be used.
    service_account: "<Required>"
    ## Initial delay for liveness and readiness probes of Elasticsearch pods
    probe_initial_delay: 90
    ## The JVM heap size to allocate to each Elasticsearch pod
    heap_size: "1024m"
    ## Specify whether to use the built-in monitoring capability
    monitor_enabled: false

    resources:
      limits:
        ## Memory limit for Elasticsearch configuration
        memory: "2Gi"
        ## CPU limit for Elasticsearch configuration
        cpu: "1000m"
      requests:
        ## Requested amount of memory for Elasticsearch configuration
        memory: "2Gi"
        ## Requested amount of CPU for Elasticsearch configuration
        cpu: "100m"

    storage:
      ## If persistent the elasticsearch data. Set to false for non-production or trial-only deployment.
      persistent: true
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 10Gi
      ## Storage class name for Elasticsearch persistent storage
      storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"

    snapshot_storage:
      ## If persistent the elasticsearch snapshot storage. Set to true for production deployment.
      enabled: false
      ## Set to true to use dynamic storage provisioner
      use_dynamic_provisioning: true
      ## The minimum size of the persistent volume
      size: 30Gi
      ## Storage class name for Elasticsearch persistent snapshot storage
      storage_class_name: ""
      ## By default, a new persistent volume claim is be created. Specify an existing claim here if one is available.
      existing_claim_name: ""


  ########################################################################
  ########  IBM FileNet Content Manager initialize configuration  ########
  ########################################################################
  ## The deployment of FNCM will be initialized with the default values assigned to the parameters below.
  ## The initialization process includes the creation of the P8 domain, the creation of the directory services,
  ## the assignments of users/groups to the P8 domain and object store(s), the creation of the object store(s),
  ## the creation/addition of add-ons for each object store, the enablement of workflow for each object store, the
  ## creation of Content Search Services servers, index areas, and the enabling of Content-based Retrieval (CBR) for each object store.
  ## In addition, the creation of Navigator desktop will also occur.
  ## If any of the values below does not fit your infrastructure, then change the value to correpond to your configuration
  ## (e.g., "CEAdmin" is the default user for ic_ldap_admin_user_name parameter and if you do not have "CEAdmin" user in your directory
  ## server and have a different user, then replace "CEAdmin" with your own user).  Otherwise, the rest of the values should remain as default.
  initialize_configuration:
    ic_domain_creation:
      ## Provide a name for the domain
      domain_name: "P8DOMAIN"
      ## The encryption strength
      encryption_key: "128"
    ic_ldap_creation:
      ## Administrator user
      ic_ldap_admin_user_name:
      - "CEAdmin"
      ## Administrator group
      ic_ldap_admins_groups_name:
      - "P8Administrators"
      ## Name of the LDAP directory
      ic_ldap_name: "ldap_name"
    ic_obj_store_creation:
      object_stores:
      ## Configuration for the document object store
      ## Display name for the document object store to create
      - oc_cpe_obj_store_display_name: "BAWDOCS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "BAWDOCS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOCS_connection" 
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "BAWDOCS"
          ## The XA datasource
          dc_os_xa_datasource_name: "BAWDOCSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os01_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "docs_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 1
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false
      ## Configuration for the design object store
      ## Display name for the design object store to create
      - oc_cpe_obj_store_display_name: "BAWDOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "BAWDOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "DOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "BAWDOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "BAWDOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os02_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "dos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 2
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false

      ## Configuration for the target object store
      ## Display name for the target object store to create
      - oc_cpe_obj_store_display_name: "BAWTOS"
        ## Symbolic name for the document object store to create
        oc_cpe_obj_store_symb_name: "BAWTOS"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "TOS_connection"
          ## The name of the site
          site_name: "InitialSite"
          ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
          dc_os_datasource_name: "BAWTOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "BAWTOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "CEAdmin"
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        - "{CE460ADD-0000-0000-0000-000000000004}"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
         ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/os03_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: true
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "tos_region_name"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 3
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: "pe_conn_target"
        # Enable the content event emitter only when deploying
        # BAI and have shared_configuration.kafka_configuration defined in
        # your cr.  Default value is false if not specified in cr.
        oc_cpe_obj_store_enable_content_event_emitter: false

  #--------------------------------------------------------------------------------------------------------------------------------
  # This section contains 1 object store: Business Automation Application Data Persistence(ae_data_persistence) object store(AEOS)
  # It is required when you want to enable ae_data_persistence optional feature. Please uncomment it when enabling ae_data_persistence
  #--------------------------------------------------------------------------------------------------------------------------------
  #       ## Configuration for the application engine object store
  #       ## Display name for the application engine object store to create
  #     - oc_cpe_obj_store_display_name: "AEOS"
  #       ## Symbolic name for the application engine object store to create
  #       oc_cpe_obj_store_symb_name: "AEOS"
  #       oc_cpe_obj_store_conn:
  #         ## Object store connection name
  #         name: "AEOS_connection"
  #         ## The name of the site
  #         site_name: "InitialSite"
  #         ## Specify the name of the non-XA datasource (from dc_common_os_datasource_name in the dc_os_datasources section above)
  #         dc_os_datasource_name: "AEOS"
  #         ## The XA datasource
  #         dc_os_xa_datasource_name: "AEOSXA"
  #       ## Admin user group
  #       oc_cpe_obj_store_admin_user_groups:
  #       - "<Required>"
  #       ## An array of users with access to the object store
  #       oc_cpe_obj_store_basic_user_groups:
  #       ## Specify whether to enable add-ons
  #       oc_cpe_obj_store_addons: true
  #       ## Add-ons to enable for Content Platform Engine
  #       oc_cpe_obj_store_addons_list:
  #       - "{CE460ADD-0000-0000-0000-000000000004}"
  #       - "{CE460ADD-0000-0000-0000-000000000001}"
  #       - "{CE460ADD-0000-0000-0000-000000000003}"
  #       - "{CE460ADD-0000-0000-0000-000000000005}"
  #       - "{CE511ADD-0000-0000-0000-000000000006}"
  #       - "{CE460ADD-0000-0000-0000-000000000008}"
  #       - "{CE460ADD-0000-0000-0000-000000000007}"
  #       - "{CE460ADD-0000-0000-0000-000000000009}"
  #       - "{CE460ADD-0000-0000-0000-00000000000A}"
  #       - "{CE460ADD-0000-0000-0000-00000000000B}"
  #       - "{CE460ADD-0000-0000-0000-00000000000D}"
  #       - "{CE511ADD-0000-0000-0000-00000000000F}"
  #       ## Provide a name for the Advance Storage Area
  #       oc_cpe_obj_store_asa_name: "demo_storage"
  #       ## Provide a name for the file system storage device
  #       oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
  #       ## The root directory path for the object store storage area
  #       oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/osae_storagearea"
  #       ## Specify whether to enable workflow for the object store
  #       oc_cpe_obj_store_enable_workflow: false
  #       ## Specify a name for the workflow region
  #       oc_cpe_obj_store_workflow_region_name: "<Required>"
  #       ## Specify the number of the workflow region
  #       oc_cpe_obj_store_workflow_region_number: 1
  #       ## Specify a table space for the workflow data
  #       oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
  #       ## Optionally specify a table space for the workflow index
  #       oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
  #       ## Optionally specify a table space for the workflow blob.
  #       oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
  #       ## Designate an LDAP group for the workflow admin group.
  #       oc_cpe_obj_store_workflow_admin_group: "<Required>"
  #       ## Designate an LDAP group for the workflow config group
  #       oc_cpe_obj_store_workflow_config_group: "<Required>"
  #       ## Default format for date and time
  #       oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
  #       ## Locale for the workflow
  #       oc_cpe_obj_store_workflow_locale: "en"
  #       ## Provide a name for the connection point
  #       oc_cpe_obj_store_workflow_pe_conn_point_name: ""
